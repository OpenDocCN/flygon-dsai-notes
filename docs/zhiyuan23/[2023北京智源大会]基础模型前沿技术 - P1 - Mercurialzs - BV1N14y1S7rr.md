# [2023北京智源大会]基础模型前沿技术 - P1 - Mercurialzs - BV1N14y1S7rr

[音乐]，好 大家下午好，我是自我介绍一下，我是来自清华大学的刘知远，非常欢迎大家来参加到，咱们今天下午的基础模型的，这么一个主题的论坛，因为前面给了我5分钟的时间，然后来做开幕。

因为我们今天的所有的嘉宾，然后我们在后面都会邀请他们来做特邀报告，那么我就不一一地介绍他们了，我只是想表达一下我自己的个人的一些，来到这个会场的一些自己的感受，那么实际上其实非常的感慨。

就是在今天这么一个特殊的时刻，然后在我们志愿大会，来去举行这么一个基础模型的主题的论坛，那么实际上回想起来，我们应该是在2020年，然后在志愿研究院的支持下。

开始了国内最早的大模型的一些相关的研发和研究的工作，实际上是在过去的两年里，我们在志愿大会上都进行过相关的大模型的发布，那么实际上是在一直到去年底之前，实际上是大模型更多的还是在学术界。

在产业界然后引起一些从业者的关注，那么到了今天，实际上是在ChinaGPC的这么一个影响下，那么我们实际上是有更多的人士认识到了大模型，然后为代表的人工智能技术。

然后在各个方面的存在的这么一个巨大的潜力，我们一个方面是感受到我们以志愿，[音速缺少]，为代表的国内的研究院，然后在这种技术上的探索的这么一个前瞻性，那么同时我们也能够感受到在技术的浪潮上。

我们的一个相关的机遇和挑战并存的这么一个趋势，那么今天来到2023年，实际上是我们可以看到，无论是全世界还是在国内，然后我们都已经陆续地涌现出来了非常多的和大模型有关的一些创新的技术。

还有一些创新的应用，那么我们也相信以志愿为代表的国内的这些大模型的先行者，也能够在我们最新的这次人工智能的革命中，然后能够发挥重要的作用，那么我认为志愿大会应该是咱们国内最早的。

比较系统的去推动大模型技术的普及和推广的这么一个论坛，那么我们今天的话我们就以基础模型作为我们的主题，然后来邀请了国内外的非常一线的专家，然后来给大家介绍大模型相关的一些比较前沿的技术。

那么今天其实我们后来在跟讲者进行交流的时候还看到，我们今天邀请的四位特邀讲者都是女性，其实我们也是觉得是一次非常有意义的巧合，那么我们也是希望能够希望我们更多的女性工作者。

然后能够加入到咱们的大模型的人工智能浪潮中来，那么我们接下来就首先欢迎我们的第一位特邀讲者，是来自于志愿人工智能研究院的副院长兼总工程师林永华老师，然后来给大家介绍基础大模型。

工程化打造AI中的CPU的主题报告，那么大家欢迎，请，好 谢谢，喂 喂 有声音吧，喂 好，谢谢刘老师的介绍，那今天呢 今天上午可能我们的整个大会的kick off的时候。

大家也看到了志愿发布了这个天鹰大模型，所以我也趁今天这个报告的机会，一方面想跟大家分享一下我们在打造大模型的过程中，为什么认为是说需要以工程化的方式来打造大模型，并且为什么它就像AI中的CPU。

同时呢也利用这样一个topic给大家介绍一下天鹰大模型，但在这头我想先说一点，因为我们的tech report还没有出来，所以有点抱歉的是今天的整个talk。

一些具体的指标的数字可能都不会跟大家往外去说，那个可以期待我们的tech report，好 那首先是说为什么我们会认为，基础大模型它去打造它的时候就像打造AI中的CPU。

实际上首先我觉得第一个最重要的是说，它的一个单一产品的投入是巨大的，已经成为了整个AI里头，如果我们说是一个基础的大模型，百亿甚至千亿规模的大模型，它的成本是很高的，那在这里头呢给大家分享一下。

这是我们的一些具体的practice，以及去预估的一些数字，因为有一些东西不好disclose出来，所以大家就是主要是看这个比例，那首先大家可以看到是说对于几百亿的模型，蓝色的是我们的用于训练部分。

所有的我们需要的蓝色是数据，训练数据，因此我们为训练数据所需要花的人力，我们的计算我们的处理等等，这些加进去是多少，那灰色的是我们的训练部分，包括，包括人力也包括我们的机器的花销。

那还有橘色的部分是评测的部分，也是包括人力和花销和算力，那大家可以看到，对于几百亿的模型，它的用于数据上的投入，跟训练时候的投入已经可以相当，所以从一个侧面说为什么数据很重要。

那另外一块也是想提起大家的注意，是说评测很重要，但这里头有一些东西是没包括进去，例如是说我们因为去explore一个新的模型的架构，而要做的很多的创新，那那些是没加进去。

因为我们认为那些3POWER-5还是可以，去分摊到我的不同版本的模型，那这里头就说SINGLE版本，它的一个分布是这样子，那对于330亿这样子的模型，它的成本大概是在2000万这样的人民币的一个投入。

那后面如果是说我们把这个，拓展到1300亿这样的模型，那在这个成本上面就不一样了，那这个还是keep我们以一个T的token这样子的量来说，那这个的投入的量，是另外一个数字，我就不具体说了。

大家只是看这个量，那如果是说我们对于一个千亿模型，一个T的数据不够，我希望让它的数据量变成两个T以上，那大家也可以看到，它对于我们的数据的成本和训练的成本，也是有不一样的一个高，所以总体来说想说的是说。

对于我们语言模型来说，它的开发成本是十分高昂，但这也值得，因为今天大家也越来越意识到，语言模型它不是仅仅是一个语言模型，它真的会成为我们未来AI中的大佬，那第二个，从第二个角度来说。

为什么它是AI中的CPU这么重要，因为基础模型，它很大的程度决定了后续模型的能力，和产业落地的因素，首先是说能力和知识，其实最近Meta有一篇文章是讲Lima，具体不说。

但里头它的一个SAH的假设我是很认同，其实我们在大模型，尤其是基础模型里面，所有的能力和知识，都是在基础模型这一部分所获得的，所以如果我们在基础模型这一块，没有把它的能力训练好。

把它的知识能够训练进去的话，其实对我们后面再怎么做SFT等等，其实是会面临很大的一个制约，所以这是第一，从能力和知识上，它决定了我们后续去持续训练，还是做微调训练的能力。

那第二个很重要一点是合规性和安全性，因为训练模型它的数据的一个干净程度，尤其是它的合规程度，很重要的会影响我们的AIGC的应用，毕竟咱们这个语言模型，很大程度是会生成内容，那在这里头给大家举个例子。

Common Core可能是很多人都很熟悉的，一个全球的一个数据集，里头我们关心一下，它那个中文数据集的情况，这是我们把里头的100万条中文，带有中文的数据，拿出来去分析它的占元情况。

发现是说来自中国大陆的占元，仅仅只占17%，有83%的占元是来自于海外的中文网站，所以在这里头就是说，从内容的合规性上，从内容的一些的安全性上，这个是有一个很大的一个风险在这里头。

而当我们把用很多的用这样子的数据，去训练我们的基础模型的时候，其实对我们未来的微调后的模型，是具有一定的风险，当然大家可能会说，那我在最后模型的输出或模型的输入，我加一些安全的风控。

但要知道这个不是所有的安全的风控，都能够防得住所有的生成，例如是说我们有时候可能会问是说，中国发生的十件大事，那这种的问题不能不让人问吧，但是它在产生这十个不同的事件的时候。

有可能就会存在一些不安全的一些的输出，那另外因为本身对于我们来说，不单我们要考虑这个模型是否可以拿出来，给更多的学术界的去使用，我们还要考虑怎么可以让产业更宽广的去使用。

所以在这里头会考虑这个版权和商用许可，那到底这个基础模型它是可商用许可还是非商用许可，它的使用的许可是copy left还是copy right的一个许可，是否具备这种开源的一个污染性。

这些都是我们需要很仔细去考虑的，那这个是从今年一月份到五月份，所有在国内国外发布的这些语言模型，我们做了一个简单的统计，在国外发布的语言模型我们记录了有39个。

其中可商用并且非copy left的协议的大模型大约有16个，那这里头例如LAMA我们也很熟悉，知道它其实是一个非商用的，那意味着我们所有基于LAMA去进行。

做continue train和SFT的模型，实际上都不能够合法商用的，那还有一些是使用了copy left协议的模型，意味着我们通过这种copy left的协议的模型去进行。

further develop例如这个持续训练或微调，所得到的模型也必须开源，这是copy left的协议，所以这个势必对产业如果是正规企业要落地产业，其实是会造成很大的限制，那国内的情况是怎么样呢。

其中这个语言模型我们统计了28个，开源的语言模型有11个，其中直接使用开源可商用的语言的大模型只有一个，并且是只是一个进行了指令微调的对话模型，所以我们看到在基础模型上面。

尤其是来自于咱们国内的完全开源可用的，中英双语可商用的其实是很缺乏，所以这里头就是我们寻找的实际上是说，第一能支持中英双语知识，这个知识不是只是翻译，所以这意味着我们需要把大量的咱们中文语言。

所表达的知识要放到这个预训练数据，第二我们期待它是支持商用的许可协议，没有copy left的限制，第三是符合国内数据合规的需要的，所以这个就是我们打造这个Aquila天鹰。

悟道天鹰这个语言模型的一个目标，首先第一个就是我们希望为产业打造，像刚才所说的具备双语能力，并且是以商用许可协议的开放源代码及模型的系列，第二个我们实际上是在设计之初，就定下了一个高层的设计。

我们希望这个语言大模型，它有怎么样的一个能力的框架，这个能力框架其实很重要，这个能力框架决定了我们后面所寻找的数据，以及我们的评测的方法，最后一点是说我们越来越觉得重要的是，为整个语言模型的打造。

并且是持续打造，需要有一个端到端可持续循环的，整一个模型的生产的流水线，打通从数据训练到微调到评测，再回环回数据这么一个畅通的链路，所以就这样的一个目标，我们今天也是开放了这些的一些模型。

这里头其实就包括了330亿的，和70亿的中英双语的基础模型，基于这两个基础模型，我们的对话模型，以及基于我们70亿参数的代码模型，其实在这里头，对我们来说对话模型和代码模型，更多的是一个例子。

就给大家看到是说基于这样的基础模型，我们可以怎么进一步的去打造，通过SFT去打造我们所需要的对话模型，或基于持续训练去训练出我们需要的代码模型，其实使用者可以基于他自己的应用需要。

去重新去做这样子的fine tuning，介绍这个模型的时候，首先我想还是给大家介绍一下训练数据，支援我们的中文数据，实际上是持续一直在积累，在这里头也给大家分享一下，大家可以看一个右边的图。

我们是接近30%多的数据是中文，60%多的数据是英文，这是目前的一个比例，不排除后续我们会有一个调整，另外第二个大家可以看到这里头的分布，这个我就不说了，但是我想给大家强调是说。

中间其实最重要的首先是互联网数据，它的一个质量，我们整一个的中文的互联网的数据，检查了所有的它的来源，其中99%以上的是国内的占元，所以这是我们很重要的一个基础，是说它的一个内容的安全性和干净的程度。

第二个呢，无疑大家可能做过中英双语模型的，一个研发或调研的，比较过这个数据集都知道，compare我们的英文的开源数据集，其实中文数据最缺的是，第一开源的高质量的文献的paper的中文的数据集。

第二个是我们的开源，可用的这种的书籍的数据集，那在这里头支援也是得益于，国内的一些数据机构跟我们的合作，他们愿意去把它的中文的文献数据，还有中文的书籍数据，贡献到这样一个模型的训练里头。

那我想这也是因为我们这个模型，是以一种完全公益的形式，以商用许可的方式，再回馈给整个产业，所以他们愿意跟我们一起来做这个事情，在此也很感谢这些机构，那当前我们已经积累了，超过1。

4T token的训练数据，并且我们还持续正在增加，更多高质量多样性的数据集，也在源源不断地把它训练到，Aquila的这样一个基础模型里头的训练中，那这个基础模型，第一它在技术上承接了。

像GPT-3还有LAMA这些的架构设计的优点，那另外我想提一下是并行训练，我们使用了PM Train，这个来自于刘老师团队很好的一个工作，那我们升级了PM Train里头的，这个并行的训练方法。

它目前能够达到的，直接可以对标的，例如像MicroTron DeepSpeed-02，我们实测是可以在一个，具备一个大规模并行范围里头，可以达到8倍的训练效率，那可能大家会说，为什么我们不跟03比。

因为03有bug，这个给大家贴一下，这是我们团队大概两三周前，因为我们这个训练比较早就开始了，两三周前提交给DeepSpeed Team的，最后fix了这个03的bug，那另外呢。

下一个就想给大家分享的是，我们SFT数据的打造，因为这一次我们除了基础模型，我们也开源了这个我们的对话模型，这也是大家可能在实际用的时候，经常会用到的模型，就可能对于更多的一些爱好者。

或者是更多的下游的一些应用企业，可能会直接用到这样子的模型，那我们在整个SFT数据打造里头，是分了四个阶段，数据采集，然后第二个阶段是，根据这个数据的分布进行，数据分布的分析并进行调整。

第三个是进行这个SFT模型的测试，以驱动我们的一个数据的迭代，最后是包括这个重要指令的添加，在这里头给大家稍微分享一下，那不同的团队有不同的数据的采集的方法，那智原这边我们是，首先我们为了这个数据采集。

指令数据采集，因为它我们可以预见，它是一个长久性的东西，那因此我们特意打造了一整套叫Open Label，这样一套指令数据采集的工具，但实际上它后来已经不单是，我们的指令数据的采集和生成的工具。

也包括我们在去reward model的时候，用来做排序标注等等的这些工具集，那我们使用了，就是说包括我们智原内部的，有一个固定的一个数据标注的团队，也包括向外面发起这个数据标注的公益活动。

我们叫数据飞轮，我们在三月份的时候，发起这个外部公益者这个数据飞轮的活动，我们当时是说等我们储备到了一万条，我们就把这个所有的这个，在通过公益活动，他们来贡献这个数据标注的部分，把这个全部开源出来。

整理好全部开源出来，那正好其实是在昨天，我们就把这一部分开源出来一万条，坦白说这个时间有点比我想象的要慢，我当时就觉得是说一个月就能够，至少能够这个通过外部的公益活动，能够标注够一万条。

但发现其实这个东西不是那么容易，但我们会持续去做这个事情，那第二个呢，很重要的是整个数据分布的分析以及调整，前面说到了，其实我们定义了整一个的大模型，我们认为语言模型的能力架构，能力的分布。

那这个图实际上是对应前面那个图，我们会分析是说，我们的指令微调数据集，它对于我们那个需要的能力分布来说，它从指令数据的角度，它的分布是不是能够对应上的，这不是我们目前的这个图。

这个是稍微比较早期的一个分布图，那当时我们出了这个分布之后，我们就会看哪一些的方面的能力的数据偏少，那因此我们需要增加那一部分的数据的能力，实际上我们一直有一个理念是说，SFT的数据集不是越大越好。

其实合理的应该是说，我们的基础模型很强，然后我们只需要少量高质量的SFT数据，来让这个模型发挥很好的，它的知识的一个执行能力，所以我们一直实际上在控制着，我们这个指令微调这个数据集的大小。

这一点其实是很重要，SongFile实际上我们一直控制到今天为止，大概就是十几万指令这样子，然后我们比过，因为本身我们也有一个几百万，甚至一千万的一个指令微调的数据集，包括有一部分也开源出来。

比过是说到了今天为止，用这个数据集来funtune同一个基础模型，已经超过了用一千万或五百万的数据集，来funtune这个基础模型了，那再往下一步就是说，我们持续的需要去构造这样一个迭代的过程。

当我们这个SFT指令微调这个模型出来之后，我们会经过人工评测，看到它的不好和好的，然后呢不好的那些case，我们会在一个很大的，其实也就是一千万条的那个数据，大的指令的数据的pool，那个池子里头。

通过解锁方法，把一些能力吻合的一些数据拿出来，来进入到我们的下一个版本，叠加到下一个版本，所以大家可以看到这个微调数据集，前一个版本是蓝色，上面一个版本是红色，所以我们持续的这样子去自动迭代。

就除了人工来评测那个SFT的那部分，会是人工，剩下的就会是自动的去调整我们的微调数据集，那最后一个呢，对我们也是很重要的一块，就是一些重要的指令的添加，那在这个过程中，首先是左边这块。

就所有的我相信今天，要放出来的对话模型，都必须要做的是安全的这个的安全伦理等等的，这样子的一个评测，那智原本身我们是有一个，专门有一个Red Team，我们把它称之为Red Team。

他们专门是帮助我们去评这个bad case，并且我们这个Red Team的选择是，它既不是我们做前面，就等会说到那个，每天做这个评测的那些评测人员，也不是我们做数据集的人。

它是完全一个separate team，然后不好的那些问题，肯定要有重写这个答案，让它放回到我们的指令微调里头，那另外一个呢，就是我们在这一次，也定义了这个去构造，连接一些应用。

或连接一些其他模型的指令数据，很简单的定义了这个格式，然后因此，它可以帮助我们去，很好的去链接其他的模型，例如在这里头有两个例子，一个是文生图的例子，上面说请画一只戴眼镜的狗，然后它就可以自动的去生成。

这样子的response，其实这个response里头前面半句话是，说我作为一款文生，门本生成模型我没有这个能力，那后半句话它就真正的输出，如果我们要真的喂给一个，例如diffusion的模型。

那它就直接生成一个格式，一个特殊的字符的格式，以及后面需要用到的prompt，那我们这一次实际上是集成了，两种不同的模型，这其实是一个范例，所有人如果用这个Aquila的模型，也可以用自己的方法来去。

同样的格式就可以扩增自己，要接的更多的模型和工具，那这个呢是今天上午，如果有看到这个黄老师，他的demo可以看到的，第一个实际上就是，我再放一遍，其实这个飞机是一个多轮对话，是一个多轮对话的。

然后呢在下面，这个还是一个多轮对话的场景，然后这个是高考作文，我们这一篇高考作文，大概800字左右，生成的时间不到10秒钟，其实这没有什么magic，其实这得益于说我们，这个demo里头用的。

仅仅是我们的70亿参数的模型，那这个就是我们通过刚才那个指令，来能够在同一个语言模型里头，去应对用户说要画图的这样子的一个，然后背后实际上是调用的是，我们的Auto Diffusion，在这里头。

其实我们放了这个我们的demo，放在外面的demo booth，甚至大家先那里头是放video，大家到时候如果看到我们的同事在那，可以要求他们去给你实操，其实我们是可以实操的在那，我们在这个上面。

其实也可以用不同的语言，包括韩语包括西班牙语，包括法语等等，我们支持18种语言的文生图，正好就跟我们这个语言模型，它其实也已经具备了多语言的能力，进行一个结合，就是用不同的国家的语言。

去输入给Aquila Chat，然后让它生成相应的图，那最后这个是一个，把一个复杂的一个人脸编辑的指令，自动的划成成好几个step，然后背后是调用了我们新出来的。

一个叫instruct face的这样一个模型，至于这部分的工作，大家可以留意明天上午，AIG内容生成模型的workshop，我们会有介绍，好那下一个是说，我们这次发布里头，其实也给大家提供了代码模型。

我们认为其实代码模型，它会扮演着未来，尤其是面对企业应用，企业用户场景很重要的一个角色，那这次我们的确是说，首先我们用的数据集，我觉得我们也比较lucky，当我们刚开始想做这个事情。

去try我们的Aquila Base的，这个模型的能力的时候，Happen， the stack，这个数据集出来了，这个就是那个Big Code的团队，由Hackenface来牵头的。

那个Big Code的这个项目团队，开源出来的，这个数据集的好处是说，它所有的代码数据，都过滤干净它的版权，它去掉了所有没有版权声明的数据，只留下有版权声明的数据，它去掉了所有copy left的数据。

因为如果一旦有copy left的数据，在我们的预设链数据里头，很难说以后出来的，我们给人家用户生成的数据，你是不是也得follow，copy left的这个规范，现在没有法律去规定，但是有这个风险。

所以我们倾向于是说，只保留有版权说明，并且只有copy right的数据集，但我觉得我们是比较幸运，刚好他们开源了这个数据集，那我们队里头也是做了很多，高质量的过滤，那在这里头我们。

在这里头我们也是做了，另外一个很重要的，就是说在我们训练这个数据，我们拿我们其中比较早期的一个，Aquila Base的一个7B的模型，来做持续训练，能够达到很好的一个，代码生成的效果。

那同时我们除了在英伟达平台上，我们还在天数之星的这个，咱们国内的另外一家，GPGPU架构的一个硬件平台上，做了一个32台服务器，一个cluster上面进行训练，这个整个训练下来的，还是相当稳定。

所以这也是去，想说的一下是说，国内实际上咱们一些，晶片so far目前，除了在训练喷吐量上，的确还不如英伟达，但是当我们push去解决一些，更多的算子优化的问题之后，其实是可用的，例如在这次我们把东西。

migrate到天数的平台上，我们也帮助它一起，enable了像fresh attention，这样子的最新的加速算子，在它的平台上，好下一个是说评测，评测我是认为相当相当的重要，首先为啥重要。

咱们如果要训至少这种，像我们这种百亿以上的，或三百亿的模型，每天要花的训练成本，是超过十万的，所以在这个过程中，我认为就说，这种很大的模型，它真的是大船难以挑头，我们如果是说不每一天，盯着这个评测。

每一天看它这里头，这个问题，你真的是放手，让它训一两周，有可能出了，出现了什么问题之后，那已经可能，有可能这一两周，就已经过去了，这中间所耗的成本，是很让人心疼，所以我们在整个过程中。

都必须关注所有的细节，用来对训练的策略，进行及时的调整，然后甚至对训练的数据，也要进行及时的调整，另外是说，实际上本身大模型的能力，是很复杂的，所以我们肯定不能够，只依赖去看。

training loss和validation loss，根本它们这两个loss，不能代表一切，那在传统的下游，适配这种评测的任务，又有现在新的，像HARM为代表的。

这种in-context learning的方式，来进行评测，其实它们是用一模型，在不同的一个训练阶段，那另外，因为毕竟咱们，这里头是一个生成模型，我们还需要去盯，这个生成模型，它的主观评测。

之后它的生成能力，另外模型的SFT，这种微调的能力，也是很重要的，需要考虑的部分，所以这个是我们认为，就是说整一个评测，正因为这个模型很复杂，训练成本又很高昂，所以我们需要很紧密地，去通过评测。

来盯着它的所有的性能，那在这里头给大家看到，是说我们这个模型，真的是整一个回还，我就不说了，因为时间关系，那这是天鹰，我们目前执行的，按分钟和小时算的，可能是像training loss。

validation loss这种，每天至少两个checkpoint，来做任务的评测，in context learning，我们HAM里头，已经extend了所有的中，HAM原来只有英文。

我们extend了中文的部分，中英都能评测，然后每天至少有一个checkpoint，要做主观评测，优选的模型，我们甚至会进入，我们的Red Team的评测，那整个评测体系，实际上是依赖于。

我们这个叫天秤，也是今天发布的，那这里头不花时间介绍，明天下午在AI开源论坛，我们有专门有这个评测体系，开源评测体系的介绍，这个我也不说了，我们在这个评测体系，尤其是它也是一个，很重要的系统工程。

要自动实现自动化的评测，边训练边测，包括我们要实现评测结果，可以指导我们的模型训练，还有需要对各阶段进行优化，就用更少的并行的一些机器，来去支撑好我们高效的一个评测，那另外呢，对我们很重要的。

无疑是下面的这套，这个infrastructure，这次我们是基于，智原本身就有的九顶，专门为大模型训练开发，打造的平台，那我们在整一个里头，其实是across了几个数据中心，但是每一个cluster。

都很typical的，都有它的训练的集群，微调的集群，以及它的这个评测的集群，这几个集群必须要放在一起，否则中心与中心之间，光传每天传几个checkpoint的时间，可能都要花好几个小时。

那这里头说法可能最后一两页了，首先我们认为，这个基础大模型，为什么回到这个CPU的这个说法，因为我们希望是说，以CPU方式，借助像TikTok这样的方式，来构建大模型，一个周期性发展的路线图。

就我们希望从智原的角度，我们不是今天只是发了一个模型，就完事了，我们希望是说，可以去定义未来，可预见和不可预见的创新，来构造我们后面的路线图，所以大家可以持续的关注说，我们未来不断的去更新。

我们的模型的版本，我们会这个，这个时候我们会源源不断的，把我们的预训链的海量数据，继续往里头去压那个模型，我们应该是今天或明天，就全部开源，就会开源出来，但是这个开源的版本，不是我们的最终版本。

我们觉得这个模型的能力，是需要被持续提升的，所以这个是可以被期待的，同时各种大模型的新技术，甚至产业的需求，也都会源源不断的，加到新的版本的模型中，所以我们觉得是说，打造整一个可持续往前走。

包括从数据到训练到评测，以及它的回还，是目前我们看到基础大模型，它的一个发展，很重要的一个基础设施，那最后说一下，我们说资源悟道3。0，今天也全面发布了，我们从去年年底开始发布，一直到今天。

那这个是给大家看，我们认为的整个大模型，我们sofa资源悟道里头的模型术，的确是说，没有基础模型的生根，带不来知繁业茂，最重要的是，其实是得先有最下面的，这些越往下越重要，这些基础模型。

这个是开源仓库的地址，然后大家有感兴趣，建议大家可以扫一下，这个二维码，这是我们这个，这个AI，我们的这些开源的模型，都会放到Fly AI里头，那这个是我们的，这个开发者群，然后希望资源可以帮助。

通过我们的持续创新，持续迭代，持续的产出，可以帮助推动大模型的发展，谢谢大家，好，那感谢永华老师，那个非常精彩的介绍，这个没想到，这个现场已经坐无虚席，而且站了这么多同志，那就辛苦大家了，那我们接下来。

就有请我们的下一位讲者，是刘硬含女士，她现在是BIRDS AI的，核心创始人和CTO，那么在创业前，是这个Facebook AI Research的，研究员，那么她非常著名的作品，应该是大家耳熟能详的。

这个Robota，还有BIRDS，那应该是我们，这个非常重要的几个，这个预训练模型，早期的预训练模型，那我们接下来就欢迎，这个刘女士来给大家，带来她的精彩报告，首先非常感谢志源，给我这次机会站在这里。

和大家一起讨论一下，大语言模型，我先做一个简单的自我介绍，我叫刘硬含，我来自天津，现在居住于西雅图，几年前我跟我的几个朋友，一起创建了BIRDS AI，我们致力于开发一种SARS产品。

Target的客户群是医疗工作者，所以我们的产品主要是，聆听医疗工作者和客户的对话，这里的客户很多时候都是病人，然后对他们的对话进行梳理，然后写入客户的数据库，或者病人的病历，这样的话医疗工作者。

可以更加把时间用在和病人，怎么讨论病情，或者解决客户的问题，而不需要用过多的时间，去讨论这些数据，所以这就是我们刚开始创始的目标产品，那我做一下，在创建BIRDS AI之前。

我在Facebook AI Research，做自然语言处理，就像刚才介绍的一样，我发过的paper里包括，Robota， BIRDS和mbirds，所以今天我想跟大家讨论一下。

Reinforcement Learning with Human Feedback，在过去的一段时间，大元模型风靡全球，尤其在research领域，大元模型主要从Lamar到Apaka。

这种Pretreat到Funting，但是我觉得大家过多的注重，在Pretreat和Funting，而忽略了一项非常重要的内容。

就是Reinforcement Learning with Human Feedback，那我今天想从不同的角度来讨论一下。

这个Reinforcement Learning with Human Feedback的重要性，这是今天的Azanda，首先我们从产品的角度来讨论一下，为什么我们需要大元模型，之后我们再讨论一下。

我们怎么样利用搭建这样一个AI产品，让大元模型更好的发挥其价值，然后这里就运用到了，Reinforcement Learning with Human Feedback，之后我从技术的层面去讨论一下。

Reinforcement Learning with Human Feedback，在大元模型中是怎么实施的，最后我们回过产品的角度去展望一下，我们在大元模型当中还可以做什么，让它更多的发挥价值。

那谈到产品，那无非就两种产品，一种是面对消费者的，另外一种是面对企业用户的，那面对消费者的话，很重要的一点，就是我们需要产生的文字是消费者想要的，那在此之上是产生一种个性化的文字。

是能发挥消费者更大的个性化，那举一个通俗一点的例子，我有一个朋友，他是一个职业的演讲者，他每年都会被邀请到世界各地去演讲，然后自从Chai GPT出来以后，他就会试图用Chai GPT去写他的演讲稿。

但是不管他适用什么样的Prom，得出的演讲稿总是，开头是Ladies and Gentlemen，这种文绉绉的气势磅礴的一个开头，但是其实他所需要的是一个更加接地气的，一个更温柔的一个开头。

所以他每次都会进行大量的修改，同时他有一些特别的个人经历，他总会写在自己的演讲稿中，还有他个人的一种幽默感写在演讲稿中，所以他每次在Chai GPT产生的文件当中，都要进行一个很多的修改。

然后融入他的个人风格，所以对于个人用户，其实每个人的演讲风格，每个人的写作风格是很少发生变化的，所以如果我们能更好的收集，这些客户的个人风格，那这样下次当客户再使用这种大语言模型时候。

产生的东西就是更贴近于他们所需要的东西，这样我们可以减少他们的编辑，提更好的提高他们的效率，好，我们现在讨论一下，面对企业用户大语言模型，现在的大语言模型所需的东西，第一点是了解特定的语言环境。

举一个例子，因为我们是一个医疗产品，所以我们的客户大多数都是医疗工作者，那有一个phrase叫做shoe modifications，在我们的日常生活中，这句话的意思就是改一下鞋跟。

从高跟改成低跟或者矮跟这种，但是在医疗行业，其实这个是一个treatment，是一个治疗方案，是治疗怀腕关节的一种治疗方案，所以现在这种非常通用的大语言模型，很难了解到这种特异特殊的语意，那还有一种呢。

就是公司的内部的政策和和policy和knowledge，那举一个再举一个通俗一些的例子，比如说沃尔玛的退货原则呢，就是30天无条件退货，但是呢cosco呢，只是15天无条件退货，那沃尔玛呢。

是可以退货，只能退货成一个coupon贷金券，一下子可以使用，但cosco呢，是可以退货退回到你的信用卡，或者现金退货，那这种特别的公司内部才知道的knowledge和policy政策。

那一个通用的大语言模型就很难做到了解，所以这个时候我们就有意义去搭建一个个性化的模型，来满足不同客户的需求，那怎样加建这个个性化的模型呢，我们现在来讨论一下啊。

这solution呢就是建立一个实时的AI系统，那我们这是一个非常重要的一点，因为这个实时的AI系统可以更有效的接收客户的使用feedback，那么我想在座的各位都应该很同意一件事情。

就是AI现在不能取代人类，这就是我们现在存在在这个地球上的意义，那我们具体的讨论一下为什么它不能，首先第一点，我觉得AI更像是一个小帮手小助手，比如说我需要写一篇500字的高考作文。

那AI可能10秒钟就写完，我需要用20分钟或者是更多的时间对它进行修改，采纳其中的某一些段落，然后对另外一些段落进行修改，然后体现我自己想要的这个作文风格和文采，那这个呢是AI现在做不到的。

是因为人它不了解人到底需要什么，人是最后做决定的，最后决定是否采纳，最后决定我提交什么，然后呢，所以这是一个人和机器共存的时代，现在所以机器更是一个小助手，那这个时候呢，我们就发现了一个很有趣的现象。

那就是人类到底是怎样编辑这些文件，然后最后提交的，那比如说我用AI写了一篇500字的文章，然后呢，我删掉了重写，那说明AI产生的东西根本不是我想要的，那也有可能我用AI写一篇500字的文章。

我只改了10个字，我只加了一句话，那就说明这个AI产生的东西就是客户想要的，或者中间呢我改了200字，in the middle，所以呢，这个时候我们就发现，这个信息其实是一个很好的评估系统。

能了解AI的performance，因为大家都知道generative AI最重要的一点就是这个performance matrix，是一个非常主观的，因为有的人。

每个人每个不同的人都有不同的taste，不同的品位和不同的偏习，所以它很难量化，但这个时候如果我们有这样的一个实时的AI系统，我们就可以量化的收集到客户的信息。

然后以客户做个多少修改来评测我们所产生的文件，是不是用户喜欢的，想要的，需要的，那这样的话呢，我们就建立了很好的一个评测体系，正像我刚才说的，我们主要面对的是企业用户，那企业用户中有一个很重要的特点。

相比要个人用户，那就是企业用户的员工一般都是受过训练的，他们了解公司的策略，他们了解公司的knowledge和policy，所以对于这些企业用户的feedback是具有更高价值的，但是即便如此。

我们还需要建立一些filter，filter掉一些没有意义的低质量的feedback，那这个filter是一个非常case by case的情况，那我一会儿会举一个具体的例子。

然后呢大家可能更好的了解到，我们这个filter怎么建，我一会儿会提到更详细的信息，好那我现在收集到了一个非常重要的信息，就是用户的使用信息，用户的编辑信息和用户最后提交的信息。

那用这个信息我就有足够的数据量去训练一个reward model，那这里我有一个非常非常strong的hypothesis，这个hypothesis就是用户最后提交的信息，是一个更高质量的。

用户更想要的信息，相对于大元模型最初产出的信息，所以这是一个自然而然，浑然天成的training dataset，非常的高质量，那当我们得到这个training dataset的时候。

我们就可以去训练一个很高质量的reward model，最后呢运用强化学习，不停的提高我们大元模型的质量，让它越来越产生人类想要的答案，所以在不远的将来有一天，AI或许可以取代人类。

这是一个让我们既兴奋又值得担忧的问题，但是我们现在先更紧准这份兴奋，然后把担忧留给以后，所以今天呢我在这里讲的是大元模型的应用和价值，希望不久的将来有一天我站在这里来讲，人类存在的意义和价值。

好那我们现在举一个例子具体的例子，这个是我们刚刚部署的一个客户的例子，很像但是不能不完全一样，那我们在这里来讲一下，怎么运用大元模型，怎么运用人类的反馈信息，搭建一个实时的系统来收集反馈信息。

然后去出一个更好的model，那这是一个很贴近生活的例子，那一个客户呢打电话说，我四月份的时候买了一个printer，然后呢现在降价了，然后呢这个时候这个接洽员呢就会做两件事。

第一件事我要调出这个客户的信息，确定他确实在四月份购买了这样的一个打印机，然后呢我要看我这个客户，他是一个什么样的客户，他的消费频率是什么，他是不是会员，他每次消费的额度是什么。

当我确定这是一个非常非常高价值的客户，我想让他开心，我想留住他，我想让他持续的在这消费，然后第二件事呢，这个接洽员要去查一下公司内部的政策，那公司他的退款的政策是什么，他可能是60天内降价可以退款。

但是如果60天以后就不可以退款，那结合这两者信息，接洽员做出最后的决定，那就是告诉这个客户，首先先议后扬，告诉这个客户，嗯60天的退款政策已经过了，所以我们现在不能退款。

但是你呢是一个非常非常有价值的客户，你非常的特别，我们为了你愿意更改政策，所以我们决定给你一个贷金券，你可以下次使用，那这个在这种情况下，大语言模型可以做到怎样的应用呢，首先大语言模型有聆听这段对话。

然后呢他做了很重要的第一点，是虽然客户有说，我4月份买了一个打印机，但是呢现在降价了，他没有提到一个词就是退款，但是大语言模型可以以上理解，他客户打这个电话的目的是退款，然后呢他会收收集公司的退款政策。

那找到OK60天内是可以退款的，但是60天后是不可以的，同时呢他又走到客户的，他又走到他又走到data base，去找到客户的信息，然后去classify这个客户是一个高质量的客户。

是一个是high value的客户，然后结合这两种信息，大语言模型推荐给了接话员一个回应，那就是可以可以给一个coupon，可以可以给一个贷金券下次使用，那我们的接讯员呢是很聪明的，他们受过专业的训练。

他们知道怎样说才能让客户更开心，那接讯员呢采采纳了大语言模型的推荐，就是OK我可以我不可以退款，但我可以给一个coupon，但是呢他用了一种其他的方式，更好的更愉悦的传达出这份信息，让客户更开心。

听起来因为客户会觉得，我很我很special，我很特别，那这个时候呢大语言模型，就在后面收集到了这份信息，然后他就学会了，好我去我下一次去训练一个排序模型，我下一次的时候，我会用这种方式去说。

让这种方式可以让客户更开心，更满意，这个时候他会进行强化学习，收集到这个信息，那回到我们刚才说的filter的问题，那不是每一个接讯员都很优秀，总有一些人是销管，总有一些人卖不出去。

总有一些人会惹动客户，所以呢这里很重要的一点，就是大语言模型同时还会监督去查找，这个客户下一次有没有使用这个消费，有没有对这次谈话进行满意，如果满意度很高的话，然后下次进行更多的消费。

那说明这是一个很好的agent，这是一个很好的客服，那我会给一个更更高的权重来学习你的话术，那如果这个客户就totally disappear，再也没有出现过，那就证明这个客服可能说的话术并不好。

不是用户想要听到的话说，那这是一个非常不好的数据，那我就会把它filter掉，所以呢所以大语言模型会很聪明，然后在进行强化训练一段时间后，那大语言模型的target就变成销管。

这是一个很ambitious的goal，好那既然我们已经讲过了，大语言模型和reinforcement learning with human feedback，在日常在产品角度上的应用和重要性。

还有搭建这个实时的系统的重要性，那我们现在讲一下到技术层面去讲一下，这个是如何实现的，首先这幅图是引自于OpenEye，去年三月份发的instruct gpt的paper，那我们清楚看到这里有三步。

第一步呢是OpenEye收集了客户，收集了用户使用Prom的信息，然后他们进行了人工的标注，然后训练了一个SFT model，我想在座的各位都对SFT model非常非常地了解。

所以我今天就不在这里过多地讲述SFT model，但请大家记住这个词SFT，我们后面会用到一个监管的微调，那第二步呢就是他们做了一个，第二步第二层次的标注，然后做了一个reward model。

他们的标注呢是每个用户给的这个prom x，然后不同的model会generate出不同的y，然后他们有请标注员去标注，为了保证质量，他们的engineering也进行了标注，他们标注了一个排序。

就是这个model产生的x比另外一个model产生的，这个model产生的y1比另外一个model产生的y2质量要高，那就是y1大于y2这样的一个排序标注，那回想我们刚才讨论的AI的实时的一个系统。

那我们刚才有说了一个非常重要的hypothesis，那这个hypothesis就是我们觉得用户最后修改过的提交的文本，是更有价值的是用户更想要的文本，相对于大元model最初产生的文本。

所以我们就浑然天成的运用了这个排序，所以我们的用户其实在为我们标注数据，而且我们的用户是专业训练过的用户，他们更了解他们的数据，那好我们谈到这个reward model之后，我们走到第三步。

第三步就是用reinforcement learning这种强化学习，去improve这个大元模型，我们可以看一下，他首先先给了一个prom x，这个时候这个policy就是通过强化学习。

训练过的一个中间量的一个大元模型，他比最初的大元模型稍微聪明一点点，然后呢他进行了一个generation，然后产生了一段话，然后产生完这段话之后，然后reward model对他进行一个评估。

然后评估完之后，根据他的output之后做一个backpropagation，然后去更新这个policy，所以我们看到reinforcement learning，顾名思义。

它不是一个supervised training，它不是一个监管的训练，所以在整个的训练当中的heavy lifting，是reward model的值。

所以reward model的质量是最至关重要的，回到刚才我们说的搭建一个实时的AI系统，所以我们的reward model的训练值，是我们客户使用的数据机，所以搭建实时的AI系统是非常重要的。

也是一个非常聪明的方式，去收集这样一个high quantity的data set，好那我们现在具体的讲一下，什么是reward model，那reward model通俗一点的去讲。

就像一个高考作文题一样，X就是prompt就是作文的题目，Y呢就是不同的考生写出的作文，那phi呢当parameter是phi的话，就是它的参数是phi的话，那我们就可以想象成不同的老师去评估这个作文。

所以reward model其实就是一个评估体系，它的输出就是一个评估体系，它可以简单成为一个人为的评估，就是一个老师当给定一个高考题目的时候，对一个学生的作文进行打分。

那我们讲一下就是reward model去怎么modeling它，那最简单的方法就是用一个encoder only的一个model，比如说Bort或者是Robot这种，把X和Yconcate在一起。

然后呢用COStoken上的embedding，做一个projection，然后呢产生了一个scala，所以这里很重要的一点，reward model的输出值是一个数。

就是比如说你的作文是一个98分97分这样的数，而不是一个向量，那openai呢他们用了一个decoder only，很类似啊就是X和Yconcate在一起。

然后用COStoken做了一个projection，然后输出了一个last layer，之后输出了一个scala，就reward model的值，那我们回顾我们刚才说了。

reward model它标注的数据集是一个排序的数据集，也就是说我们有说Y1大于Y2，这篇作文写的比那篇好，根据所给的题目，那去modeling这个的话，一个非常著名的一个非常常用的model呢。

就是BrediTariff model，它是一个概率的数据，概率的model，它往往就是predict，一个pair哪个更受喜欢，哪个质量更高，所以它的数学表达式呢，我们用pij，相当于Yi大于Yi。

Yi大于Yj的可能性，也就是说当给定一个高考作文Tx的时候，考生i写的作文比考生j写的作文好的一个概率，那它的数学公式是pij除以1-pij的log，等于这两篇评分的差，那我们把这个公式稍微转换一下。

我们就可以看到，pij这个概率，就是作文i好于作文j的概率，就相当于作文i的分数减去作文j的分数的一个函数，那么讲一下它的loss function。

那就是我们尽可能的当我们的标注是作文i比作文j的分高的时候，作文i好于作文j的时候，我们让这个概率尽量的大，所以非常简单也非常直观，好我们现在讲的是PPO。

reinforcement learning with human feedback里最重要的一点就是PPO，首先呢这是2017年OpenAI发表的一篇paper。

它在reinforcement learning中扮演了非常重要的角色，但是非常遗憾的是，至今没有一个任何一个大公司有开源。

他们的reinforcement learning with human feedback是怎么实现的，所以呢我们只能去猜，在这里呢我们有不持自己有implement这套系统。

而且我们确实得到了一个比初始SFT更好的policy，我们有进行评估，again我们的评估人就是我们的用户，我们用户确实的告诉我们，现在输出的结果是他们更想要的结果。

那好我们先讲一下最简单版本的reinforcement learning with human feedback，所以这个在这里有两个gauss，一个是clip一个是value。

那原始的OpenAI的paper呢还有一个entropy，instruct gpt呢还有另外一个term，但是我们有我们的implementation只有这两个term，我们发现结果会更好。

那是不是加上entropy和其他的gradient average会更好呢，我们不知道我们没有试，所以我们今天因为时间有限先讲这个简单的，那clip的定义，这个非常的复杂。

而且这是reinforcement learning，所以是强化学习跟我们大元模型关系不是很紧密，所以我今天先粗略的概括一下这里，如果大家感兴趣的话。

具体的公式需要重新回到2017年OpenAI的paper，具体的理解一下它是怎么样实施的，首先这里有两个变量和一个parameter参数，那变量是Aadvantage，然后还有变量Ratio。

然后参数呢是Epsilon，Epsilon在这里我们用的是0。2，我们follow了OpenAI2017年的paper用的0。2，那我们可以看到这是一个clip。

clip呢就是在Ratio是1的情况下是什么意思呢，就是我的policy更新之后，预测的每一个token的probability和以前的。

以前没有SFT的预测的每一个token的probability是相同的，那这个时候Ratio就是1，也就是说我的model没有更新，所以呢它这个clip就是相当于Advantage是正值的时候。

那我们的clip到1+Epsilon就是1。2，如果Advantage是负值的时候，那它clip之后是0。28，也就是说我让它的更新永远在一个范围内，不会过度的走得非常的狂野。

所以只在一个region内进行更新，这就是它这个clip loss的意义所在，那我们讲一下Ratio和Advantage，Advantage呢是reward value减去value。

然后reward呢和我们刚才调的reward还不是完全一样，我后面有讲具体reward的定义，那我现在讲一下value，value和reward的关系，那reward呢相当于就是一篇作文整体的分数。

那value呢就相当于每一个词输出的分数，所以我这篇文章洋洋洒洒，我里面有很多词是非常细节的描写，每个词都很优美，那这样的话我的value高我的reward也很高，但是我也有一种文章就是。

我的文章整个立意非常非常的标新，就是我的文章整个每一个字看着平淡如水，但是呢如果你去深挖的话，它这些平淡如水的文字联系在一起，却产生了非常深刻的意义，那这种文章呢它的reward可能很高。

但是它的value并不高，所以这个时候Advantage就是表达它们俩之间的差，但是Advantage具体的implementation要比这个复杂的很多。

这只是一个简化的概念上conceptual的一个理解，那如果想要真正去明白Advantage是怎么定义的，还需要走到2017年的那篇paper里，它有具体的定义。

我们的implementation有follow 2017年的paper，那像我刚才讲到的resell，resell就是相当于我现在这个policy相比较，起始的SFT到底做出了多大的变化。

那如果我变化非常大的话，那我resell就会非常的大，resell的绝对值会非常的大，那我几乎没有变化，那我resell就是1，好那我们现在回到这个DAR，这个DAR的reward是怎么定义的。

这个DAR呢是reward value，这个reward value就是我们刚才讲到的，给一个高考作文题，然后呢一篇作文的文章，然后被一个老师做出了评估得到的一个值。

然后第二个term就是KL divergence，那第二个term存在的意义是，PBO就是我当前的policy，然后reference就是SFT model，那我们往后退一步来讲，这是一个什么意思。

那pre-trade就相当于一个0到100的一个变化，那fine tuning就相当于一个10%的微调，那PBO其实相当于一个2%的一个微调，微微调所以我们叫它微微调，那在我们实施PBO的时候。

我们其实只有最后两层layer有进行更新，其他的layer我们全都freeze掉，也就是说它真的是一个微微调，所以这KL divergence的意思就是，我尽可能小的改变我的参数。

然后得到一个尽可能高的reward value，之所以这一项之所以KL divergence在这里，它存在的意义是，在很多时候AI是非常聪明的，它会学会怎么作弊，它有时候会写出非常非常不好的文字。

但是却拥有很高的reward的成绩，所以这个时候KL divergence就可以限制这种情况的出现，那我们在这里引用一个hugging face的图，当我们给出一个prime x的时候。

刚开始的model就是SFT，我们刚才提到的那一套parameter，然后PBO是一个微微调过的一点的一个model，像他所说的我们有freeze它的layers，然后这个时候它输出稍有变化。

不是很大的变化，这个时候我们进行每一个token level的probability的prediction，然后进行做它们俩的resource，然后根据resource去决定KL divergence。

然后加上我PBO出来的x的reward value，然后加在一起做gradient，然后再重新去更新我的PBO我的policy model，这就是整个一个PBO存在的意义。

好我们讲一下这个KL divergence，这也是一个很著名的一个公式，那就是model color approximation of KL divergence。

所以我们用的是probability ratio减去1，减去log probability ratio，所以这里不是用这里，这个公式也是2017年非常经典的一个公式，如果大家感兴趣的话。

可以回到最初始的reinforcement learning的paper里去找一下，好那我们现在讲一下这个value function。

就像我刚才说的value function就是对于一个每个字的评估，那reward是对于整个一段话或整个一篇文章的评估，那这个时候我们这个term的意义就是minimum square。

所以我们让每一个字更有价值，当我们的整个文章的价值固定，那举一个简单的例子啊，40分钟的脱口秀，那我们更想要的是在这40分钟的脱口秀中金句频出，而不是刚开始有一个5分钟非常高潮的段子。

然后后面30分钟非常包容让大家想睡觉，所以第一种情况是这个PPO model更想要的情况，所以呢我们加上这个variance，加上这个minimum square。

就是限制一篇文章它仅仅有个别字非常出彩，而整体非常无聊，所以它是想要每个字都很出彩，所以这就是整体的一个PPO，好那我们讲过技术，那我们回归到产品，我们大元模型的未来的展望。

然后想想我们大元模型能做什么，那这产品的角度呢，我想引用我们客户说过的一句话，现在的generative AI只是一个point solution，我们真正要搭建的是一个平台。

那这回到我们刚才讲过的一个例子，就是客服的例子，那当大元模型决定我们的decision是，我们不可以推款，因为你已经超过60天，但是呢我可以给你一个代金券，你可以下次使用，当大元模型做出这个决定的时候。

它不仅仅给客服这样的一个指令，让客服去把它传达给消费者，而它同时呢可以医术这个refund，同时呢可以给消费者发邮件，这样的话客服其实什么都不需要做，他只需要坐在那里去读大元模型，告诉他要怎样做。

然后大元模型会给他采取所有的follow up options，那这样呢才能更有效地节省人类的时间，更有效地代替人类，那我们再举一个日常生活中的例子啊，比如说我开一个会，然后我这个会呢大概是一个小时。

我和我的engineers在一起讨论，我们下一个月要做什么，主要focus在什么领域，那大元模型呢有聆听我们这一个小时的会议，然后它呢写出了会议的章程，但是呢，但是现在的大元模型只到这一步。

包括微软它的teams，它现在只能写到会议，但是呢真正有意义的事情是，我赛给我每一个队员，我每一个engineer，一个calendar，那我两个星期之后呢，要和他们在一起重新meet。

然后去看一下有没有完成这些任务，然后赛给他们新的任务，甚至大元模型在有朝一日，可以代替我的engineer去完成这些任务，这就是大元模型，对今后的一个生活的一个改变，所以它更是一个平台，一个生态系统。

而不仅仅是一个文本的输出，大家有什么问题吗，好，那再次感谢殷涵女士，然后给大家带来的这个报告，其实就是RLHF应该说是OpenAI，然后这个ChatGPT引入的，一个非常重要的去改善它的这个。

包括这个follow我们人类的伦理，等等的这么一个技术，那么殷涵女士的这个报告呢，其实可以让大家看到，它能够在行业的这个应用中，然后其实也能够非常好的，去把这个用户的一些反馈的信息，能够考虑进来。

那其实是具有非常好的这个insight，那我们接下来应该还有几分钟的时间，那我们接下来要不看现场，大家对这个报告有什么问题，然后我们可以进行一个交流，那我们就请我们的工作人员，这边。

我认为现在NLP的底层的技术，还没有突破，我觉得就是东方文明的，最底层的应该是基于语意类的，而西方文明的底层应该是基于一种神学，所以我觉得东方文明的底层，如果它能够真正做出来的最终的NLP的。

就是语言类的这种产品，它应该能够更好的，获取我们人类心底的那种答案，所以你的问题是什么，还是你是一个简单的comments，这个是我一个是我的个人看法，然后我是觉得。

这个如果NLP的底层技术出现以后的话，我觉得大模型一定是专用的，好，那谢谢你的反馈，那我另外一个，一寒你好，我有一个技术上的一个问题。

就是reinforcement learning by human feedback，这边这边，你好你好，你讲得非常精彩。

我想说的是reinforcement learning by human feedback，是fine tune的一种option，然后但是其他的option，比如说prompt turning。

比如说通过这种高参数微调，parameter efficiency fine turning，就是我们在商业场景里面，想要improve这个LM的performance。

那就是我什么时候选择用reinforce，by human feedback，什么时候选择用其他的这种turning的option，就有什么建议吗，谢谢，好。

prompt tuning是它不会改变你的model，你deployed model的parameter不会被改变，但是reinforcement learning会更新一个policy。

这个policy会取代原有的SFT，然后进行改变，而且像我们产生的例子，其实客户不会去try不同的prompt，尤其对企业用户，客户一般不会去try一个不同的prompt。

这个prompt是一个fixed的，所以说更新用reinforcement learning，更新PBO用PBO policy，然后去更新这个model的weights，是一个一劳永逸的方法。

我稍微想要交流一下，刚才这个问题我觉得挺有意思的，在我来看，RLHF也好还是SFT也好，其实它主要是一种任务，相当于它希望把某一个目的来达到，而parameter efficient learning。

它其实更多的是一种技术，是不是RLHF，其实也可以把它学到，在parameter efficient tuning的，这么一个小的参数里面，是可以的吗，有这个可能性，OK 好，我就稍微澄清一下这个问题。

好 我们应该还有，还可以，前排，您好，我有个问题，刚刚我们在您举的例子当中，就是关于客服，它可能选择回复作为更好的吗，就您认为这个是一个更好的天然例子，我的问题其实是说。

假如我们现在已经有一个SFT的model，然后利用这种天然的数据，去进行强化学习，这个过程，强化学习得到的模型，相比于SFT这个模型，它的提升有多大，以及第二个问题就是说，其实可以直接取客服。

直接发送的文本去进行SFT吗，然后我理解可能，如果要再去用强化学习，去提升最终我们大模型的效果的话，可能是不是这个过程中，强化学习所需要的这个数据，可能还需要再次的，二次的人工的标注去提升一下。

首先这个问题很好，然后这个问题我恰好也有答案，因为我们有特别的关注这一点，Reinforcement Learning with Human Feedback，相当于是临门一脚。

就是说SFT到达一个范围内，它其实是上不去的，但是这个Reinforcement Learning，恰好能把它提高一个很小的微调，去能把它完全更好的满足客户的需求，这是一点，然后既然你已经提到。

我们这个产品中的应用，那么回到我们产品当中，其实人是一个很多变性的，就是说他刚开始有看到，这个SFT的一个output，那其实他的思想是在改变的，就比如说你想说一句话，但是你看到大屏幕上打出一句话。

那你的思想其实比你，刚开始想说这句话的时候，是有所微调的，有所改变的，所以说在这种情况下，当我们的这个SFT有输出的时候，人看到这句话的时候，他会人和机器会共存的converge，所以说这样的话。

人出来的结果，反而其实是更有效的，能帮助reinforcement，with human feedback，绣给人一个更好的model，谢谢，然后这个除此之外，还有另一个就是您刚刚提的这个过程中。

其实就是包括您刚刚讲的那过程中，就说大模型可能不太会理解，就是他说降价了，但是其实他可能背后的意思，可能想退款，或者是补一些差价，这种类似的东西，其实我在想是不是说历史的一些过程中。

就是历史天然的客服跟用户的对话过程中，因为他们肯定也存在这种，补差价这种行为，所以可能是否SFT这个阶段就已经足够，或者说换一个换种方式来说，就是强化学习提升的那个点，就是您刚刚说的提升非常微小。

那个点它究竟是指在哪一个点，或者说它是更容易被客服选择吗，还是什么样，首先我们deploy的model，就是一个已经是SFT的model，而不是一个原始的model，就是你客户看到的这个推荐。

这个intern的model，包括你说的已经是一个SFT的model，它是处于在过去一年的客服的信息上，所以我的理解就是，其实根据用户的反馈，你到底是学到SFT还是学用IHF。

其实取决于你的这个反馈的这个形式是吗，对，我做一个具体一个小小的一个background，就是说在before deployment之前，我们有一年的history的data。

然后一年的history的data，我们已经trade了一个SFT的model，那我们把这个SFTmodel，initially deploy到这个AI，实时性的AI产品当中，然后呢进行进行进。

对它进行监管，实时的收集客户到底是怎么样的feedback，然后三个月之后呢，我们trade了一个新的PPOmodel，去取代之前的一个SFT的model，然后也就是说，这三个月的时间。

其实就是收集human feedback，所以它initial model，其实就已经是SFT的model，而不是pre-trade的model，好，那个抱歉，由于那个时间的关系啊。

那我们这个QA这个环节就先到这儿，然后我们后面还会有一个圆桌的讨论的环节，咱们可以到那个地方，再跟我们的这个特邀讲者再做交流，那我们再次以掌声，然后欢迎这个感谢啊，英海女士，好。

那我们就接下来进入到下一个报告，那么特邀讲者是来自于中科院自动化所的研究员，刘静老师，那么刘静老师，我其他的背景的信息就不多做介绍，那么她是我们国内啊，这个多模态大模型，这个叫子冬态初的主要作者。

那么大家也应该知道，就是在国内，我理解子冬态初应该是最早的，这个跨三模态的这么一个，这么一个大模型，那么也有非常深远的这个影响力，那么接下来我们就有请刘静老师来给我们带来多模态的相关的介绍，大家欢迎。

非常非常感谢刘老师，还有志愿的邀请，让我能站在这里给大家分享，我们在多模态多模态域训练模型相关的一些，我们做了一些一点点的工作，以及我，我们这个团队对这个方向的一些认识和一些思考，我现在开始。

我今天报告其实主要想带大家去看，因为多模态域训练现在越来越被大家关注，所以我今天报告主要分为以下三方面来展开，首先来介绍一下就是多模态，就我们为什么要去关注多模态域训练，然后讲一下这个多模态域训练。

当前大家都是怎么做的，就是从其实这个方向并没有太久的，这样基本上在19年底开始到现在，其实也就不过有三年多的研究时间，整个学界都是这样一个研究，就这样一个三年多的这样一个研究历程。

所以我给大家来带着回顾一下，然后接下来就是说会讲一下未来怎么做，首先一个大背景就是说我们知道在过去的十多年，其实以深度学习为核心的这样一个人工智能技术，已经渗透到了我们各行各业。

我们可以看到无论是人脸车辆识别，确实已经服务到我们的大众生活中，但是其实也让我们越来越看到，其实AI的落地应用已经遇到了它的一个应用瓶颈，可以表现在说传统的AI技术落地，都需要大量的人工标注数据。

然后需要针对特定的场景进行定制化的开发，其实大模型就是在这样一个背景下，然后被提出来的，那么大模型其实被我们认为是最有望突破上面说的，这种应用瓶颈的一个技术，那么大模型其实它开启了。

我们所谓说大数据大模型的这种新范式，然后让我们可以从这种大规模的无监督数据中，去挖掘信息来进行模型的学习，那么简单来看，其实我觉得大模型技术跟传统的，或者说跟过去十多年的AI技术相比。

我觉得主要有三点不同，首先就是从原有的这种基于全监督的这样的一个，基于这种有限人工标注样本的全监督学习，转变为这种基于大规模无标注训练样本的自监督学习，因为我可以去做这种不需要依赖于人工标注。

因此我就有大量的数据可以用于模型的学习，因此我就可以学习更大规模，具有更大参数的这样的一个模型，因此我们的模型规模也从专用的小模型，走向了这样一个具有通用和泛化能力的大模型的研发。

那么在接下来就Chad GP出现，就从去年底Chad GP出现之后，让我们更多的看到了大模型，从基本的这样一个数据驱动的方式，又进一步去走向了这种人机交互的学习，去使得大模型的这样一个能力。

更好的去跟人类的意图对齐，成为一个与人类意图对齐的这样一个基础性模型，那么也确实在过去的三五年中，确实我们可以看到，无论是学界还是企业界都有非常非常多的人，涌入到这样一个大模型的研发赛道。

基本的方式就是让我们看到，大家通过不断的去增大数据的规模，不断去增加模型的参数规模，然后也让我们见证到了在这样一个语言语音视觉，这样一个通用领域，以及像无人车呀生物医药等等这样的专用领域。

都带来了这样性能的非常显著的提升，当然也出现了像Chad GPT啊Dell E这样，非常引人关注的这样一些大模型的应用，所以我觉得这个特别Chad GPT啊，我觉得Chad GPT真的是将大模型技术。

引入到了大众的这样的眼中，让我们全民都在关注大模型，那么下面用两页PP来简单的介绍一下Chad GPT，Chad GPT是什么，它实际上它本质是一个基于这样一个大语言模型，然后通过这种人类反馈学习。

然后得到了这样的一个对话生成大模型，但它已经不是简单的像小兵啊，像我们说的Cereal这样的一个简单的闲聊机器人，而它是让我们感触到可以用自然语言，作为AI交互的这样的一个新的语言处理平台。

所以我觉得可能这就是它更强的这样一个画实在的意义，那它也带给我们非常强的这样一个交互体验，表现在比如说它具有非常通用的意图理解，就是说你在跟它聊天的过程中，你会发现它特别懂你，不管我问什么它都知道。

还有强大的这种连续对话能力，它的token数从GPT到GPT2， GPT3到GPT4，其实它的token长度也是在不断的增长，从2000，8000，一直到1万。

那么token序列的增强就大大提升了它连续对话的能力，以及智能交互修正能力，还有较强的逻辑推理能力等等，这样对话我们见证到了说Chad GPT很强，它具有类人的智能。

也被我们认为说Chad GPT可能是未来，已经开启了通用人工智能的这样一个大门，也因此才得到了大家对它如此的关注，那我们来看Chad GPT，其实它并不是一个简单的技术的创新。

它更多的是一个众多技术和成果及大成者的，更多的我们可以认为它是一个产品级的创新，它的核心实际上就是大模型技术，或者说自监督学习技术和人类反馈强化学习技术的一个融合。

让我们实现了这种AI能力跟人类的这样一个意图对齐的这样一个展示，那我们就来看回到我们今天的主题，就是OpenAI其实从公司成立之初，他们就是要走向这种通用AI，那么其实可以在这条路上。

最终它的终点其实走向了这个GPT思维代表了多模态对话大模型，因此也就回到了我今天的报告的主题，就是我们觉得其实大模型从单模态迈向多模态将是一种必然，除了说我觉得可能现在业内越来越形成这样的一种共识。

那么我们是怎么来分析这个，就包括我们所在开发子动态处的时候，我们一开始的定位就是我们要去做图文音，做这样的多模态的大模型，那其实我们的考虑有两点，一方面就是我们的数据，就是多模态数据是无处不在的。

我们知道我们手机上我们的电脑上，其实我们大量的信息，包括每天浏览的网页，都是这样的大量的都是一种多模态信息存在的这样一种形式，那再一块就是说我们知道ChadGBT它实际上是个语言大模型。

那实际上我们人类由文字记载的历史，其实只有5000多年的历史，但是我人类的历史，整个人出现人的历史，其实有300多万年前，那也就是说在5000多年之前的这样一个人类存在过程中，实际上人类没有文字。

照样可以去交流，可以去表达，也就是说我们人类其实更多的表达方式，或更常用的表达方式，就是通过我们的，就是通过我们的这种，通过我们的去看去听去想，然后通过一样的这样一种，不一定用文字记载。

用口语用一种语言的这种方式去来表达出来的，那因此我们觉得我们大模型去解决什么，我们就是要解决通用文案，我们去希望实现类人的这样的一个认知能力，因此我觉得我们从这样点，我们认为大模型要从单模态走向多模态。

要像人一样去听去看去想去看我们周围的世界，正因为这样，所以我们其实一直在，从这个大模型开始入手之期，也就是从19年底我们开始就着手于去做多模态大模型，那接下来我会对这个多模态大模型，我刚才说过嘛。

基本上从19年底，就这个整个学界或企业才开始研究多模态大模型，所以我会接下来用企业PPT来回顾一下，多模态大模型这个领域，大家都在大概是怎么做的，就开始又是怎么来研究这个问题的。

那么首先我们来看多模态域训练要解决什么问题，那它既然是一个大模型技术，那我觉得它首先要具备最基本的，就是大模型需要具有这种强大的自监督学习，会有通用知识迁移能力，有时候我们对大模型最希望它具备的能力。

就是具备这样一个通用范化这样的一个能力，那我觉得一个多模态域训练也是同样需要的，那么作为多模态域训练它特有的东西，我觉得就要更多的去关注多模态的融合表征，以及模态之间的这样一种转化或者说语音关联。

而更好的去服务于多模态融合理解，和跨模态转化生成这样的一些下游任务，那我们来看就是我们来分析说，大家在怎么做这个领域的时候，首先我觉得我们来看一下整个域训练模型，到底它有哪些核心的这样的一些模块。

那我们知道就做域训练的人，做大模型都知道，其实它有核心的两个阶段对吧，一个是域训练阶段，一个是模型微调阶段，那么在域训练阶段，其实我们最希望模型去学习的，就是要去针对这样的大规模的无标注样。

本通过设计合理的自监督学习算法，然后来实现使模型具备这种与任务无关的，这种通用知识，这是我域训练模型的目标，那因此在域训练模型里面，其实我们最需要关注的就是，我们的训练数据是什么样子的。

我们的模型架构是什么样子的，那现在模型架构，所有大模型基本上都是一transformer，作为一个积木块，然后堆起了一个大楼对吧，那么再一块就是学习机制是怎样的，有了数据有了模型。

我们的用什么样的学习机制，那么再一个就是有，有了这样的域训练模型，那么接下来怎么更好的服务于下游应用，这就会涉及到模型的这种下游，我们也叫模型微调，以及下游任务适配等等这样的方面的研究。

接下来我也会针对这样的四个模块来展开，对多模态域训练方面的一个回顾，那首先讲一下多模态域训练数据集，这个可能和文本不一样的，就是我们知道文本，虽然文本质量也没有说想象的那么理想。

但是其实相对多模态数据集来说，它其实要干净的很多了，因为毕竟所有的文本语调都是人来编辑的，是文字本来就是人类用来记录知识的，这样的一个符号，而多模态其实就不一样了，多模态我们都获取。

它需要现在的获取途径，基本上都互联网上去爬取对吧，比如说图文数据，那我爬取的方式就是要去网页上爬取图片，以及图片的相关文本信息，作为它的文字描述这样一个过程，那其实我们知道在这个爬取的过程中。

其实图文之间的关联是非常弱的，它的噪音也是非常大的，这也是我们在多模态域训练里面，其实大家不得不考虑的一个问题，那么我除了去做图文的数据，我还可以做这种视频和文本的数据，以及说做音频文本的数据。

就是任意两种模态或任意一种模态的数据，其实都可以服务于我多模态域训练模型的训练，那么这边实际上这里给出了，就是我们现在所有能开源拿得到的，这样一个多模态域训练数据集，基本上上面这一行的话就是图像的。

上面这一行就是图文数据，下面这一行就是视频文本数据，现在业内基本上我觉得作为学界，其实这样一个数据就完全是够用的，那作为企业界的话，基本上也是用这些数据打底。

然后再加上自己企业的自由数据来去做对应的研发的，但我觉得这个其实基本上已经可以，就现在能拿到的多模态数据集，其实已经到了这样一个几十亿的规模，数据量是非常大的，但这个数据的噪音也是非常大的。

所以怎么能把这么大数据，这么大规模并且是弱关联的数据能用好，可能也是多模态域训练这个领域，非常需要值得去关注的一个，那么再一块就是我们刚才说Transformer模型，我觉得现在所有的大模型技术。

其实都是在用Transformer，那Transformer其实从它2017年提出来到现在，其实大家一直在用它的最基本的架构，因为我们可以看到Transformer这个基本架构。

实际上有两块最核心的东西，一个就是Transformer的encoder部分，一个就是decoder部分，那现在所有的在多模态领域，其实也可以看到，大家搭出来的模型架构。

无非也就是说要么是基于它的编码器，要么是基于解码器，以及编解码结构相融合的这样的一种架构，去来设计我的多模态域训练大模型的一个基础模型，那我们知道就这两大类，一类我们说是这种编码器。

encoder这种架构，其实我觉得在最早学这些，其实在做多模态域训练的时候，基本上都是在关注encoder，也就是说多模态最初的任务，更多的是在做一些分析理解任务。

而做基于这种BERT为主的这样的一个encoder架构，可能更适合来做理解任务，所以早期的一些工作都是基于BERT的，那当然可能我们觉得未来再看，可能大家更多的会采用这样的一个生成式模型。

或者说是采用encoder加decoder这种架构，去来更好的去实现，在对多模态特征理解的基础上，再进一步进行生成，来去做多任务的这样一个泛化能力，那我们来简单来回顾一下，其实这几篇工作。

这基本上都代表了，就是在多模态域训练这个领域，最开始的几个这样的工作，可以看到它发表年份都在2020年，但出来基本上都在2019年出来的工作，那么这几个工作其实非常简单。

它基本上就是套用了BERT的架构，然后把BERT这个纯文本的模型，然后相当于把它输入到，用各个模态也去做不同的token化，然后来进行了这样模型的输入，那么简单来看采用编码器的结构，还有分为两大类。

一类我们叫单流模型，也叫单塔模型，或者是双塔模型，也叫这种双流模型，那么比如clip模型，就是我们最常见的双塔模型，那么其实这两类模型，我觉得它各有它的优势，尤其在多模态，因为其实我们做多模态。

我们刚才说过，我们更重要的就是要解决，模态之间的关联，那我们去设计，无论是设计单流还是双流，其实都是希望去更好的建模，模态之间的这种关联，那么单流网络实际上你可以看到，它在网络的最底层。

它就相当于是图文信息，实际上我是一起，token化之后输入到同一个transformer，输入到同一个encoder上去的，那么也就是说，它可以通过transformer。

去做token级别的这种不同模态的关联，那因此在建立模态关联之间的话，它的力度将会更加精细，而可以看到clip模型，实际上它只是在最顶层，通过这样一个对比学习的损失，然后来实现了不同模态的关联。

那么也就是说，它的关联对力度上来讲的话，相比单塔模型肯定是要粗一些，那它的优势就在于说，它可以去离线的对文本和对音的，或对音的图像去做离线的编码，那么可能在一些检索任务上。

或者说大家纯粹用它的视觉编码上，可能它就有更大的优势，所以大家可以在针对不同的应用，去选择不同的这样的结构，那再一类就是这种decoder的结构，包括咱们最早支援这边做的conquerview。

其实就是采用了这样一个decoder的方式，来实现了图像以文生图这样的任务，早期其实做以文生图都是基于，这样的一个decoder的架构，那么现在可能更多的是用扩散模型。

那无论像conquerview也好，大约也好，其实它基本上都是采用了，当时基本上都是基于GPT的这样一个架构，然后相当于把图像进行了这样的一个量化编码，然后对应成这些码字，然后相当于和文字一样。

去输入到这个生成式模型，然后再去生成对应的码字，然后从码字再重构回原来的图像空间，实现了这样的一个图像的这样的一个生成方式，刚才有了编码有了解码，很容易想到就是我可以去做encoder加decoder。

就是采用类似于像这样的一个像transformer，最基础的这样一种架构的方式，那么它的decoder加入主要是因为，我现在图像很多就比如大家知道，就很多任务其实最终都可以归结成。

是一个用文本来表述的任务，就是我无论是caption也好，QA也好实际上我输入图像，我最终都可以用文本来表达，那么其实它一般都会接一个文本的decoder。

因为所以大家会采用这种encoder加decoder的架构，那这种架构其实又分为两大类，一类就像transformer一样，就可以理解成是一个encoder和decoder串行的结构。

就是把encoder的输出通过一个交叉注意力，然后接到decoder上，那么再一类方式可以理解就是encoder和decoder，是类似于是并行的一个结构。

就是encoder和decoder可以共享同一个transformer，通过多任务的学习，实现了这样一个encoder和decoder的同时编码能力，那么再一块就是刚刚前面我们讲了数据，然后讲了模型。

那我觉得可能另外一个重要的环节，就是怎么来去优化这样的模型，那么就需要去设计合理的自监督学习的这样一个算法，去来更好的去建模所谓的跨模态的这样一种关联，那么现在基本上我觉得，就是业内能想象到的这样一个。

或者大家用到的这种自监督学习范式，实际上应该基本上就是我这里面归出来的这样几大类，一类就是通过研码学习，像BERT一样的这种研码方式，我可以去做，首先是模态内部的，就像BERT一样，就是我可以去研码出。

在任意一种模态内部去做，自己模态内部的这样一个研码，然后去构建这种模态的这样的一种上下文特征的表征，那么再一种就是做模态间的研码，就是说我可以通过Mask，比如Mask文本，然后通过视频。

通过它的视觉信息来去把它的文本去做一侧，这样就通过这样的一种研码学习，去建立不同模态之间的关联，那么再一类我们叫模态间的匹配学习，这个也比较容易理解，就是我们说自监督学习，其实我更认为它是一种有监督。

但它的监督信息不是来源于人工标注，而是来源于说我从我的数据中去挖掘潜在的这样的监督信息来进行学习，那么匹配学习其实一个最典型，它其实比如说，我既然我不知道什么是正样本复样本。

那其实我可以自己去找自己的正样本，对吧，比如图像我可以做各种变化之后，我当前图像做各种变化，它仍然作为我的正样本，那其他样本就作为复样本，这是我们的模态视觉内部的这样的一种匹配学习，那如果模态间的。

那其实也比较好理解，比如说我有一个图文匹配对，那任意不匹配的，那就是它的复样本，然后来进行对应的学习，那么匹配学习又分为两大类，一类就是我通过正复样本，然后通过二分类的方式来实现，那么再一类呢。

就是通过这种对比学习的方式，来实现这种模态间的匹配，那么有了，那接下来前面就通过大规模的数据，然后通过基于这种transformer架构的基础模型，再通过这样的一个自监督学习。

使这样的一个模型具备了非常好的通用性，以及模态之间的这种关联能力，那么接下来其实我们大模型最终要能服务于应用，其实我们更重要的环节就是要去做模型的适配与微调，那这个环节其实我觉得研究又分为几方面。

一个就是要怎么合理的让模型去迁移，或者适配我对标的下游任务，那么这里面的研究方式，我觉得又分为几个阶段，从最早期的大家去基于这样的一个pro-tune+fan-tune。

也就是说我通过我下游任务的这样的一个，全监督的少量样本的这种监督学习，然后来实现这样的一个全参数的微调，那么随着模型规模越来越大，对吧如果百亿千亿万亿，那我其实在少量的这样的下游任务数据上。

其实已经很难全参数去微调这样的模型，那因此业内大家就想怎么能够去更高效，更低代价的去微调这样的模型，就变为非常重要的一个方向，那因此业内又不断的去提出包括pro-tune，包括这种适配器的方法。

以及现在这种拉腕的方法，其实都希望去实现这种低代价的，这样的一种增量式的微调，希望模型在微调的过程中，既不要忘记它大模型该具备的能力，同时又能够很好的去适配下游任务，然后去实现这种增量的学习。

那么再一块其实我觉得多模台，在多模台这个下游任务里面，其实它的下游任务，其实可想象的空间也是非常大的，因为其实我们除了图文，其实我们还可以不断的去泛化，我们的模台形式，那实际上这种不同模台的组合。

就会组合成不同的这种下游任务，那因此我们可以去想象，怎么去让我们有了这样一个，多模台的基础模型之后，我们怎么去更好的去想象出，更好的可能的这种下游任务，使得我的模型更好的去对它服务，那么简单来理解。

其实所有的下游任务都是生成类，和理解类两大类对吧，那么生成类实际上，又包括这种文本的生成，语音的生成，视觉的生成等等，那么理解类任务主要是说，我们相当于是语意的这种理解，怎么去做问答，怎么去做推理。

那其实我们可以，围绕这样的生成和理解两大类，去来设计我们合理的，这样的一些下游任务，使得我大模型，能更好的去赋能于不同的应用，那么在这个研究过程中，除了下面在几个基本环节里面。

大家去做各种各样的创新的算法，那我觉得其实要，既然是大模型，其实我觉得在这个里面，大家其实怎么去把一个模型堆大，做强，那可能是大家一直在努力的方向，这里其实列出了几个，业内典型的这样一个大模型。

那他们其实基本上，都是通过几个方向，去来做大模型，怎么去把模型做大，比如说怎么把参数量堆大，其实大家无非的努力方向，一个就是用更强大的，这样一个语言模型，比如现在可能未来，可能让我们能看到的就是。

以大语言模型为基准的，以为核心的这样的一个多模态模型，可能会成为一个非常重要的，一种研究范式，那再一个就是怎么去，更大的这样的视觉模型，或更大的音频模型，就是更大的单模态模型，怎么去做大。

那其实至少因为，我觉得在文本里面，可能不存在，这个语语鸿沟的问题，但是在视觉和音频里面，其实语语鸿沟一直是，是大家一直，几十年大家都在解决的一个问题，到现在也没有把它解决好，因此我就是说，这种单模态。

就是像视觉，视觉这种音频，其实是需要强大的，这样的一个单模态的encoder，去来帮助它去跨越鸿沟，所以怎么去建立，这样一个更好的，这种单模态的这种编码，其实也是非常重要的，那再一个就是说。

用更多的数据对吧，其实现在可能大家，我去一些大厂，可能更多的去，怎么来比拼数据，也是很重要的，一方面数据规模要大，另外一方面数据的质量也要高，那再一个就是像这个，更多模态形式的数据，除了图文音。

其实我们可以泛化到说，去做红外，去做雷达，去做等等，去做听觉，去做触觉等等，也就是说，我通过更多模态的信息，是不是可以带来，整个能力的这样一个涌现，这边右边，其实我给出了这样一个图，就是用一个。

多模态一个典型的下游任务，叫视觉问答任务，那这个任务的设置是说，我给定一幅图片，然后我用文本提一个问题，然后让你用文本去做作答，那么因此，这是大家来验证，多模态预训练模型的，一个基础能力。

大家最常用的这样的一个，最常用的这种下游任务，我们其实通过右边的，这样一个曲线，可以看到就是，这个红色部分，就是在预训练模型之前，大家的一些研究的性能，其实我本人，其实也是从14 15年那时候。

我们就在做，维仁贾兰规制的，这样的一些任务，就那个时候，其实我们感觉这个方向，已经做不动了，但是其实你可以看到，蓝线部分，就是说在预训练模型，出来之后，大家那个时候，其实只需要把问题，就是问题部分。

就是因为是文本输入，只要把问题部分，替代成是BERT，我用BERT去替代一下，我都会发现性能，就会做一个，非常强的提升，再通过去把问题和图像，去做简单的这样的一个，多模态的这样的一个，关联建模。

会发现性能，会得到进一步的提升，也就是说蓝线部分，基本上是基于，BERT架构的一些，相对规模比较小的，这样的一些，多模态预训练模型的方法，来在可以看到，在VQE这个任务上的，性能提升。

那再进一步去到绿色的，这样一个曲线，那其实这基本上都是，就是大模型，通过堆更大的，用更多的数据，然后去来见证说，VQE能力的提升，可以看到它已经，现在可以做到很好了，但不管怎样，这条线上的曲线，就是说。

其实在Chad GPT，出来之前，包括我自己，其实也认为，多模态预训练这个领域，想ZeroShot很难，就是因为感觉，刚刚刚才说的，就是这个领域的数据，很这个领域的数据，是非常非常非常，非常非常厚的。

所以我觉得，其实在这个领域，就像刚才说的，就这个领域的数据很，这个数据很脏，就是数据可能，比如我从互联网上爬，可能连10%的数据，最后都保留不了，那我保留下来的10%，也很难保证，它的质量就是特别高。

有时候它数据很脏，而且它的任务很难，所以那个时候，我一直觉得，在这个领域里面，可能想不微调，去比拼性能很难，所以大家基本上，在这条线上的发展，基本上都是拿，都是拿微调任务的，但是我们可以看到，那个红星。

也就是GPT-4，GPT-4出来之后，可以让我们看到，当把语言模型做得非常强，就当我们以GPT-4为核心，去来再去重新解读，这个VQ这个任务的时候，它的自由效率能力，就已经就相当于，已经超过了所有的。

这样一个蓝线的，这样一个区域，因此我觉得，拆的GPT可能对，未来的这个多模态领域，就提出了一个，更大的挑战，可能大家未来再去做，多模态域训练的时候，我相信都应该是，在自由效率的能力下，去做比拼，对吧。

因为我有了这样的一个，就可以站在，这个非常强大的，语言模型的肩膀上，去来做这个事情，所以我觉得，未来的能力将会变得更强，泛化性也会变得更强，接下来我会用GPT来，介绍一下我们自己的工作，这个其实。

我觉得业内更多的，做多模态的模型，基本上都在做图文，这样的一个，都在做图文多模态模型，那我们所其实从，从2020年启动，这个项目开始，我们就一直瞄准，要做图文音，因为我们人，其实我们不光有眼睛。

我们也有眼睛，我们的眼睛，是一个非常重要的，一个东西，所以其实，我们不光有眼睛，我们还有耳朵，对吧，我们需要去听，需要去看，我们才能去，我们一个健全的人，对世界的认知，和一个这种，有残缺的人的理智。

肯定是不一样的，所以我们觉得，要去构建这种，图文音的大模型，那么其实做这个领域，其实我觉得，就是当然，我们在数据上，和在模型上，都做了非常多的工作，因为毕竟图文，图文就很难了，图文音关联的数据。

可能收集起来，代价就会更高，所以我们其实也是，我们可能近期会发布一个，这种千万级规模的，图文音多模态数据集，而且我们的音，不简单的是，现在大家意味着，理解的speech，我们还会把声音。

就整个我们的世界的声音，都会收集进来，然后speech去来，去做这样的更好的理解，然后我们的模型，就我们有了这样的一个，在图文音这样的一个大模型，三模态大模型，那种加持下，我们其实可以看到。

我们在这种传统的，这种任意量模态的任务上，也去得到了更好的性能，无论是在图文，文音，或者是视频理解任务上，我们通过去加持，这样的图文音，三模态的关联建模，我们的性能都可以刷到当前，就在现在已经在。

20多个这样的下游任务上，都已经刷到了，SOTA的性能，那我们其实，这个工作我们，基于我们大模型，也拿到了很多竞赛的奖，以及国际的这种奖项，那另外其实我们觉得，就刚刚我刚才说，我觉得未来的大模型。

肯定是要以语言，大模型为核心，然后来实现多模态的融合，多模态的融合感知，与多任务的统一，我们也其实也做了，这样的一个工作，希望说能够去，以语言为中心，然后将各种模态，都对齐到语言上，然后更好的。

让大家用语言的方式，来去接触，来去感受到这种，多模态AI的，这样的一个能力，我们也提供了一些功能，就是我们既可以来做，这样的一些围绕视频，去做一些细腻度的问答，就比如说可以去，我不单可以去问视频。

简单给一个标题，我还可以对视频里面的内容，去做更细腻度的，这样的一些了解，比如说我可以问，这视频里面，能播视频是吗，就这样吧，我们可以去问，里面的声音是什么，以及我可以问，里面的声音出现在。

具体的视频的什么位置，我还可以去围绕，里面的声音，或者是里面的这种，运动的主体，然后去来做对应的提问，那么同时我们，可以用对话的方式，去来做这样的一个视频，或者图像的这种生成编辑，其实我还可以做一些。

非常有意思的工作，就比如说我可以，给定一幅图片，给定一个声音，然后我可以去围绕，这个图片和声音，然后去来做一些能力的，这样去做一些问答，比如像这样的场景，我给他一个两个小孩，踢球的这样一个场景。

同时给他一个欢呼和掌声，我会问他，你可以去分析一下，结合图片声音，分析一下场景的氛围，是怎么样的，我还可以去给他，一个图书馆的图片，就给他这样一种场景，给他一个气体鸣鼎师，我可以去问他。

这个声音会不会出现在，这种场景下，他都会基于这样，语言模型的，这样一个认知能力，然后来对这种多模态信息，去做更强的这样一个，理解和分析，我们还可以去比较，两个视频里面的，共同点是什么，然后可以共同点。

或者它的差异是什么，比如说这个是，报表视频是吧，比如说其实像我们这边，右边的视频里面可能就是，这下面是两个视频，右边的视频可能是，一个车在快速地移动，然后左边是快速地移动，右边实际上是慢速移动。

其实他可以通过，对这两个视频的细腻度理解，可以来做这种深度的，这样的分析，我们同时还可以去写故事，就是我们不单可以看图写画，我们还可以给你一幅图片，给你一个声音，同时给你一个视频，最右边其实是个视频。

其实我可以让他去，这样一个多模特的，这样一个对不同模特的，这样一个理解，然后去通过，它的一个语言的，这样的一个组织能力，然后来给大家去讲一段，流畅的故事，也就是说其实我们当有了，不同模特的信息。

通过构建了这种图文音的，这样的一种深层次，细腻度的关联之后，其实我可延伸出来的，多模特应用，其实非常丰富，同时我们这个模型，其实我们不单算法上，数据上，我们都做了非常多的工作，同时我们作为。

大模型的这样，做中科院，中科院为背景，这样的一个国家，对其实我们也希望，把我们的大模型，能够做到这种，全站的国产化部署，那我们现在目前，已经可以在这个，华为的生腾平台，以及像曙光，这样的一些硬件平台上。

都去可以做到，这个全面的这样的一个，模型的训练，然后推理和部署，那么同时，我们的这个太初大模型，也在很多领域，得到了一些推广的应用，最后讲一下，就是我说多模太医，训练模型的几点思考吧，就是以后该怎么做。

那首先我觉得，按照我们刚才说的这个，对我们知道，大数据大模型，虽然很简单粗暴，但是至少我觉得，肯定还是一条有效的路，对吧，未来肯定就至少，现在我们还没有看到尽头，就是通过堆数据，堆模型。

我们还是可以性能，得到进一步的提升，但我们想这条路肯定，并不是适合所有的人来走，特别是我们作为学界，来去做这个问题的时候，一味的去追大，肯定不是我们能，不是我们的长处，所以我觉得我们怎么能去。

通过另外一个方向，去把它做精，才能做到性能更好，那我觉得从数据上来讲的话，我们如果做不大，那我们就要把质量做高，就像刚才我们说的，就是多模太，多模太的数据，其实是非常脏的，就是我如果能够。

你如果有非常好的方法，就无论是通过这样的一种，自动规则的这样一种过滤，还是说通过这种，模型加数据混合，去来去做数据的清洗，我觉得如何用一个，高质量的数据，可能都是非常重要的，那再一块就是。

我觉得其实如何引入，知识去来过滤数据，特别是当我们人，去在执行很多任务的时候，其实我们带着不同的目标，其实我们的信息的，这种过滤能力，信息的过滤方式，是不一样的，那所以我们其实怎么，把知识或者任务的。

这样的一些，一些目标性的东西，放入到里面，去帮我们过滤数据，可能也是要值得去思考的，那再一块就是，我们说模型结构，对吧，其实现在我们看到，Transformer已经做到了，大一统，无论是在图文音。

还是在音乐，都是最好的，那其实再往前推，再往前推五年，推几年，那可能大家觉得CNN是最，视觉领域CNN，可能就是最好的，对吧，在语音领域，可能LSTM RNN，就是最好的，那我觉得其实这个模型。

大家其实现在也知道，Transformer它本身，确实有它的问题，比如说，它的自助力机制计算的，冗余性等等，所以我觉得可能，怎么去研究，更新的这样的，像Transformer一样的，这种基础架构。

高效模型，可能也是非常，就非常值得学界，去不断地去探索的，再一个就是，我们要把模型做大，对吧，我们最终肯定要，我们要去做到，百亿千亿，特别是做到千亿的时候，那我们就要涉及到说，怎么去做模型并行。

怎么高效做数据并行，流水并行等等，这个可能都是值得去，就是整个大模型的，这种分布式并行训练，可能也是非常值得，去探讨的一个方向，那么再一块就是，我觉得我们大模型，我们说了嘛，最好。

做完了最终是要服务于下游任务，那么怎么设计一个，合理的大模型，能更好的兼容，更多更强的，这样的下游任务，可能我们也可以在，这个模型基础设计上，也可以去考虑这个问题，那再一个就是说，关联建模，自监督学习。

那其实就像刚才我说，就像我们做多模态域训练，我们做图文音，但我们也不是只用，不是必须要用到图文音，三模态关联的数据，我们只是说需要用到，但是其实你图文的，文音的，纯图像的，纯文本的，我们的模态。

我整个大模型的训练，其实是需要用到，图文音的，图文音的，图文音的，我们只是说需要用到，但是其实你图文的，文音的，纯图像的，纯文本的，我们的模态，我整个大模型的训练，其实都是有的，也就是说实际上。

我的训练要能支持，单模态，部分模态，以及全模态的混合训练，这样才能更好的去利用，全网的数据，来使你的大模型做得更好，那再一块就是，我说的模型的下游任务，应用和迁移能力，对吧，怎么去做对应的模型的，帧流。

推理加速，然后为特定场景提供可能，就是我们落地应用，我们不可能用一个，就如果是特别是到终端上，不可能用一个，用一个这种百亿千亿的大模型，对吧，我可能只能多几百兆，或几十兆的模型，那这个时候。

怎么把大模型的能力，争给小模型，对吧，我们到底是用数据争流，还是模型争流，还是参数争流等等，这个可能都要去做更多的设计，总之我觉得可能，更多的研究创新，算力，数据，可能都会使多模态域训练，做得更好。

更快，更强，那再一块，在大模型时代的时候，我们可能要重新审视说，AI到底要做什么，其实我觉得简单来理解，就三大类工作，一类的就是研究大模型，一类就是利用大模型，那最后就是治理大模型，那我觉得研究和利用。

我就不用多说了，其实大家都非常清楚，那其实治理大模型，我觉得这个话题，其实虽然被提了很多次，但我觉得其实在大模型时代，治理大模型，可能会变得更加重要，就是因为，我们知道这样一个，完全数据驱动的黑盒子。

对吧，我们怎么更好的，更安全，更可信的服务用CIO应用，我们必须要，打开它对吧，我不知道它的原理，我不知道它，我对它的生成不可控，那其实我就很难去，安全可信，放心地去用它，所以我觉得，可能在大模型时代。

我觉得治理大模型，可能会变得，真的非常重要，我怎么使我大模型的发展，更加安全可信可控，可能是需要我们去思考的，那最后一页PPT啊，就是我来讲一下，就是说，多么台大模型，就后拆了GPT-10。

多么台大模型，我们要做什么，那我觉得最后，我们要做的，就是我们要去，对于大模型的，一个更加的理解，对于大模型的，一个更加的理解，就是我们要做什么，那我觉得最基本的，就是我们，我们刚才说。

我们要对标AGI，我们就是要去做大模型，那么未来发展，必然就是要去做，多么台大模型，我们就是要去实现，人类的这样，类人的这种智能，那人类的智能，就是多么台协同的智能，所以我觉得最根本的目标。

就是要对标AGI，去实现这种，高效协同的多么台智能，那再一块就说，多么台大模型，它在做什么，就多么台到底，会比单么台多什么，我相信不同的模台，其实它会有，它既有它自己的，这样的一个可能，既有模台之间的。

共有的东西，也有模台之间，所特有的东西，那其实我们更希望，从多么台之间，去学习更多的知识，我们希望通过，不同模台之间，实现他们的这种，知识迁移，以及相互补全，和相互验证，去来做到一个，更通用 更鲁邦的。

这样的一个大模型，那最后再就是说，我们大模型的目标，就是要去建立，通用 安全 可信的，这种多么台大模型，那最后一个方面，就是说，我们的大模型，它是一个，非常非常非常。

最后一个方面就是说我觉得大模型怎么用，至少现在我们可以看到 特别是China TP出来之后，开源了这么多大模型，这种 通过积木拼搭式的这样那种大模型的应用，已经特别多 层出不穷。

那么其实在哪些领域我们还可以去做更，其实我们可能还有更多 尤其在多模材领域，还有更多可尝试的排列组合的方式，去来拼插出一些更有意思的这样的多模材应用，那么其实我这里简单的总结了几方面的这样的应用。

其实我觉得可能未来更值得去关注，特别是可能作为我们学界，我觉得更值得去关注的话，就是这种多模材感知决策一体化的这样的一种多模材智能，因为我觉得其实现在大模型更多的在解决感知问题。

也就是说相当于我可以给机器人，其实已经可以给他长了脑子 对吧，我怎么把他的眼睛 他的耳朵 把他的手 他的脚，怎么更好地把他的感官和他的执行的这样的一个部件，去更好地协同起来。

那我去做这样的一种多模材感知认知，或者决策一体化的这种大模型，我觉得可能是未来更值得大家去往前走的这样的一个方向，那么落地的应用就可以看到更新一代的这种机器人。

对吧 可能不光是一个类人的这样一个聊天对话平台，可能更多的是可能未来有可能一个机器人坐在我们身边，就能提供像人一样的这种各种服务 各种这种解答，所以确实我觉得大模型给我们带来很多想象。

我们可以看到很多很多，我们可以做很多很多事情，好的 谢谢大家，好 感谢刘老师，这个报告信息量非常大，这个刘老师自带这个二倍速的这个加成的这个特效，那个 那我们应该还有十分钟时间。

然后我们可以再做一个这个简单的交流，然后那个有提问的请举手，那个第一排，谢谢刘老师的分享，然后有两个关于多模态的一个挑战的问题，想请教一下刘老师，那第一个问题是说我们多模态的数据的标注这一块。

可能成本要比我们单模态的标注成本会更大一些，那对于中小型企业想要做基于一个成熟的多模态大模型，做自己的微调的时候，怎么去降低自己数据标注的一个成本，有没有什么更好的一个办法，这是第一个问题。

那第二个问题的话是关于算力的，那我们看我们GB4即使是强弱OpenAI，它也并没有说在它的官方对公众开放它的那个读图识图的能力，那从新的性能信息来看的话。

还是我们多模态的推理对于算力的要求是非常非常高的，那未来像总态初这样的集合了三个模态的大模型，后续进行推理的时候怎么去降低它的算力成本，有没有这样的一个后续的一个方向，谢谢李老师，好的 谢谢你的问题。

首先我来回答第一个问题，就是说数据的问题，首先我觉得就是刚确实我觉得图文音或者是说图文等等，这种多模态的这种数据它的质量，因为它确实难度收集更大，但是我们怎么来去做到高质量。

我觉得现在完全靠人工标或者是说这肯定是不现实的，所以我们更多的要去想一些这种自动的方法，我觉得现在大家我们现在常用的一种就是说通过模型，比如说图文数据对吧，那本质的就是我要有一个图。

以及对这个图像的一个描述，那就像一个图文的匹配对，那实际上我的模型我在做的事情，本身我就可以训练一个captioner，可以训练一个文本描述器，那实际上我就可以用我自己的模型去来对所有的数据做清洗。

然后就这样去得到我的这样的一个类似于，不断的去来洗我自己的数据，或有一个更强的模型去来清洗我的数据，那再一块其实我觉得可以考虑的就是怎么用现在，这样强大的语言模型去来做文字的这样的一个修正和润色。

其实也是可以去考虑的一个方向，而且我觉得未来就是，就是我们说语言模型，大家说2025年可能就已经枯竭了，可能就已经用完了，那实际上我觉得可能未来在大模型这个研究道路上，我觉得可能怎么多。

怎么更好的用大模型，或怎么更好的用模型来生成数据，也是非常值得去探讨的一个方向，就是我们怎么用模型去来生成图片，用图片再去生成文本，文本再怎么，就来形成闭环，就是可能我觉得未来。

可能20% 30%的数据可能是来自于生成的，未必是要来自自己去收集的，而特别是当您对标下游任务应用的时候，那我觉得怎么把大模型的能力，其实我觉得更多大模型，怎么去通过数据征流。

去征流出能够服务于您对标应用的这样小领域的这种数据，可能我觉得是非常值得去探讨的，就怎么用大模型帮，就大模型有时候到下游任务上，可能你直接想把一个千亿万亿的参数，想把它征流成是一个这种几百兆这样参数。

其实不现实，但是我觉得确实你可以让大模型去帮您征流一个很好的这样的高精度的，高质量的数据集，然后用这个数据集相当于是把大模型的能力赋予了你，你还用你领域的小模型，但是我的数据会比你原来好，数据多质量高。

那同样可以得到更好的性能，所以我觉得可能怎么去用大模型去来，帮我们征流数据也好，帮我们生成数据也好，可能也是值得去探讨的，另外您说的第二个问题就是算力的问题，其实我觉得我刚才也引出来说。

我觉得可能未来多么大模型，真的是要以语言大模型为一个基础的基座，然后来去构建，就是相当于语言大模型，就像人的一个认知大脑，我有了这样的一个，通过这种不断的这种文字学习，其实我已经有了一个基础的认知能力。

然后我再赋予大模型，也就是其实我的语言大模型，就是语言大模型的这样一个基础能力，我要很好的保持，就是说我其实，我可能未来多么大模型训练这一块，可能我百分之七八十的参数，都来自于语言模型。

而这块模型的参数，实际上我可以在，真正的多么大模型这个领域上，我可以固化掉不学习，就因为语言大模型现在确实已经发展得非常好了，就让我们看到它能力已经蛮强的，那再一块就是。

其实就是为什么我要去做多么大模型，我们去想到说，我们通过这种多么大模型之间的这样一个，对知识的补全，这叫相互的验证，我们觉得它可能会大大降低我们，对任意一种模型的这种数据的需求。

就我通过这种多么大模型的这种融合验证，可能我会降低我对其单一，做同样一件任务，你只用图像数据，和我用图文音数据来做的时候，我的效率会更高，所以我当用更多模型的数据的时候，我可能会带来一些能力的涌现。

这也是非常有意义的，是不是满意，好 那个要不我们给后面的同志机会，最后面一排，Testing Testing，我想问一下老师，之前我看过一篇论文关于用模型，去生成数据导致的模型探索，还有数据危害的问题。

对于这个问题的话，你们有没有什么其他见解，去解决这个问题，当然这种数据生成，肯定是你要定义场景，定义好你的规则，并不是说这种自由的生成，就是肯定要定义好场景，就像我们说我们要用大圆模型。

你一定要定义好你的propt是什么，你这个才能去更好的去服务，它的生成结果才能更好的服务你应用，就如果是说通用大模型的训练，我倒觉得可能用这种生成式的东西，可能只是文字可能更多的润色，你用这个。

但是我觉得这种特别对标到下游应用的时候，我觉得生成你要结合你的应用的需求，然后去写合适的propt，然后去来做对应的生成，好 那个由于时间关系，我们最后一个问题，然后那个要不第一排那边。

下午好 我是赵紫荆从宾夕法拉大学来的，是否可以我问你一个英语问题，我只是在想，我们正在进一步的向更多的多模型生成训练，是否主要的利益是从增强的特殊化和特定模型，或者是系统性的资源分配和专注资源。

向发展增强的优秀的大语言模型，我没有听得很清楚，就是抱歉我中文真的说的不太好，你用中文说吧，但是我试一试，就是在我们多模型的多模态的模型的发展，我们走向多模态的时候，我们是应该在任意一个某个模态里面。

dedicate更多的时间，把它更specialize，做得更perfect，还是说把overall的大模型，underlying foundational的LLM，把它做得最好。

而其他的application can come later，我觉得这个都很重要，我觉得要想把多模态模型做好，我觉得未来的架构肯定就是，刚才我说的基础架构，可能就是encoder加decoder。

encoder可能就是分别有不同模态的encoder，再有这种多模态的encoder，最终再去接一个decoder这种架构，其实每一个环节都会非常重要，对性能的提升都，所以我觉得其实做大模型。

它不是简单的一两篇paperwork可以堆出来的工作，它一定是大家在每一个环节，无论是数据还是模型，还是说我去最后的这样一些工程的部署，可能最终才能一起才造就出一个非常好的性能，性能好的大模型。

我觉得在整个就刚刚说模型这个环节，你无论是文本还是语音还是视觉，你这个单一模态的，单一模态编码好了表征好了，肯定对你最后的贡献也是非常大的，但如果只是单一模态建好了，你的多模态之间的关联不建立好。

那就不是一个真正的多模态大模型，所以我觉得每一个环节可能都会非常重要，很难说是哪个环节不重要，我觉得大模型真的是一个集成公关的这样一个任务，不是简单的说我们靠一个算法就能堆出一个工作的这样一个东西。

如果说抱歉再additional一个小问题，就是说如果一个产业一个enterprise，要develop他们在某个项目的上的能力，他们应该focus在一个specialized area。

他们自己的domain，还是说能把大模型push forward，我觉得作为企业来说，你有明确的应用场景，我觉得肯定是应该想好怎么把现在的大模型，怎么更好的赋能运营的场景，我觉得这个是很重要的。

而且我觉得未来大模型做基础基座的可能不需要太多，但是我觉得能垂化去发展的，可以针对不同的领域去做各种各样的垂化的发展，我觉得作为企业特别是有明确这种应用场景的，我觉得还是要更多的去定去聚焦自己的场景。

因为我觉得其实现在的大模型，比如语言大模型，包括一些基础的这样的多模态，无论是生成，还是说我们做这种多模态理解，其他基础能力都还可以了，但未来怎么针对说真正落地能赋能应用。

更需要垂化的方式去来怎么去把每一步，你的数据怎么去做，对吧，你的这个模型怎么去构建，你的下游任务是怎么来定义的，以及说现在大家其实我说，未来可能不简单的是一个纯数据驱动，可能还要去做怎么去做人类的反馈。

这种人类的交互学习，可能这些环节都是对你这个，追踪你的这个模型能不能产生价值是更为重要的，好，多谢您，好，那再次感谢各位提问，那也再次感谢刘老师给大家带来的多模态的精彩报告，那大家再次鼓掌，感谢，嗯。

好，那我们接下来就进入到今天的最后一个特要报告，是来自于Google的研究科学家周燕琦女士，然后她要给我们讲的是。

Scaling Large Language Models from Power Law to Sparsity，那么周燕琦女士本身应该也不多做介绍，她是我们应该所有的这个预训练模型，预训练模型里面。

另外一个非常重要的这么一个模型叫T5，她是这个T5的作者之一，那么接下来我们就欢迎周女士给大家带来报告，大家欢迎，大家下午好，我是周燕琦，来自Google的DeepMind。

我是一名Researcher scientist，我在Google做了很多关于Large Language Model的工作，最开始的工作是关于T5。

做了一些这个Input Pipeline的Building，然后做了一些Finetuning的一些工作，然后在往后的一些Language Model的Research里面。

做的关于Sparsity以及Scaling Large Language Model的一些工作，然后和刚才那位同学有一个一样的问题，我的这个中文讲这个technical的东西非常差。

所以这个talk我就还是用英文来讲，然后我可能尽量的这个语速放慢一点，然后能方便大家能够更好的理解这个slides里面的内容，然后如果大家有什么问题的话，我们可以线下接着交流，OK。

Let's get started，I'm going to talk about a large language scaling，from Power law to Sparsity。

And then here's today's agenda，We will have four separate sections。

The first section will be around Moore's law，and the Power law in deep learning。

And later I will talk about my research work at Google Brain。

Ranging from T5 unifying the Text Transformer，And several recent work on MOE architecture。

And more advanced MOE techniques we developed this year，in ICML's paper，And first。

 Moore's law and Power law，If people know deep learning's development。

we might get a sense that deep learning is actually thriving。

because of the development of hardware and modern accelerators。

Jordan Moore actually postulated that the number of transistors，on a fixed areas of a chip processor。

will be doubled every two years，or every one year， one or two year。

And that actually fundamentally provides the thrust。

and the drive of developing large deep learning models，and recent large language models，However。

 more recently we all know that，we are hitting the end of scaling Moore's law。

That means the number of transistors we could pack，on a fixed area of a chip。

is pretty much fixed these days，Therefore we cannot get the free lunch we got from the past。

We cannot really scale the deep learning models for free。

And of course we all know that chip performance，are not just bounded by the number of transistors on chip。

But also bound by the memory bandwidth around the chip，That's what we call memory wall。

And for other reasons，So given the end of Moore's law，In the past few years。

while I was still working at Baidu，Our colleague Joe actually had a very important paper。

about deep learning is empirically predictable，The performance is predictable。

given the size of the model，and given the total training data of the model，So at that point。

it could be like a very groundbreaking research work，But it was not very well known at that point。

And a few years later，Open AI had its own very systematic paper。

around scaling law on large language models，And they have more systematic results。

based on scaling the computation resources，scaling the data set size。

and scaling the total number of parameters in the model，And we could find uniformly。

you could get this linear scaling curve，by exponentially scaling all these parameters。

or each of the parameters，That fundamentally provide our。

the incentives to all the major big tech companies，to develop their big models。

and more recently the larger language models，And in this session。

I'm going to talk a little bit details，about the T5 work we had at Google。

And one of the greatest contribution T5 had，is to formulate each NLP task。

as a unified tax to tax problem，So for example you could，create a tax problem for translation task。

for a sentiment analysis tax，for classification task，and also for like a question answering tax。

like what we this day care most about，And another significant contribution，is the C4 data set。

which was open source with the T5 model，together a few years ago，And this data set actually benefit。

the entire research community a lot，And I observed that many many follow up papers。

are based on top of the T5 model architecture，and the C4 data set。

And more particularly C4 is a web crowd data set，We basically do like a scraping。

from the internet data，And do some data filtering，pre-processing to create a clean data set。

So more particularly we could，remove the redundant sentences，remove short lines。

remove the lines with bad phrases，And by doing those，we create a very clean data set。

of around 750 gigabyte of clean English data，And a little portion of multilingual data set。

is also released with C4，That's why actually the translation results，on T5 model is not so great。

because it contains very little，multilingual data set，compared to the web crowd data set。

And in general，as we know there is a transfer learning，the concept in the title。

So transfer learning is very different，from what we currently care most about，which is in context。

few-shot one-shot learning，in GPT-3， GPT-4，So transfer learning means that。

you pre-train a large language model，and using web crowd data set。

and using the knowledge from the word，while you create the generation capability，of this model。

So that the foundationally，the model is very good at the word knowledge，at the linguistic in general。

However for all the downstream task，you need to do another round of fine tuning。

to actually fine tune the model，with glue， super glue， translation， etc。。

to make the model really excel，on the downstream task，And in T5 we particularly。

make all the parameters very simple，so that people can reproduce easily，And the objective in T5。

similar to BERT，we use the mask language modeling loss，which basically you give an input。

you randomly carve out some of the tokens，and you let the model predict，the carved out tokens。

And the loss is just a cross entropy loss，between the target，and your generated tokens。

And this slide covers some basic concepts，of both encoder-decoder based model。

which is what T5 proposed，and a language model，and a prefix language model。

So basically an encoder-decoder model，is a very general model，An encoder will encode。

generate embedding of your input，a good representation，while doing in the encoding stage。

all the tokens can be attending，to all the other tokens，So the attention mask。

is a fully visible attention mask，while in the decoder，you start the generation。

like the translation or question answering，you need to generate the target。

And doing the auto-regressive generation，there is a causal masking applied。

Therefore all the tokens can be，only attended to the past tokens，not the future tokens。

Similarly in the language model，it doesn't have the encoder part，That means all the tokens。

has a causal masking，Therefore the generation，is causal auto-regressive，through the entire sequence。

including the input and the target，And the prefix LM，improves the language model a little bit。

by providing the prefix part，being fully visible，That means you can do。

like a full attention in the prefix part，And do the causal attention，in the generation part。

makes the model slightly more capable，than the language model，In T5，we picked a BERT style。

mask language modeling loss，with a 15% corruption ratio，That means you carve out，15% of the tokens。

from the entire sentence，And let the model predict，the corrupted tokens，And a very interesting。

actually phenomenon，that the T5 observed is that，for 4X compute，how we should allocate。

the compute resources，And according to the results，it's very interesting，We noticed that。

you could allocate the 4X resources，to either your training data，your training time，your batch size。

or the total number of parameters，It doesn't really matter，The model would，like a pretty much。

uniformly scale linearly，in terms of log complexity，during training，And that finding。

is actually very important，I think it's actually the foundation，of the later Chinchilla paper，Well。

 the Chinchilla paper，developed some theory，around the compute efficient，model scaling。

I think that paper，is actually a follow up work，from the T5's theory，And T5，at that point was ranked。

number one，a bunch of leaderboards，like glue， super glue，except translation test。

like I mentioned the reason，it doesn't have much，multilingual data，that's why it's not good。

at translation，but it ranked number one，on the leaderboard，at 11 billion subparameters。

So since the inception of T5，we've been seeing this competition，across all the big companies。

generating newer and newer，version of larger language models，So in the same year of T5。

OpenAI built a much larger model，called GPT-3，which used in-text decoder only model。

using in-text field short learning，So instead of doing this，additional round of fine tuning。

it cares more about，the generalization capability，of the model，by doing purely，next token prediction。

during training，and doing evaluation，is just use the，in-context field short learning。

It generates a few examples，of the task，and the latter of the model，follow the example。

and it generates the answer，for a new question，So basically that's how GPT-3 works。

And GPT-3 works really well，and the word notice that，the decoder only model，works really well。

especially for the generalization，without fine tuning perspective，However later two year later。

Google has a new model，called Palm model，with over 500 billions of parameters。

And that was considered，the biggest model at that point，It's super capable。

and super expensive to train，However even like one year later，we don't really have like。

officially announced the dense model，above 500 billions of parameters，If you check GPT。

it's actually fewer than，500 billions of parameters，If you check GPT-4，it's not even a dense model。

So it comes to my next topic about，efficiently scaling larger language models。

with mixture of experts，Our first paper on，sparsely gated larger language models，at Google。

which has over 1。2 trillions，of total parameters，but with a slightly smaller number。

of activated parameters than GPT-3，So activated parameters，means that we only，dynamically switch on。

sub-ratio of the，sub-portion of the neurons，for each of the input，That means your model is actively。

is actually sparse，And some more details about Glenn，It's a decoder only model，like GPT-3。

It uses in-text fusion learning，the same as GPT-3，Difference is that，model architecture level。

it has a sparsity，So it has sparsely activated，FFN layer，that makes the model super scalable。

and super efficient，And like I mentioned，the total parameters，is 1。2 trillions of parameters。

with 97 billions of，activated parameters，If you check the results，on the table。

the zero-shot one-shot fissure，compared to GPT-3，is way better，even with a fewer number。

of activated parameters，which means fewer flops，per token，And if you check the cost，on the top row。

the training energy is reduced，by over 60%，compared to GPT-3，So looking into the details。

of a Glenn model，It's a sparsely activated model，But we don't build an MOE，for every layer。

We make the dense layer，and MOE layer，in like an interleaved fashion，on purpose，Because we wanted to。

whenever we introduce more experts，we want to only sub-linearly。

increase the total number of parameters，not linearly increase the number，total number of parameters。

which might require too many，slices of machines，And comparing the few-shot results，with GPT-3。

So at every single activated，parameter size，Glenn outperforms GPT-3。

in natural language generation task，and natural language understanding task，pretty much uniformly。

And here is the decomposition，of the results，You can see the gap，between Glenn and GPT-3。

is actually big，And if you track，the rightmost column，It's comparing the TPU years。

means how many TPU years，we need to train，a certain size model，And Glenn actually provides。

even bigger gain，compared to GPT-3，However， even with，this more efficient Glenn model。

we still notice，the token-based MOE，can be very limited，for several reasons，One of them is that。

it creates some，loading imbalance problem，That's because the token-based，routing have the token。

picking experts，using the routing function，However， that can create，hot experts and code experts。

especially in the beginning，of training，So that's a big problem，Some experts will be underutilized。

Some experts will be overutilized，And the end-to-end latency，can be increased even。

due to the hot experts，So to mitigate that，we propose a new routing algorithm。

We call it expert choice routing，This is a paper in NURBS 2022，So instead of having。

the token-picking experts，We have the expert，with fixed buffer capacity，picking token。

So the buffer capacity，actually can be pre-computed，given the capacity factor，of the model。

which is the sparsity of the model，So the program，can define beforehand，of the sparsity of the model。

And then pre-compute，oh， what is the buffer size，And then use expert choice，to route the token。

using expert choice routing，And which creates，perfect load balancing，You don't have to add。

an auxiliary loss，which might hurt the training，using cost entropy loss。

And also tokens can be received，by a variable number of experts，Which essentially。

creates hydrogenity，in resource mapping，Some important tokens，can get more resources。

While some less important tokens，can get fewer parameters，And this figure shows。

the gather stage of expert choice，Basically a router，select the tokens。

send the tokens to each of the experts，And after the gather function，we needed to still。

run the scatter function，to gather the tokens，to its original temporal order，Which is very critical。

for the following attention layer，And comparing to GLAN，the sparse， the best sparse model，at Google。

The model with expert choice routing，is 2x more efficient，in terms of training convergence。

And in terms of a step time，it's 20% faster，than the GLAN baseline。

So basically expert choice is faster，because it removed，actually removed the load。

imbalanced issue entirely，So all the experts，are evenly balanced，that actually reduce。

the critical path of the round time，And comparing to GLAN，and the switch transformer。

which use top two routing，top one routing，both are token-based routing，Expert choice。

consistently outperforms，switch transformer and GLAN，in various scales，In the largest scale。

AB64e setting，our model even outperform，11B T5 dense model，in the super glue score。

And having the more，advanced routing algorithm，we think about how to improve。

the MOE method even more，by creating even noble MOE architecture，So we call it brain former。

So the purpose is to create a model，that is as efficient as a human brain。

that is more like dynamically，using dynamic conditional computation，is sparse。

and is highly specialized，into different regions，So we propose brain former，which is essentially。

a non-uniform model architecture，rooted from the fundamental，low-rank multi-expert primitives。

And brain former，demonstrate two X faster training，and a five X faster step time，compared to GLAN。

So how do we derive the search space？，How can we decide，what kind of operators。

to put in the search space？，So instead of combining，purely combining all the recent work。

from the world like the X former，different formers，We actually started from，like a very fundamentals。

using two different basic，compression methods，One is a low-rank，and the other is multi-expert。

So by low-rank we could decompose，a big matrix multiplication，into two vertically stacked one。

smaller one，which reduce the loss by half，And a multi-expert means，you could vertically。

horizontally speed the matrix，multiplication operation，And also split your input，into two parts。

and route your two parts of input，to two different experts，And also by stacking。

those two methods together，we could create even higher，compression ratio。

as demonstrated in the right figure，And very interestingly，if you insert a mixture layer。

across the bottleneck part，of the model，the model starts looking，very similar to transformer。

And actually if you use，a tension layer，in that bottleneck part，it becomes a multi-expert。

transformer layer，So that actually our，the search space，help us understand the transformer。

model architecture even more，And we decide to build a search space，on top of those。

very fundamental primitives，by varying the operator types，of each of the layer，And hyperparameters。

of each of the layer，And routing algorithm，capacity factor，sparsity of the model，each layer。

And create a search space，out of this，And during the search，we first sample，a block architecture。

from the search space，And build a proxy model，of size 100 million，per meter。

And a total of 32 experts，And we train the proxy task，to gather the validation accuracy。

And create a reward function，And we pick the top K models，And scale the models，to different size。

1B64E and AB64E，And evaluate different models，at a different scale，And our search objective。

is a compute efficient，search objective，which is actually，taking inspiration。

from the Chinchilla paper，We want to build something，that is not just a block-wise，very small。

or memory-wise very small，We want to build something，that can run really， really fast，on TPU。

Therefore our search objective，is to minimize the validation loss，of the architecture，while meeting。

a inference time constraint，compared to your baseline，Berliner transformer，And your search space。

is the previously mentioned，block-wise，architecture search space，And here comparing the results。

Brainformer is in the right figure，8B scale，is more than 2x faster，in training convergence。

compared to Glenn architecture，And 5x faster in step time，or inference time。

So this table shows more details，around the training efficiency，Looking at the last row，you can see。

with fewer activated parameters，and it gets a lower perplexity，and 5x faster than the Glenn baseline。

And we also compare，the downstream task performance，using fine tuning，and using in-context。

future learning，And Brainformer can beat，both the primer 1B dance model，and the Glenn 1B 64E。

sparse model，on various NLP tasks，So after finding，this model architecture，we start thinking about。

how to effectively train the model，As we know，training larger language model，can be very expensive。

So there are actually，a bunch of use case at Google，we needed to improve，First is we have a temporal。

dataset at Google，So basically we collect，the new samples from the world，in a very constant fashion。

We get new search data，new foreign data，dialogue data，Wikipedia data，GitHub data。

The data is changing everyday，So how can we make，the language model updated，And another question is。

we wanted to adapt，the foundational model，Let's say a pre-trained GPT-4，or POM model，to some target。

downstream task domain，So for example，we wanted the model，to do really well，on conversational tasks。

like chatbot，Or like the model，doing really well on translation，So therefore we needed to create。

like a second round，of a fine tuning of training，using the mixture of，downstream task dataset。

However if you do this，additional round of training，It's also very time consuming。

And it has a significant issue，of forgetting，So whenever you train。

a very different data distribution，than the previous one，You forget on the previous。

data distribution，So here explains the problem，of forgetting，So when you train，on your original C4。

or GPT-4 dataset，And later you wanted the model，to do really well on medical images。

The model gets really well，on medical images，But forgets what is，previously learned。

So that's the issue of forgetting，So here we wanted to create a method，that can make the model。

can efficiently incrementally，learn the new training data，while retaining the older knowledge。

So here is our proposed，progressive lifelong learning，on mixture of experts。

So basically for every new，drastically new data distribution created。

You want to add a bunch more experts，which sub-linearly creates，more parameters in your model。

And you only need to fine tune，the newly introduced experts，with the new data。

while freezing majority，of the older parameters，And by adding a regularization loss。

You could make sure that the model，actually deviates very little，from its original data distribution。

So that's how this method works，So basically we create，three data distribution，A。

 it's created using Wikipedia，web search data，That is very super helpful。

for question answering task in general，And a second B dataset，is a non-English dataset。

which can be benefiting，the translation task really，And the C is a dialogue dataset。

which can benefit，the conversational task really well，And we add a lifelong。

like a learning without forgetting loss，to regularize that the new。

the newly introduced model parameters，would not change the prediction，on the older data very much。

So this figure shows，how it works exactly，We have originally，have the gray part。

which is the old experts，that is pre-trained，on data distribution A，So whenever you introduce。

a new data distribution，you add a bunch of experts，And while freezing the old experts。

you add a regularization loss，by generating two predictions，One using the old experts。

And the other using the new，the new experts plus the old experts，And you make sure the difference。

is very small，in the regularization loss，And comparing to the baseline。

without learning without forgetting loss，And we can see that，our method retains。

the knowledge really well，So when you have a very drastic，change of data distribution，from A to B。

the baseline actually got a deep drop，on its performance on，distribution A，However our method。

retains the knowledge，relatively well，And you compare the numbers，on the downstream task scores。

Surprisingly lifelong learning MOE，actually is better than the dense oracle。

Dense oracle is the dense model，counterparts with multitask learning，So well multitask learning。

has a full access to all three data sets，However in this setting，lifelong learning MOE。

while having limited access to，like a stream of data，don't have access to the older data。

actually can outperform the dense oracle，And this slide will summarize，my today's talk。

So basically we know that，we can no longer substantially，sustainably scaling。

dense large language models，by simply doubling the parameters，or doubling the tokens。

It's a very efficient，less sustainable way，And we need a more sustainable way。

scaling large language models，That's why we developed，various forms of MOE technology，at Google。

And we first we built a，routing algorithm called，expert choice，And then we create a。

non-uniform architecture，We call it brain former，that is 5x more faster，than the Glenn baseline。

And then we investigated，how to train the model efficiently，in a very scalable fashion。

And in the lifelong learning MOE paper，we defined a method，that we could sub-linearly。

increase the number of parameters，while introducing new training data。

and adding a regularization loss，so that the model would not forget。

on the previous trained data sets，And that would summarize my today's talk，Thank you very much。

Any question？，No， thank you，Thank you，Okay， we still have a lot of time。

Thank you for this opportunity，Let's take a seat，Or you can click on the screen，Okay，This one。

This one，Thank you，I think the sparsity，you just mentioned，is a very good thing。

And you just said that，GPT-4 is not a dense model，Is that true？，I can't tell you。

the source of the information，But the multidimensional source，means it is a sparse model，Okay。

 thank you very much，Yes，The girl，The girl in the second row，Thank you for sharing。

I have a question about the computing，like the US and China，you know， on large language model。

because you know， China has，obstacles from the cheap side，We don't get invaders A100 and H100。

I want to know whether you think，like computing-wise，computing power-wise。

whether China is in a disadvantage position，Thank you so much，I might not fully get the question。

Can you repeat the question？，I wonder， you know， whether，Yeah， I want to ask about，you know。

 the computing power side，because China is disadvantaged，in the cheap side。

like Chinese companies cannot get chips，like invaders A100 and H100，This may be put， you know。

the startups and Chinese companies，in a disadvantage position，when， you know， developing。

large language models，which the training is very expensive，and require a lot of computing resources。

So I want to know how do you see this，Yeah， that is a very great question，So I。

 actually when we're thinking about，whether to start a company in China， right。

the very big concern for me，is whether we could get，enough computational resources from China。

As we know， there is like a ban，from NVIDIA from US government。

how many chips we could export to China，each year，There might be a limitation restriction。

of how many GPUs we could get from NVIDIA，So that's a big disadvantage，for Chinese startup companies。

But actually I think that provides us，more incentives to build more，like chip companies。

to actually to be able to compete with，companies like NVIDIA， AMD，etc。。

That would also require a bit more，collaboration between the US and China。

So we cannot be very like a，create such kind of a closeness culture，anymore。

We need to like exchange the knowledge，information more so that we could have。

a Chinese-owned chip company，that could eventually compete with NVIDIA。

and build a very powerful accelerators，So that's the fundamental thing，we could address。

we should be addressing in the future，And another maybe short pass。

My thinking is that maybe a short pass，for the startup companies is to try to。

get some resources from the major cloud vendors，like Amazon Cloud， Google Cloud， etc。。

So recently I know Google purchased，the 26，000 H100，So Google doesn't really just use TPU。

It also provisions GPU as the option，to the cloud users。

Thanks for a great talk about scaling and sparsity，And you have introduced the different。

architectures of large-scale learning models，like encoder only， decoder only， and encoder-decoder。

And then you display the scales of these models，And I noticed that only decoder-only model。

can scale up to like 100 billion scale，But other models like the T5。

or encoder-decoder model developed by Google，is not scaled up to 100 billion by Google themselves。

Instead they scale up decoder-only model，to 100 billion scale，So we don't know why this is the case。

So can you show some insights about，why only decoder-only model can scale up to the large scale。

Thank you，Yeah， that's a very good question，So I think， I guess the key point is not。

the encoder-decoder model cannot scale，So I still believe that encoder-decoder model can scale。

But as a matter of fact， T5 used，pre-training fine-tuning based method。

which might not be very suitable for，the other players to adopt。

Like for those companies who don't have，many， many TPU， GPUs like Microsoft， Google。

They cannot do a fine-tuning on like a giant model，of 500 billions of parameters。

So that fundamentally limits how far we could go with T5，So I guess that's why later we actually。

think really highly of GPT-3， GPT-4，where there is no fine-tuning stage required。

Where like any reasonable size the company，could actually fine-tune instruction。

 fine-tune their model，using the decoder-only model，Okay， thank you，Yes，Oh， I can't hear you。。

Or is it the microphone？，I just got here。 I don't know if you answered the question。

in the previous lecture，I just want to ask about Google。

How fast we are going to be doing multi-modal，Our direction and path，Because now。

 maybe you don't know，How fast GPT-4 is，Is it that I have trained a big model。

Or is it that I am using the MOE，as a basis for the natural language model，To make a system。

I don't know what you think，To be honest， I don't know either，If we knew。

There should be a model that can beat GPT-4 soon，We really don't know。

What the secret recipe of GPT-4 is，We just know from the information source，That it is a MOE model。

Very likely it is a training from scratch，MOE model，It is not necessarily，Taking existing checkpoint。

And create a mixture of experts，But I am not sure，Because we are also doing some research。

It is doing some，Research is doing some，Dance from sparse work。

Based on the existing dance checkpoint，We can create a mixture of experts。

Out of the existing dance checkpoint，This work is also there，But we are not sure。

What method is GPT-4 using，I want to ask，For example， we are in Google，Are these two routes。

Done simultaneously，Or we are in this，For the personnel organization，And resource allocation。

What is the situation of these two routes，If it involves commercial secrets，You don't have to answer。

This may be a bit of a secret，But I think it is，Researchers are doing both directions，Is to explore。

We have such a paper，Is that there are papers in both directions，Thank you，Or you can help me。

I may not have the opportunity，Or let's give the last chance，The last row，It seems to be you again。

I want to ask，About the MOE you just said，If I have a task，Is to be in the MOE。

There is no in the module，Is this an OOD problem for this task，Its performance。

Compared to some dance models，What are its advantages and disadvantages，Yes。

 I think what you said is a，We are currently handling a problem，Many students will complain。

I finished this fine tuning，This MOE seems to be worse than the dance model，Why is this。

Because many times，When everyone is fine tuning，The data set used，And the data set of pre-training。

The gap is very large，You may find tuning，Is based on，For example， based on，You want to make it。

Find tuning more，Align to human preference，For example， GPT-3，Human reinforce，Find tuning data set。

Then your data set，Is far from your pre-training data set，You just do a fine tuning。

Then under the parameters of your huge model，It will actually hurt，Its performance。

It is a pre-trained MOE，All the experts before it，Have not seen such training data。

Then it has no expert，Can capture，This new distribution，So you need to create a new expert。

To capture this new distribution，Not to say，Just rely on this router，To learn how to do routing。

It is very likely to learn，Is a random garbage routing，Then this expert，Is a worse expert。

Why did I say that MOE is worse，Because MOE，It is a specialization on experts，Each expert。

It is not a generalist，Each expert，It is specialized，To a certain distribution，So you。

You generate a random mapping，It may be worse than，This dense model counterparts，Because dense model。

Is a more general version，This is my MOE，Many times，It is tricky to get it correct。

This understanding，But our，This lifelong learning MOE，It is a good solution to this problem，OK，Then。

Because we are going to enter，To the original table later，Then we will invite Ms。 Zhou。

To come down to the stage，To interact with everyone，Then we invite our staff，To set up the stage。

Then，Then we invite everyone，To see if there are any questions，To communicate with Ms。 Zhou。

Then we choose a middleman，Is there a microphone？，Is there a microphone here？，No one，OK，Over there。

OK，Hey， Ms。 Zhou，I have seen your resume before，I feel that you have，The experience of hardware。

You should have been in contact with hardware design，And chip design，Then we are actually。

In addition to this CUDA，This GPU，We actually have this TPU。

That is actually in the North America region，And there are more chips in other regions。

Then we have a problem now，In our T5 and more models，We really put the model to。

Scanning to this more than 10，000，More than 1000 such a，Chip or machine experience，In fact。

 it is the same as us in the past，On the NVIDIA DGX，See this。

Based on the optimization of eight machines，NV LINK，In fact， it should be a completely different。

A scene，Then in the process of this scene，You are，Completely out of this，Uh。

 the optimization of the DGX，When you go to develop，You will find，What are your demands。

You have this software and chip，Find out what kind of this，New this，Uh， some ideas，Uh。

 I'm very concerned，Thank you，OK， this is a very good question，And then I also involved。

I have been working on Google recently，That is， MOE co-design with systems，Uh， we are in this。

The research on this，It may be a general，A feeling，Is our past chip design，Including GPU and TPU。

It is all for a general，This kind of matrix modification，This very compute intensive。

These application workloads，Uh， a specialization，Then it is for this kind of CNN，Well。

 you have a lot of this，Data reuse，This kind of operation is very， very efficient。

But in the transformer，This model，Such a hardware design，It may not be the most efficient。

Because it is over provision，Your 14 point unit，Its compute power，But it did not go over provision。

Its memory bandwidth，And this communication，The communication bandwidth between chip and chip。

This is why this recent，The H100，It is the main one，I made an optimization for this transformer，Uh。

 my H100，This kind of MOE model，It is very， very efficient。

Ten times more efficient than the previous H100，So the reason they can have this kind of claim。

It's because they did a very fast，This communication between chip and chip，Then basically it is a。

N by N crossbar，Such a communication between chip and chip，So in our traditional architecture。

It will not use this kind of，N by N communication between chip and chip，Because it is very。

 very expensive，You can imagine，Now a chip of H100，It sells to the same price as Tesla。

It is what we can't imagine a few years ago，Right？，Right？，Is it possible that in the future。

What kind of Z100，It may sell to a house in Beijing，This is also possible， right？。

So I think it is for this，Uh， transformer model，And for the future，Uh， what is this called？，Uh。

 the model of mixed experts，I think there will be more and more，Specialized chip and system。

To do some optimization for them，OK， it's over，OK， let's thank Ms。 Zhou again。

The wonderful report brought to us，Everyone applaud，OK， you can take a break，Uh， please，OK。

 let's move on to the original table，In our original table，In addition to the three speakers here。

We also invited，Uh， this graduated from Fudan University，And then do a doctorate at CMU。

And now I'm back to Shanghai University of Transportation，Be a assistant professor。

And then online connection，Can you cut it，Wow， and this one，Are you in Hainan？，Can you hear me，Yes。

 yes， thank you， Mr。 Liu，Then we will invite our three speakers，And then sit down on the stage。

And then we start our original table session，In order to prevent everyone，Uh。

 to prevent everyone from this，Let's just follow this speaker order，And then from this。

Start from the second position，To the first position，OK。

 let's welcome the three teachers to the stage，Uh， over here，OK， to be honest。

I didn't prepare any questions for them in advance，So all the questions I asked today。

All of a sudden，Uh， and then， uh， in order to，Uh， let's have this discussion，More information，So I。

 I， I will，Uh， just try to ask as few questions as possible，And then we'll leave more time to，Uh。

 the audience here，And then to you，And then communicate，Uh， I don't know if you have any，Feel it。

It's us today，Uh， the three speakers，In fact， the report they brought us，Uh， this report，In fact。

 it represents，Uh， let's look at the big model now，Very important three front-end technologies，Uh。

 and then it's this，Uh， and this multi-mode，And then there's this， uh， this is。

Skilling up this model size，This sparsity technology，Uh， I think this， uh， today we're also far away。

Uh， this one， please， Mr。 Liu Pengfei，And then we'll connect，Uh， do we want to， uh， I want to。

Just give this to Mr。 Liu Pengfei，Can you uh， quickly，And then introduce it，It's just you。

Look at you think， uh， this big model，Uh， what's the most important technology you're paying attention to。

And then why，And then can you take about two or three minutes。

And then share your views with everyone，And then we'll start this group，Uh， is that okay？，Uh， uh。

 can you hear me？，Uh， this question is actually I think，It's likely to uh， be biased。

To some of the individual research，Experience for me，I think I think the most important uh。

The first one must still be in the process，Uh， how to get the data to be better，Uh。

 structural questions，In fact， uh， like we did before，The teacher said before。

The work in Lima has actually been verified，In the S&P stage，Many times it's just a format or style。

Or a form of learning，A lot of important knowledge，Like math， reasoning， these things。

It's probably still going to be put in，The pre-training stage，And the pre-training stage，In fact。

 like natural language， uh， or literary language，These data will still be limited in the end。

So I think the future pre-training， uh， is more important，It's not just this over data。

It should be more important，Over this information，It's equivalent to the literary data，So much。

And then there's so much other model data，How to put its structural information in，In this case。

 you won't be in，Uh， when the data is more compact，You can still find more data to use。

This structure can be very rich，For example， is it before，We are a relatively simple text。

Can it be turned into an html later，Or turn into a json，Uh。

 and this thing corresponds to another principle，It's just that I've always been very firm about one thing。

It's the reason why there's a problem，And you're in such a very bad process，It's because， uh。

 the big model is doing，It's a storage problem，Pre-training is a data storage。

And the problem is that you're actually doing，It's a data reading，And we're just because。

It's too dependent on some black boxes，We don't know how to store data in the training。

How to save it，It led to us reading，When I did it with promise，Try all kinds of things to guess it。

To save the format，So in the future， the pre-training data will be structured。

If the process is getting more and more transparent，Many problems will be easier。

And the model may be more powerful，This is the first pre-training data，From the structural problem。

The second point is the reward model，I've always felt that RLHF，Maybe RL is not the point。

The point may be that the reward model will be，The higher the quality， the better。

Because now there will be more people，To try to study some RLHF，The flat method。

Whether it's like contrast learning，Or unlikely goods，These things are used，But I think， uh， yeah。

If the model itself can be trained，How high a quality，It should be very， very important。

In my opinion， maybe the binary，The reward model may not be the final state。

More likely to be like now，There is a fine-grained，I think fine-grained may not be the final form。

Maybe it should be a deep form in the end，It has many benefits，And this model may be，Uh。

 let's put the reward model，The scale can be added to something，For example， the model of 7B。

I think it's relatively small，If it's a bigger model，At that time， it may not be a binary thing。

In short， the reward model should have a lot，I think it's more of this secret。

Some recipes are too long，It's also a change in my feelings at present，Uh， mainly these two pieces。

Okay， thank you， Pengfei，Okay， let's move on to the second question。

And then I hope every one of these guests can answer，Uh， actually， I think today。

When we invited the speaker，In fact， we still considered。

The difference in the background of everyone，In fact， you can see，Our four guests，In fact。

 they come from four different backgrounds，And then there are companies that start a business。

From this institute，And then from the college，And from this factory in our legend，In fact。

 we can see，It's this big model，In fact， it's for the whole industry，Uh， all of this subject。

Such a very big wave，Uh， everyone， whether it's active or passive，To get into this wave，So， uh。

 I just hope，Uh， every one of these guests，Can you from your own background，Uh， that is to say。

 you are a startup，And then you are a research institute，And then you are this big factory。

And then there's this college，So， uh， you， you， you feel，It's from your perspective，Uh。

 from your background，And then you're in charge of this big model。

Research or innovative applications，And then， uh， this one， you， you can，Uh。

 the advantage of being able to play，And then some of the shortcomings that may exist。

And then the future，And then， uh， you're in charge of this，Uh。

 you're going to cut in from this angle，And then you think you should go，Uh， what could it be。

Because I believe all of you here，Uh， this audience，And then there's the online comrades。

It should be， uh， a large extent，It's distributed in these areas，In addition to those investors。

 right？，Uh， so， uh， I still want to hear，Each of our， uh， this guest，And then you choose，Now this。

 uh， this background，那么你认为你应该怎么能够更好地在这么一个切入的角度，然后来发挥你的优势，我想可能会对在座的所有的观众可能会比较的能有一些收益，那要不先请音涵开始，好谢谢。

我想从我的两段经历来讲述我对大模型的一个态度，第一段经历是我当时在Facebook AIResearch，那个时候是19年和20年初，那个时候刚开始的时候先是谷歌出现了Bot，这是笔祖。

这是很久很久的第一代大模型，然后后来我们Facebook团队做出了Robota，后面又做出了Bot，后面还有一个Matalingo的Mbot，这是我参与的Leader的三个project。

但是后面很明显，就后面Facebook又出现了OPT，后面直到现在最新的Lamar，相比较而言，就在我在Facebook的那个时代，所有的Leadership，所有的领导层人都对大语言模型非常感兴趣。

主打一个字就是大，因为首先research是不计成本的，多少钱都没有关系，没有一个budget，尤其FIRE这种专注于open source，它其实我们可以看到Facebook真正运用大语言模型。

商业化其实几乎没有做，相反openAI并不open，他们其实是真正把大语言模型商业化，谷歌在逐渐的闭环，所以Facebook的理念一直就是不计成本，我想知道大语言到底能做到什么样。

所以当时我们大语言模型在19年和20年的时候，就已经在research行业，大家就不停的在讨论，Skilling up，但是后来我开始做了startup，我的观念就有很大的改变。

我觉得首先要理性的去看待大语言模型，尤其我们是专注一个非常小的segment，就是healthcare，我们只做healthcare，我们所有的customer都是healthcare。

其实我们的使用者很多都是cardiologist，像这种年薪非常高的医生，他不需要了解怎么去处理一个AT&T的call，他不需要去处理怎么去帮助用户重新去订一个flight，去改一个hotel。

他不需要关心这些，他只需要关心这个cardiology，他这个用户的心脏图EKG是怎样的一个情况，然后这个用户下一次的治疗方案是什么，用药方案是什么，所以一个通用的大语言模型其实在一个垂直的领域。

在一个像我们这种startup的领域其实是没有必要的，所以这是第一点，第二点专业性反而是很有必要，第二点就是一个实际的应用，比如说我们一天其实要handle8 million的call。

如果用一个大语言模型的话，其实这个traffic非常大，整个成本非常的高，而且像我刚才有讲到的我们是实时的，我们必须要在几秒钟内完成transcription，就是ASR的一个transcribe。

然后通过大语言模型实时输出，然后human in the loop，然后这些cardiologists去读这个大语言模型，读到东西然后进行修改提交最后finalize。

所以这些其实需要在一秒到两秒钟完全完成，所以大语言模型几乎不可能在如今在现在这个情况，而且还要考虑成本，我们不能用A100去做influence，我们不能用A100去做production，因为太贵了。

其实我们production只用T4这样的小的GPU完成，所以说大语言模型它很酷很性感，但是是在实际的应用中，尤其在startup在这种真正handlehigh traffic。

这种skillup的情况下，其实它没有那么的实用，相比较而言一个中等型号的，然后一个更专注的模型，其实更有价值更有实用价值，当然我现在所代表的观点只能到今天2023年，可能在接下来的几年内。

N维达在不停的出现新高，不停的impress我们A100的价格，可能只像T4的价格一样，那后面的日子后面的情况就很难预计，但是如今的情况，大语言模型在实际的production中，没有那么的sexy。

好谢谢殷涵带来来自既有大厂的，然后也有startup的经验，那刘静老师看关于研究院做些什么，OK谢谢，我是代表学界，我确实是来自研究所和高校的这种代表，我觉得其实作为一个研究单位，无论做科研还是高校。

其实我们是科研的使命，就是要去做这种创新有用的研究，那我相信我们做大模型也是这样，我觉得我们就要去做创新引领，也要去做有用能踏实服务与应用的研究，那从创新上来讲，我觉得我们的优势就是。

我们有源源不断的这种学生，而且我们会有一个对学生的培养，是一个长期的培养，不像企业去做事情的时候，它可能需要一年建校两年建校，可能我们对学生的规划可能是希望，你两三五年去瞄准一个问题。

然后去来解决这个问题，所以我觉得我们可能，就是学生的资源以及我们整个，对我们的这个目标的规划，我们可以更先进一个稍微长远的目标，我们可以有一个稳定的这样的一个，不断创新的这样的研究力量的补充。

所以这就需要我们去选择，那作为这个，尤其像我们作为这种，我们更重要的是要有一个非常好的眼光，去来做一个，真正能做到创新引领的方向，能够去让这帮研究力量更好的去发挥，不断地去引领这个领域的发展。

比如说在大模型里面，其实我觉得有很多方面还是值得去探讨的，对吧，比如说我们可以去做更强的这种，自鉴度学习算法，我们可以去做更好的这种数据清洗，我们可以去做，怎么去用小模型去来解决大模型的能力，对吧。

比方说大家现在去做这种，怎么把大模型的争给小模型，怎么通过小模型的协同去实现大模型的能力，就是主题就是，就是我们怎么去发挥我们的优势来，不断地引领这个前沿，但我觉得我们的劣势可能就真在于说。

大模型最需要的这种大算力大数据，可能都是我们有所欠缺的，那这块我们怎么去补齐这个劣势，那我觉得可能我们就要去跟企业去做合作，对吧，我们去用我们的优势来补，可能我们的优势刚好可能是企业的一部分的劣势。

因为其实他们可能确实要短期见效，所以我们可能在前沿，已经得到了一些成果可以投入到他们的阴影中，可以去赋能他们，所以我觉得怎么去跟企业去做更好的合作，然后去实现这种优势的互补，可能我觉得是作为学界。

就是作为我们创新这块更重要的，那作为有用的，就是我们要选择的方向肯定就要有用的，对吧，就像我刚才说的，就是大数据大大模型这条路径，还没有看到尽头往后走，大厂肯定是要瞄着这个目标去走的，要去做更多的数据。

要做更大的模型，那这显然不是我们学界的优势，那我们去瞄准什么方向，我们想的就是说，怎么用小而小的高质量的数据，然后怎么用小的模型去获得，对吧，这种大模型相当的这种能力，可能是这样才能。

然后更好的服务于应用，然后真正到落地端，能够有这样些技术，使得大模型更好的落地，去做有用的，可能这是我们可以去做的，那另外一块，我觉得AI for Science，现在应该也是大模型做的比较小。

大家比较关注的，那这个可能也是更适合学界来做的事情，比如现在我们其实也在探讨说，去跟生命啊，去跟脑科学啊，去做一些这种探索性的研究，我觉得这些AI for Science的这种研究。

可能也是比较适合科研单位来去探讨的，好 谢谢，好 谢谢刘老师，带来来自于这个研究所的，这么一些思考，那接下来请燕琪，然后带来来自大厂的这个思考，好 那我可能就是分享一下，我在Google这么些天。

然后经历了这个，ChargeGVT这么一波热点，这个几个月的一些主观感受吧，就是可能外界有一种impression，觉得啊Google这个落后了，落后了就要挨打了。

这个OpenAI就是将会成为未来的Google，那我个人呢，我是一个就是做系统背景的，这样的一个researcher，对吧，我最近的可能五六年，在做人工智能方向的一些科研，那我的感受就是说呢。

我并没有觉得，我一分钟都没有觉得，Google哪里落后了，这个OpenAI对不对，我觉得Google它关注的是，更长期的一个问题，它是关注的是，更能sustainably去使用。

Large Language Model，更safely去使用，Large Language Model对吧，去解决去干预性的解决一些，这个Large Language Model里面，存在的一些问题。

就比如说它是一个，Auto Regressive Generative的一个model，它会在每一个token生成的时候，它都有一定的概率出错，对吧，那么作为一个，我们做information信息。

Information Retrieval起家的，这样一个公司，我们有责任说，提供给用户的这个数据，是safe的，是这个没有hallucination的，是标准的，是安全的，是factual的。

所以我们就是干预性的，尽早的去解决，去试图解决这个问题，还有一个问题呢，是比较这个Google的体量，和OpenAI的体量，Google是80 billion的这个DAU。

OpenAI是1 billion的一个DAU，对吧，目前也没有说，涨到10个billion，所以我的感觉是，with almost，100 times，这个DAU difference。

这个user difference，volume difference，我们尽早的，可能太早的，过早的，这个操心起来，这个LM的这个training cost，serving cost，对吧。

我们怎么把这个，Large Language Model，deploy到产品里面去，能在Google的体量上面，去服务我们Google的用户，可能我们尽早的想了，诸如此类的ABCDE，一系列的问题。

以至于呢，我们没有花精力去release，一个像Chart GPT，这样的一个爆款，所以我，从我个人的这个体验来觉得，我觉得Google它的，它有一个非常diverse的，portfolio，对吧。

Google有一个很大的，世界上最大的，我不知道跟Amazon比，是不是世界上最大的，但是Google有这个世界上，可以说是最大的，这个Google Cloud，对吧，Google的这个TPU的储备。

和GPU的储备，都是非常非常的大，然后呢，我们有这个hardware的战略，system的战略，就是从我们这个，做Google search的，这个体验上来讲，对吧。

如果你现在用Google search，book一个flight，它的这个，基本上这个delay，这个延时是在，零点几个微秒以内的，对不对，所以说你基本感受不到，这个里面有一个延时，但是同样的。

你用一个生成模型，比如说GPT-4去找一个，我今天要飞旧金山，我应该坐哪趟飞机，给你生成了20秒，我觉得是没有一个用户，是可以去tolerate，这样的一个latency的，而且我也，个人感觉。

在未来的几个月，几年以内，我们没有办法，把这个Larger Language Model，的这个Latency，做到Google search的，这个Latency，所以这是我的一个。

一个主观的一个体验，然后我确实是一个，big fan of Jeff Ding，因为Jeff当时是，在Google做了我们的，这个超级大规模的，distributed system。

然后能够非常efficiently，用非常crappy的这种CPU，去serve，Google这个体量的用户，我觉得这在系统层面上面，在软件层面上面，我们没有去依赖，像英伟达这样的。

super computer，我们用一些非常便宜的机器，然后做到了这么大的scale，的一个serving，而且是for free，对不对，所以我觉得，Google是一个，Google应该说。

是一个世界上，最伟大的公司，没有之一，然后我不觉得OpenAI，在未来几年内，能够超过Google，好吧，我在这里想插一句，我真的是对Google，这个企业文化，刮目相看，它能培养出，这么优秀的员工。

都有这么强烈的自豪感，因为我家属也在Google工作，然后我没有感受到那一点，但是今天我在这个舞台上，强烈的感受到了这一点，Google真的是一个伟大的公司，对能感受到这个战略努力，好，那要不彭飞。

作为新晋的教授，然后讲讲你在高校的感受，好，尤其是刚过来，刚回国组队，我觉得其实还是有很多想法的，尤其在新的人工智能这一步，我觉得主要是几点，一个就是，我觉得自己要承担一些，可能作为学者的一些责任。

对我来说第一点可能就是，尝试去揭示出一些，没有被说出来的秘密，尤其在这整个技术战过程中，就类似于就OpenAI，如果做的不Open的话，能不能帮助它，变得更加Open一些事情。

你比如说像各种Scaling Law，SFT的各种的Prompting Scaling Law，或者Data Scaling Law，或者是IHF，到底它们不同技术细节中，所扮演的重要性，就这些事业。

其实都可以耐心的去琢磨的，可能未必是STARUP，愿意花太多时间去研究的，学术界其实就可以有很多时间，相当于在这方面，进行一些反思，去画一个比较正确的路子，这是第一点，就揭示出一些，没有被说出来的秘密。

第二点我觉得就是，学术界包括我自己非常感兴趣，就是相当于梳理一下，各方发展的一些战场，各方其实包含了学术界，包含了工业界，包含了VC，我自己其实在VC，包括STARUP，就这几方面能不能，高效的人。

相当于站出来去梳理一下，然后每个人应该承担的，怎样的角色，告诉这个领域，向大家各司其职，把这个领域整体做得更好，这是第二点，第三点我觉得就是，相信从学术上面来看，可以帮助整个领域。

去找到一些科学进步的方向，因为我之前觉得好像科学，只要大家一直往前走，学术论文一直往前发，就一定是对的，最后可能会发现，有些东西其实是走的是错的，有可能这个错会，变一年或两年，但是如果有个比较好的方式。

你愿意或敢说，然后这个东西可能会有些，不一样的观点，也许经过几轮的argument，就可能产生一种更加，准确的一个方向，这个东西最明显，就体现在评估的方式上，可能我们在做大模型评估的时候。

到底怎样是一个可靠的，比较公正的这样一个评估，能帮助我们找到，真正的准确的找到，模型的优点和缺点，这个其实对未来大模型，真实的发展方向，有利的发展方向，就避免走弯路，还是非常有价值。

学术界在做evaluation这件事情上，或可靠安全assessor，都会有比较大的优势，最后一点我觉得，学术界应该承担责任，就是培养学生，设计师人工智能这一步，其实这个人才缺口是很大的，我觉得更其实。

我自己的感受其实，并不需要，真的有非常天赋异禀的学生，去做这件事情，更重要的是他们知道，怎样的一个成长路径，其实作为，senior的一个researcher，或者是professor。

其实有意把这个东西，告诉他们，和带他们一起往前走，大概这样感受，好谢谢彭飞，那我们第一轮问题已经结束了，那我接下来进入到第二轮问题，这轮问题问完了，咱们就开放交流，那个希望咱们各位都尽量简短。

就是两句话就可以回答，第一个就是希望你能给大家讲一讲，你现在在这个大模型的这个行业里面，每天最让你天天在想的一个问题是什么，就到底是大模型的一个什么问题，在困扰着你，你需要找出一个技术方案。

也就是说你现在在关心的这个，技术的一个难题是什么，然后我相信这个问题应该是大家，可能是一个非常好的一个研究，或者是创新的这么一个选题，那这是第一个，第二个是说，如果给你足够多的预算，就是没有什么限制。

那你认为这个大模型未来，你希望去突破它在哪个方面呢，这么一个特别大的想象空间，就是你觉得比如说五年以后十年以后，然后我们通过做什么事情，然后可以做到一个，你觉得特别理想的一个状态。

就是有一个什么东西是你特别来想做的，就是一个是特别短期的，一个是特别长期的，我想是不是每一位可以share一下，你的这个想法，应该肯定，我相信每一位应该都在，平时考虑过这个问题。

那我相信在座的也应该都想，听一下大家的想法，要不还是从，丁小雅开始，我想第一个问题的答案就是，我最想要的就是一个非常高质量的数据集，数据永远是远远大于architecture的，对于我们来讲。

当然我在做research的时候，数据也是远远大于architecture的，data永远是第一位的，architecture的话transformer。

或者是加上其他的一些training metrics，其实它的结果的improvement是微调，甚至微微调，那第二个问题，我觉得我在我讲的时候有提到过，我觉得大语言模型应该做成一个生态。

而不是仅仅一个point solution，就是它始于文字，但是最后要超出文字，比如说我在今天的会议里提到一些东西，然后它除了记录一下这个会议之后，它会有所有的action item，全部一键到达。

那比如说我提到，我今天的对话里有提到，我需要更高质量的数据集，那大语言模型记住了我这个需求，那在日常当中我需要这个东西，或者是它在我的日常生活中发现，这个可以是高质量数据集的时候。

它会自动帮我clog这些information，然后发送给我，然后让我进行下一步，所以它就是像一个贴身小秘书一样，24小时工作不间断，随叫随到 而且非常聪明，好 谢谢 这个非常有想象力。

我觉得我短期想做的，就是真的想把图文音的，比如说多模态的对话，能做到像大家像chattgpt这种感受，比如大家能够去图文音，然后来去做自如的对话，来去做这种各种多模态能力的感受，那如果说长远来看。

那我真的是希望，有一天真的一个机器人，它能用它的眼睛看，能用它的耳朵去听，然后能用它的手和脚去走，去触摸世界，能去跟我交流，谢谢，可能我更想做的一件事情是说，在这个大公司的体量上面。

去更好的去serve larger language model，然后用到一些，conditional computation的一个方法，可能我想，可能eventually我想做的是一个。

超级大的一个分布式系统，然后能够去有效的去serve，larger language model，把这个cost，query per cost，降到和Google search差不多一样的cost。

这是我可能，maybe短期想做的一个东西，长期我很想明白的一个问题是，就是为什么现在咱们这个generation，是一个autoregressive的generation，我不是做算法的专家，对吧。

但是我很想理解这个问题，为什么我们不能in parallel，去generate这个东西，如果说我们未来有了更强的算力，未来我们有了量子计算机，Google在做量子计算机，未来我们如果有了量子计算机。

能不能in parallel去生成我们的这个，text和这个image，和各种domain的这种content，嗯好，这个好像是科幻小说里面，有过这样的一个设定啊，好那彭飞，好。

我短期其实每天都在考虑的问题，就是非常简单，就是如何把数学解析做得像OpenAI，GD4一样好，或者是甚至更好，到底是什么secret，什么那个recipe去做，然后如果给我，另外一个问题。

如果给我1000张卡，或者是1万张卡的话，我非常想做的事情就是，自己走一遍pre-training，把自己对数据的理解方式，应该处理的方式走一遍，啊觉得会更好，完了，那你的这个长远目标好像有点。

好像很快可以实现是吧，呵呵，好，那个啊其实大家应该能感受到，我们4位嘉宾，他的短期目标和长期目标感受上，其实跟他们现在的经历，其实都都会非常非常的匹配啊，所以其实我觉得，在座的所有的观众。

然后其实都都在都在参与，或者是将要参与大模型的，这么一个工作，那么我们会认为，大模型应该是未来人工智能的，这么一个必然的，这么一个技术路径，所以其实你今天的决定，其实决定了你未来的，这个你的路径啊。

所以其实还是希望大家能够积极的去拥抱这个时代，那我就完成了我的使命了，就我去通过两个问题做了一下预热，那我们接下来就把这个啊，我们的啊，提问，然后交给我们现场的观众，然后呃我们要不要那个。

呃好像我们找一位，呃请这个已经提问过的，就把手放下，让我们看看没有提问的同学，然后可以，呃要不站着的那位同学，站着的那位，呃那个请所有的提问的，呃同学都呃都告都明确说一下，你是希望所有的嘉宾回答。

还是你希望指定一位嘉宾来回答，我问一下刘老师，就刘老师觉得就是那种机器人，两位，啊，两位，呃中中间中间中间里，刘静老师，对，就是刘老师觉得那个机器人就是我们，啊，我们能像就是像猜的基地猜的GBT那样。

就是机器人，就是，呃我们让他干什么他就干什么，就是我们比如说猜的GBT，我们问他一个问题，他就能回答，但机器人我们如果给他说，你去给我端一个水杯，他是不行的，就是我们要想完成这么一个功能。

就是难点在哪里，这个里面就要打通很多，要打通感知到决策，就是首先他得能看到水杯，然后能定位到水杯，然后他的手再能去执行这个任务，那其实现在我觉得，就现在大家做通用大模型多模态，其实。

还是我被动的提交一个图片，提交一个文本，其实这个，它和我们真正智能体看到的听到的还不一样，我们人在环境中就是我们，我们会结合我们看到的听到的，然后来去提问题，来执行在当前环境下的东西。

所以我觉得可能首先的一个变化就是，我的感知信息，感知信息源变成了第一视角的，对吧，我已经是智能体自身的这样的一个多模态的融合，然后这是感知层，就相当于拿杯子的这种，我要知道，前面哪里有水杯。

具体的位置是哪，那定位到之后，其实我就要去指挥我的手，去来执行这个动作，那其实这里面，那去执行，这就相当于是要到决策层，对吧，我要去到，我要知道状态该怎么去付出，那另外还有在这个过程中，还有一个问题。

可能万一这个记忆，他不知道什么是杯子，对吧，他不知道杯子在哪里，这个时候他其实又需要去，有一个交互的过程，比如说他可以去问，对吧，就像我们的问答一样，就是可能他不知道杯子的时候，他可以去问你。

杯子旁边有什么，这个杯子是什么颜色的，他可以去问各种各样的问题，然后来帮助他更好的理解，更好的定位，所以我觉得这个里面，其实要真的要做到机器人上，就机器人像人一样，我觉得其实很多东西，还是要去。

还要很多东西去做，但是其实范式上，比如说我们还有感知，现在也有感知大模型，也有决策大模型，只是真正感知决策，现在没有完全打通，但其实现在，我觉得路线上是大家是通的，只是现在还没有。

大家没有做出一个特别好的，这样的东西出来，但我觉得未来肯定会，很多人往这个方向去走，谢谢，好的 谢谢老师，Hello，好 下一个，我算是那个刘志源老师，在清华的师弟，我就不问刘老师，我毕业之后。

先在中科院做过科研，然后你问谁，你问哪一位，我分别问三位三个问题，OK，因为我先是在中科院做科研，然后我也高批入职过大厂，然后我也自主创作业，所以我要分别问三位，可能有点挑战的问题，先从右到左吧。

先是大厂的同学，我在美国的师兄，David Wei，他当时很早就，就Matter的VP了，对吧，他一度也很执着，但是最近两个月，他告诉我，他也离职创业了，所以我想问右边的同学，有什么样的机会。

会促使你离开Google去创业，对，你可以思考一下，然后问中间的这一位，就是我当时离开中科院，很重要的原因就是，张宏江老师当时跟我，花一个上午跟我聊过，他极力劝我从中科院出来，跟他创业。

他说如果你在体制内呆久了，我都不敢用你了，所以我当时才决定离开中科院，然后创业的同学，我觉得吧，就是虽然我们创业，都是AI大数据的公司，看起来很高大上，但是在甲方面前，我们其实都很卑微，对吧。

那么你是用怎样的心态，来应对你的甲方，尤其是中间那位同学，他说到他可能希望，去负能一下，我们工业界对吧，你觉得你会有机会被负能吗，谢谢，所以你冷落了，我们的彭飞老师是吗，谢谢，我先吗。

是什么契机会让我决定去创业，就是就是就是honest，to be honest，我在Google的时候，就有几个非常frustrated的point，就是每当我觉得很不顺利的时候，我就会想，哎呀。

我还是自己出去开个公司吧，后来呢，我就是经过好几次这样的一个思考，我可能有时候会说，真正遇到困难的时候，我会反问我自己，就说你现在遇到了这个困难，你在Google这么好的环境里面。

都没有办法解决这个困难，对吧，你凭什么说，你能在一个创业公司，在那么limited的resources，你这个下面，你可以去解决，更好的去解决问题，更好的去发挥你的这个才能，就我觉得这个是可能。

就是让我一直在这个大厂，push我这个，现在这么做的这个resource，research方向的这个原因，然后我觉得呢，未来如果说要需要创业的话，我觉得最大的原因可能是说，我在Google可能觉得。

有一些我特别想做的事情，但是在Google我做不成，只能在创业公司能够做成，这个事情可能就是说，也许是build一个，像chargeGPT一样的这种爆款的产品，这个我觉得可能在短期以内。

就是以我个人的力量，在Google是很难deliver的，所以可能如果我心之所念，就是想build一个这样的产品，那我会很快选择离开Google，去做我自己的产品，但是呢因为我。

个人本身的research的interest，是在这个system，这computer system，和这个artificial intelligence，这个上面，就我觉得Google。

它是一个很好的，能够发展我才能的这样一个地方，就目前为止我没有觉得，它Google它局限了我，做research的这个步子，所以我觉得目前为止我还ok，但是未来说不定可能，我觉得我想出去build一个。

更好的computer或什么的，那我觉得有可能会出去创业，欢迎你联系我谢谢，好那刘老师，我来说一下，我觉得其实研究所，对于很多人出去创业，当然有很多人一直在坚守，自己的科研岗位，我觉得首先。

就是你做的这个事情，就是我觉得要坚持自己，想做的事情，而且可能这个东西本身，也确实是有一些动态的这种特性，有的时候，就是我是觉得，可能有的人适合创业，有的人适合做科研，当然有的人在他做科研的路上。

发现他的东西，越来越能复能，越来越能落地的时候，可能这个时候他时机到了，也可以去创业，但我觉得这个可能确实，根据每个人不同的特性去来做吧，我觉得大模型这个事情，就是比如说我们现在在做的，我们从一开始。

就是业内企业在做大模型，大家都在做语言大模型的时候，其实我们在做多么台大模型，到现在我们也不觉得，我们的多么台大模型比企业做得差，就我觉得我们现在在很多，视频理解的任务上，其实我们。

我觉得我们做得一点也不差，然后在未来再说，我想刚才说我未来，如果要去做机器人的话，那我觉得像这种前沿的东西，大厂可能，可能企业它不一定去投资去做这个事情，但是我们如果做科研。

那我可以去大胆地去做这件事情，就所以我觉得可能每个人，都有自己适合的路，在不同的时期都有自己适合的路，谢谢，谢谢你，好 叶涵，他的问题是，怎么服务甲方，甲方心态以及你是否觉得，需要被小说界负能。

那我用九个字来形容吧，卑微，不是九个字，是二个字可能，卑微到尘埃，有求必要，随叫随到，哈哈哈，好，共勉共勉，好，那个我们因为可能还有不到半个小时的时间，然后我们为了能够更加增进交流。

那接下来还是请我们所有的问题尽可能的简短，所有的回答尽可能的简洁，那请我们的那个工作人员找这个选一位，嗯，感谢各位老师的分享，我想问一下刘鹏飞老师怎么看待，呃，带语言模型做reasoning这件事情。

因为看到很多呃学术界研究，包括工业界都在尝试用large language model做，尤其是做mathematical reasoning这种事情，当然也有一些研究反对者说。

语言模型就不应该做数学题这种事情，我们可以用调用tools就是工具，呃hack and jpt这种方式，呃想问一下老师怎么看待，呃large language model做reasoning这个事情。

谢谢，啊你好，很好提问，其实我觉得这个问题，好像大家心中可能都会有一些答案，确实你说的两种方式或者更多种方式都会反复，被被被提及，我觉得终极的我自己的觉得一个终结答案可能就是。

呃大于大于训练语言模型做mathematical reasoning是基本盘，然后去赋能其他的工具做呃做一个呃不管是外挂，还是还是还是插件还是工具，其实也是必要的，是不可能会缺少的。

所以一个比较好的事情，比如我开始来做的话，可能会先去先去梳理一下所有的mathematical reasoning，到底是有哪些类型不同类型最你觉得最合适的解决方式是什么。

比如像呃前两天那个google放出来的，他们说相当于给了那个bar的一个一个可以调用这个外部比如python这些工具的机会的时候，他们整体的解释用学习的性能可能提高30%。

现在这个东西最终呃google也会把它放那个portal level的事情去做，所以其实调用工具还是还是用mathematical reasoning呃用用大于训练语言模型去做。

我觉得是最后应该是都需要做的，只是最前者反倒更难，你只是调用工具的话，无非只是把这东西转化成一个如何更好使用工具，然后如何更好生成code的东西的时候，可是当你有个非常复杂的一个问题，有多步推理。

然后转化成一个形式化数学问题的时候，就是靠的就是大于训练语言模型，嗯有些东西适合编程，有些东西就要靠那个那个reason and change，就需要大于训练语言模型来生成。

总之啊比较理解好这样不同的数学场景，然后啊分析好到底是更适合用什么去解决，然后用大于训练模型去或者是工具选择更适合的场景，然后再做比较好的切换，我觉得应该就是最最终的归宿了，就是不要否定任何一个。

然后哪个但是我担心运营模型可能是更靠前的一个对，哦谢谢谢谢好，那请我们工作人员尽快的帮着找一位这个提问者，嗯我想问一下那个专业的老师。

在google训练大模型的过程中克服模型的hallucination，啊就有什么很好的practice，如果有涉密的话对吧也可以介绍一下业界里面。

要设计什么样的数据集可以很好的去克服模型的hallucination，谢谢，我觉得可以借助更大的语言模型去做一个critical一个model，对吧就比如说那个anthropic最近的research。

他是做了一个rl AI reinforce对吧，他就用了一个更大的更general的一个语言模型，然后呢fine tune这个语言模型去做一些classification。

就比如说让这个更大的模型去判断这个小模型生成的数据是不是safe，是不是有hallucination，就是他可以用这个大语言模型去做一个标注的这样的一个事情，然后还有一个呢我是觉得可以结合。

google search或者这种indexing的这种办法，就是你每生成的一个东西你都生成了一个索引，就是一个citation，你这个东西的源头来自于哪对吧，然后你如果有了一个很好的源头。

你就可以这个user就可以check，哦我的这个生成是基于这一段文字，然后我去查这一段文字，然后看这段文字能不能够值得信赖。

然后有没有就是如果是一个很general的一个很well-known的一个publisher，我们可能就能更trust的这个源头，这是我觉得一个比较general的。

一个是一个classification的一个model，可能这个classification的model是基于更大的模型，更powerful的模型，然后还有是可以基于这种tool。

like google search rank什么这种这种model，对，好下一个问题，几位老师好，我现在是目前在工业界，然后用大语言模型解决我们一些业务问题，现在遇到一个比较大的问题。

就是我现在大语言模型的话，基本上它的那个序列长度基本上都是2000或者4000左右，比如说要处理更长的文本的话，几位老师有没有一些比较好的一些方向和建议，谢谢，看哪位老师能回答这个问题。

我们有用sliding window，我们用sliding window在不同的window里做generation，然后再aggregate整个出来的东西再做一次generation。

就是不同的window之间差异会大吗，就是会，你要保证你的training data要line好，就是说你training data如果只有前半段，你做了trancation的话。

那你trade出来的model结果就会差很多，那如果你training data本身就有中间段，有后面段有前面段，然后它是align好的在标注的时候，那它trade出来的结果就会质量高很多，好谢谢。

好周老师有，燕青你有，我可以分享一下这个经验，因为现在这个GPD 4已经把这个sequence length卷到了32K的这个sequence length，这个是非常aggressive的。

然后Google肯定也要做类似的这种工作，然后我们大家都知道这个我们当这个sequence length更大了之后，它的这个运算的最大的瓶颈是在attention。

它是一个n-square的一个complexity对吧，那么理所当然的我们应该用更efficient的，这个attention去取代这个full attention。

然后我们如果大家读了那个openai的早期的，那个sparse transformer的paper，它用了一个fixed那个什么striding。

就是它有一个local attention plus一个fixed striding的full attention，就它用了一个sparse attention的一个方法。

就是和我之前提的MOE的这个方法有一点类似，然后我觉得大概率他们就用了这个sparse attention的一个机制，这是我的一个个人的推测，然后我们现在也是正在做一些相关的工作。

就是further scale这个attention layer，to over 100K sequence length这种工作，对，好下一个，我一个问题也问一下那个周女士老师。

然后那个我们都知道那个大模型也是现在有出现很多幻觉，那这个MOE的这个模型它有没有对这个知识啊，它有没有更显示的这种存储啊，或者说用MOE有没有更好的方法来解决这个幻觉的问题。

我觉得可能就是有一个可以做的方向，可能是说我create了一个就是更safe的这样的一个expert，然后呢这个expert它可以基于这个我有一个validation一个checker。

它可以去基于这种AI augmented的这种classifier，然后呢去对这个专家模型去做一个fine tuning，然后呢这个专家模型它可以说我非常非常精准，但是呢我很boring。

我能保证我说话是99。999999%accurate，但是呢我说的话很boring，你们要不要选我，就是我觉得可以一个非常corner的case。

就是create这样的一个非常factual的expert，但是他说话说的话不是非常creative，就是我觉得这是一个短期内可以做的一个东西，用MOE做的东西。

那个我想请教一下蓬佩奥老师就是关于那个模型推理这块，就是模型推理和数学计算我们在实际优化的时候，可能先去要把模型推理这个逻辑关系要去理清楚，然后再去走下一步的数学计算。

那实际我们在做fine tuning的时候，如果说是在一个小模型上去做一些这种优化，因为像XHPT或者说是国内一些大模型的话，其实在这方面表现都不是特别的好，所以这个地方如果说是用小模型做一些的优化的。

这种方向的选择的时候，数据级第一个是我们怎么样去构建一个别号数据级，第二个针对这个数据级的话，我们怎么样去做一个比较solid的这样一个评估吧，然后第三个就是针对这个小模型的优化。

因为pre-train的阶段的话其实成本比较高，针对小模型的这种优化的思路，是不是可以比较合理的牵引到，我们在做这种pre-train大模型的这个阶段，OK，其实我首先先分享一个观点。

就是我觉得做这种mathematical reasoning或者很复杂推理，我觉得一定不只是SFD某一个单独阶段的事情，是一个非常全段式的事情。

很多时候就是包括了要involve到pre-training，然后加SFD，甚至还要加到后面的inference，inference很多时候也比较影响性能，包括如果model的选择，先不说大小模型。

这些大模型可能如果做得比较好的话，也有这几个阶段，然后如果你不从头pre-train的话，你可能要至少你要有continue pre-training，你要把基本的数学或者推理的一些概念。

比如像最大公约数这些东西是什么意思，如果都不知道的话，它根本就无法理解提醒，而这些东西很有可能在pre-training，或者continue pre-training中，构造相关的语料是可以学到的。

然后还有其他的也至少都可以放进来，然后再说SFD data，我觉得还没有到SFD那么阶段，pre-training另外一个比较重要的事情，可能要构造的语料就是，就是做这种东西其实，大模型本质上永远是在。

根据历史信息预测下一个词，而数学这种东西怎么可能，这么简单的就可以预测呢，所以对于数学或者多部推理这个东西，一定要把中间的推理步骤给展开，永远不只是一个Q和A的问题。

就是request and answer，还要把中间的evidence展开到一个，非常适配大模型做下一个词预测的东西，而这个事情应该是最花时间的，所以我觉得不管大模型还是小模型。

能够构造这样一个data，然后比较高质量，然后转化成让必须的语言模型，很舒服的去做下一个词的预测，就很舒服的去抓它的evidence，一个比较重要的事情，这个过程大概就可以放到。

continue pre-training阶段，SFD阶段就根据你想去做的，不同的场景，然后去设计出你想解决的题型，就相当于给一个format，或style的东西就可以了，然后后面可能容易被忽略。

是inference阶段，对于这种多部推理，其实inference阶段的重要性非常大，就像你可以看到很多问题，其实都在inference阶段，加了一些trick，加了一些model。

做了一些比较性能上的提升，大概是这样，当这个东西做好之后，我觉得再考虑小模型，小模型如果你有比较好大模型，就当然可以直接进行knowledge的一些，一些distill，但也可以尝试着在一个。

至少我之前尝试的一些经验，就是很小的模型，包括13B或30B以内的，如果直接去做就mathematical reasoning，会比较难的获得一个非常好的性能，我觉得我自己非常想尝试。

能不能在一个比较大的模型上，先把它正常的技术路线给export出来，然后再往小的去走，对，嗯，好 谢谢老师，下一个问题，各位老师好，请我们工作人员把这个话筒尽量的，各位老师好，我有两个问题想问一下。

就是第一个问题就是问全体老师的，就是我们现在所已知的大模型，基本上都是被动响应式的，比如说你问一个问题，他给一个答案，那么未来他有没有可能变成主动式的，比如说针对一个具体的任务。

然后他可以一步一步引导我们去，搞定这个问题，然后第二个问题是想问一下，创业界的这个应寒女士，就是对于一个特定行业而言，我们如何去也收集一个高质量的这个数据群呢，我两个问题一起答吧，先答第二个问题。

用户data其实是用户create的data，是最高质量的data，尤其企业用户create的data，是非常高质量的data，因为我们个人用户来讲，我们可以很随意的去做一些事情，但企业用户他们。

他们的用户他们是被企业发放工资，所以有pay就有motivation，有motivation就是quality，这是第二个问题，第一个问题是什么，能重复一下吗，第一个问题就是我们现在的模型。

基本上都是被动响应式的，就是你问一个问题，他答一个答案，那么未来我们有没有可能把这个模型调成主动引导型的，比如说针对一个具体的任务而言，他可以引导你一步一步的去搞定这个问题，这是一个非常好的创业方案。

我觉得，如果能把它真正build成产品，当然我觉得roadmap还是挺清晰的，它非常attractive，至少如果我有钱，我会投这个想法，谢谢，用户粘性会很高，好，下一个问题，我这边有个问题。

就问一下应寒女士，你在哪个位置，在这，在这边，OK，就是我们在现在做2B的，我们可以认为是2B的算法服务，对吧，不管我们用大模型还是怎么样的，就是我们现在deliver这个模型的时候是，客户定制的。

这是第一个问题，第二个事情是我们的交付成本怎样，IY如何，因为做算法交付，尤其是做，它不是所见即所得，对吧，所以这里面我不知道现在我们在交付上面，有没有遇到一些成本怎么样，然后第三个事情就是。

从你刚开始创业到现在，模型已经发生了一些变化，尤其是GP4这样的一些技术的出来，这些GP4这样的一些产品，如果我们拥有这样的一个，我们直接接GP4的话，是否能够降低你的交付成本，第四个事情就是。

我们用大模型，你公平起见，你能不能不用问那么多问题，好的好，三个问题，谢谢，我尽量一起回答，第一个就是用户，企业用户是一定要有自己的模型的，而且很多时候，很多时候企业用户需要自己的模型。

存在自己的info上，因为这是一个安全性能问题，因为企业用户不可能把他的，数据发给你，然后让你去服务其他的数据，其他的客户，他的竞争对手，那比如说世界最大的medical device公司。

是我们现在的客户，在我们签协议的第一天，他就说我们的数据不可以，你用我们数据trade model，是不可以给我们的competitor的，这个是写在contract上，这个非常重要。

所以没有任何企业数据，企业用户目前是用general model，至少我们的企业用户，这是第一个问题，第二个问题，你问的是GP4，是ROI的问题是吧，那ORR就根据我刚才讲的，我的talk里有讲。

我们的ROI非常简单，就是我们原先在没有AI的时候，我们的这些用户用多久，提交答案，或者是反馈给用户，反馈给他们的客户，那有了我们的model，然后它的速度快了有多少，这个就是我们的ROI。

其实我们有reduce，他们的call handle time，by 75%，就是after call work，所以这ROI很高的，也就是说它以前写需要10分钟，那它现在由我们用我们。

然后再去改只需要2。5分钟，第三个最后一个问题是GP4是吧，GP4它有一个很大的隐患问题，就是你需要把你的数据发给它，发到它的server端，这个在任何一个，注重数据隐私的公司，都是不可能的。

尤其像housecare，这种非常sensitive data，是不可能发到GP4上的，所以GP4像是一个更，是像是一个更科研的，然后或者是个人用户，for fun的一个东西，至少我不会把我个人的信息。

发送给GP4，好，那个因为我们还只有不到9分钟时间，所以我们再保留两个问题，Hello，问一个问题，就各位老师，现在那个prompt engineering，已经比较火了。

然后国外已经出现提示工程师的职位，然后我想问问各位老师，怎么看提示工程师，作为一门职业，或者说提示工程，作为一门工程学科的发展，好谢谢，你是希望每个老师都回答吗，还是，我想听听就大家，谁有想法。

或者想问一下，就想听听各位的意见，对，我觉得就是这个，这个叫什么prompt tuning，工程师这个职位，会比世界上任何一个职位，都更早的消失，这是我的一个判断，这个因为那个Sam Altman。

好像他自己都说了，这个职位可能很久，不久的将来就已经不需要了，因为我们现在目前有一个什么work，它叫soft prompt tuning，就是prompt。

你可以用一个gradient descent的形式，去直接去soft里去，去tune这个prompt，你就不需要去人工的，就是说我觉得在不久的未来，我们可以就是automatically。

去tune这个prompt，而不是说需要人工的去做一样，这样的一个tuning，对，周老师，还有其他几位，我觉得我的想法也差不多，我觉得prompt tuning，这个可能是短期的短期有效。

但实际上我觉得作为一个，长期的职业，或者作为一个方向去做，我觉得可能，价值不是特别大吧，谢谢，周老师你好，就是我有一个问题，就是我在您的那个介绍里面，看到了一个，就是关于大模型的，一个连续学习的问题。

就想问，就是在大模型的未来的5展当中，它的评价体系中，是否可以把连续学习的这种能力，作为它的评价标准之一呢，我觉得应该，就是我们的这个benchmarking里面，应该有一个这种。

持续学习的这样一个能力，因为如果不推，如果不encourage大家，去推进这个能力的实现的话，这个training large language model，将会变成一个，大厂之间的这种恶性竞争。

因为大厂它拥有这个世界上，绝大多数的这种计算资源，它可以去重复的，每两年甚至每一年，去训练一个更大的语言模型，但这个资源，是不是所有其他的公司，或者是学校具备的，所以我觉得，这个可以把它作为一个。

benchmarking的一个标准，来以后去推进，好像大家进展比较快，那我们接着往下回，接着好像我问，周姐好，我这里有几个关于，你问谁，我问一下周姐，对，就是关于skilling law的，几个小问题。

第一个就是我们都知道，那个skilling law是一个power的，它其实对于我们，一直往上去skill up以后，它其实会变得非常，inefficient，然后，就是我在想，会不会有一些新的工作。

或者大家会去讨论，就是这个power的skilling law，会不会可以被break，比如说变成一个linear的，甚至变成一个exponential，就是比如说，以在这个data的这个维度。

比如通过一些数据选择，之类的方法，可以让它变得，对就是可以，就不要依赖于数据power的增加，accuracy才能linear的增加，这样就有点不太好，对我看到有的素材服务，他们有做了一个工作。

但是它是一个非常toy的，然后是一个linear model，在high dimensional limit上，做的一个，但是我不知道，就是在大场里面，在对于这样一个，非常fundamental的问题。

有没有就是在真正的，实践中的model上，做过一些探索，对这是第一个，第二个就是，我看到您是出于这个scaling law，所以去做的moe的这个模型，moe确实我们知道它，相对来讲推理的时候。

data就是会，会premature efficient一些，但是我之前看到过，也是deep mind的，就是Aureus，他们做过那个moe的scaling law，它其实也是一个power的。

所以那我们到最后，会不会就变得，我们moe也会面对同样的，这样的一个scaling up的问题，我觉得这个同学的观点非常好，你说的那个power law，我觉得就是，可能有两个方面。

我们目前的power law，主要指的是这个，预训练这个阶段，就用这种unsupervised pre-training，然后这样的一个setting里面，observe的这样的一个power law。

然后我并不觉得，有什么fundamental的方法，可以就是去，sublinearly去scale这个power law，因为我觉得这个是，这个是很多，过去的这些理论的paper，都已经证明过的。

就是我们为了去实现这个，linear scale的这个accuracy的scale，我们需要在模型capacity上面，去做一个exponential的这个scaling。

这个是我觉得fundamental上面，是这么回事，就是你没办法去bend这个curve，但是你可以去shift这个curve，对吧，我觉得moe做的一个事情，它就是shift这个curve。

让它的这个intercept，with这个axis，它有一个改变，对让它变得更陡峭一点，对对对对对是这个意思，对我这还有一个小问题，就是那个，就是我最近看到有一些工作，他们认为说那个大模型。

在训练的时候，当它比如说超过6。7B以后，它就会出现很多特别大的值，然后很多的其他值，会变得越来越趋向于0，少量的会变得特别大，然后这个可能也是它更好的，泛化性的一个来源，也就是说。

就是即使是dense的model，它在训练的过程中，也会出现sparse structure，然后这样会不会导致，这个dense的模型，也会逐渐变得有一些moe的特性，以至于它俩最后可能会分不开。

对对对，你说的非常对，就是我们现在也有很多research，是不是基于我们这个mixture of expert，因为mixture of expert，它是created for这种。

像TPU这样的这种结构，这个well，这个你没有一个很好的，像GPU kernel base的这种，structure的sparsity的support，就比如说你刚才说的这种。

这个模型dense model里面，本身它也具备sparsity，这个是我们可以在用GPU kernel，去很好的capture的，这个东西我们在TPU system里面。

也没有这样的一个kernel base的compilation，所以我们因为我们基于的是，XLA的dynamic compilation，所以我们没有办法去很好的，support这种。

目前为止没有没有很好的办法，去support这种structure的sparsity，所以这是为什么在谷歌，我们选择做这种混合模型。

这种course granularity的mixture of expert，然后用model parallelism，能更好地去并行这个很多个experts，我稍微补充一下这个问题的回答。

就是实际上我们在前年的时候，做过类似的这种发现，就是你基于这个transformer架构的模型，你是它的确是会自动的出现，这种西数激活的现象，你是可以去把它转成一个MoE架构的，就这个是是可以做到的。

就如果有兴趣可以看我们当时发的论文，也可以就这个没问题的，就是你的这个insight是对的，好 那我们只有两分钟了，要不把这个机会交给别的同学，我问一个问题，就是我也是racing sophomore。

然后学了一年的计算机，然后现在有点迷茫，就是想问问各位老师会给现在的学生一些什么样的建议呢，刘鹏飞老师，我觉得可以先，我之前常说的就是，主要是先认清目前整个大时代发展的趋势。

因为在这个趋势下做事情会事半功倍，还有就是尝试发现一下你自己最独特的那个优势是什么，然后把它和这个大趋势发展到一起，或者和技术结合到一起，这个时候你更容易在这个领域做得很好，对，我稍微想补充一点。

就是我是觉得你其实已经选择了这个方向的话，我是觉得你首先要感到非常的幸运，你比这个世界上的绝大部分人都更加接近这一次的技术的革命，所以你只要意识到这一点，接下来不管吃多少苦，你都觉得应该是值得的，加油。

谢谢，谢谢老师，好，我们还有一分钟的时间，最后一个问题，我想问一下这个易涵女士，这边这边，你好，我想问的问题就是这个小模型怎么会怎么样不被这个大模型淹没，那么就是说基于我这个多年做NLP的这个经验。

那么之前做了很多年，那么这个，TED GPT一出之后，那么之前的GPT的，之前做的这个自然语言处理相关的工作，就基本上都失去意义了，或者是没有多的作用了，那么现在这里的问题就是，同样的。

我们做这些小模型，它的一些这个功能，比如说我们这个GPT4或者GPT5出来之后，比如说像易涵女士你们做的这个，Bug起那么它，在哪些比如说性能或者是一些功能上面，会不会被GPT5或者是其他的大模型给。

他们这个表现的更好，另外一个就是，能快一点吗，因为我们时间，好的好的，我就是也是这个问题的，也是这个问题的，那么就是说同样，另外一个除了性能，另外就是这个，数据隐私的问题，那么现在这个GPT4。

他们这个Plus用户已经，就是说对用户的数据，它不会收集，然后还有那么说我们会不会有一些其他的，中间层来进行这个数据隔离，那么这样的话，我们是不是就说不是需要所有的，业务都去建立一个小模型。

那么会不会这个大模型通吃，谢谢其他老师如果，谢谢，首先我明确一点，我们也有很大的模型，我们有80G的模型，但是我们的模型只是不是实时性的，我们更是batch的，对于这种大模型，我们不仅仅只用小模型。

这是第一点，然后第二点呢，回答你的问题就是当你funtune的data，足够多的时候，如果你的funtune data set，能到达10M的话，其实小模型的performance。

应该是和大模型一样的，甚至更好，因为大模型在funtune是有不稳定的因素，那小模型convert是非常的快，这是第二点，然后第三点是用户隐私的问题，那这个他收集不收集用户去吹猫，都是一个问题。

还有另外一个更重要的问题，是responsibility的问题，当用户的隐私被泄露的时候，谁负责，我想openai它是有免责的，就是它不用你的，它不收集你的数据，但它同时不保护你的数据。

如果有hacker去hacker了你的数据，导致你的数据在网上，能被所有人download的话，openai是免责的，好谢谢，好那我们时间已经超时了，但是我想最后，我们今天下午的这个时间过得非常的快。

但是我其实还是想最后不能免俗，然后希望我们4位嘉宾，最后利用最后的机会，因为我觉得在座的人士，应该说绝大部分的应该都是，刚刚进入大模型的领域，那么各位然后作为大模型领域，已经耕耘已久的。

那么对于这些刚刚进入的这些，无论是同学还是说从业者，还是说投资人，就你对大家加入到大模型的这么一个方向，你对他们最大的忠告或者是建议是什么，然后你能想到的，马上然后能够给大家分享的一句话，好吧。

然后咱们就用这个每一位，然后说一句话，然后我们来结束我们今天的这个论坛，好吧，那要不我们首先还是从银行开始，我可能说三句话吧，已经说了一句话，我本科学的是化工，然后后来自学的计算机。

然后有幸进入做research，发表了一些NLP的东西，现在在创业，所以没有任何一样东西是恒定的，没有任何一样东西是一直popular，一直风靡全球的，但是总会有新的东西到，所以stay tuned。

不停的去改变自己，迎接新的东西，找到自己喜爱的方向，不能追逐自己的梦想，但是不能随波逐流，好，谢谢，应和，我觉得我差不多的意思，就是首先要坚定，我觉得至少在未来的三五年，我觉得大模型确实会颠覆很多领域。

再一个就是坚持，坚持做你自己认为，你觉得有价值的东西，最后我觉得真的是不要盲目追风，好，谢谢，好，可能我的建议就是对媒体，或者是投资人，或者是同学，一样的，我的建议是对大模型。

保持cautiously optimistic，就是我们要认识到它的一些局限性和危害性，然后我们在做事情，在做科研的时候，可能更放眼于未来，就不要说我们解决的就是未来三个月，六个月的这个事情。

我们可能做科研的时候，更要考虑的是未来五年十年，我们要解决一个什么样的问题，就是你带着这样的一个预测去做科研，可能就是说对未来社会也能做更大的贡献，好，要高瞻远瞩，很像前一位讲者的一个观点。

我觉得很类似像比尔盖茨之前也曾经说过，其实做人工智能要很需要有责任心，就是你最终的目标是什么，我觉得那个威人如果是可以推动全人类更好的话，我觉得你做每件事情都不太会有错，对，大概是，好，好。

那这个时间总是过得很快，那我们今天下午这个技术模型的前沿技术论坛，然后就到此结束了，那再次感谢我们所有的线下线上的这个观众，然后也再次感谢我们，我应该说在座的四位嘉宾，然后以及我们刚刚离开的这个。

我们的这个林永华老师，那再次感谢大家，谢谢主持人，谢谢，谢谢大家，我們下次見。