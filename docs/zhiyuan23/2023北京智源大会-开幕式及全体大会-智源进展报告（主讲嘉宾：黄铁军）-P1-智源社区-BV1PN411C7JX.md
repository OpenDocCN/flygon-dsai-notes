# 2023北京智源大会-开幕式及全体大会-智源进展报告（主讲嘉宾：黄铁军） - P1 - 智源社区 - BV1PN411C7JX

自原研究院自成立以来，积极的探索新型科研管理等体制的机制的创新，，已经在创新研究、学术生态、成果转化等方面取得了重大的进展，，而且取得了一系列的研究的成果。。

下面有请自原研究院黄铁军院长代表研究院简单的汇报一下过去一年的建设进展。。

![](img/d091ad525a8ec9a0b08d6204924f6264_1.png)

铁军！，振興的吴部长 于市长 各位专家 各位领导 各位代表。

![](img/d091ad525a8ec9a0b08d6204924f6264_3.png)

![](img/d091ad525a8ec9a0b08d6204924f6264_4.png)

![](img/d091ad525a8ec9a0b08d6204924f6264_5.png)

![](img/d091ad525a8ec9a0b08d6204924f6264_6.png)

![](img/d091ad525a8ec9a0b08d6204924f6264_7.png)

一年一度的志愿进展报告，是我最想跟大家汇报的，也是最高兴的这么一次报告，一年来呢，在大家的支持下，志愿军院又取得了新的成果。

那么我们先从今天大家可以说最热门的这个词开始汇报起。

![](img/d091ad525a8ec9a0b08d6204924f6264_9.png)

![](img/d091ad525a8ec9a0b08d6204924f6264_10.png)

通用人工智能，那么有两个解释，一个呢叫GAI General Artificial Intelligence。

另外一个叫AGI Artificial General Intelligence。

![](img/d091ad525a8ec9a0b08d6204924f6264_12.png)

我想大多数咱们媒体那个大家理解的应该是第一个。

![](img/d091ad525a8ec9a0b08d6204924f6264_14.png)

确实我们现在已经进入了通用人工智能时代。

![](img/d091ad525a8ec9a0b08d6204924f6264_16.png)

但是呢，在人工智能领域谈了二十多年的是AGI。

![](img/d091ad525a8ec9a0b08d6204924f6264_18.png)

我们正在往这样的一个终极目标前进。

![](img/d091ad525a8ec9a0b08d6204924f6264_20.png)

所以目前呢，我们就处在从GAI往AGI迈进的这样的一个历史时期。

![](img/d091ad525a8ec9a0b08d6204924f6264_22.png)

要实现AGI，在过去的几次志愿大会上，每年我们都会讲有三条技术路线，第一条技术路线，大数据加今天大家都在用的自监督学习加大算力形成的信息类的模型，第二种基于这个虚拟的世界或者是真实的世界。

通过强化学习来训练出来的巨神模型，还有第三种，那就是直接超自然进化的作业，抄答案就是直接复制人脑复制一个数字的。

这个一个一个电子版本的这样的一个一个智能体出来。

![](img/d091ad525a8ec9a0b08d6204924f6264_24.png)

这三条路线的在全世界方面的都在进行。

![](img/d091ad525a8ec9a0b08d6204924f6264_26.png)

其中，当然所有的务女都是为了这个实现AGI。

![](img/d091ad525a8ec9a0b08d6204924f6264_28.png)

其中的第一个是今天最热门的一个机构。

![](img/d091ad525a8ec9a0b08d6204924f6264_30.png)

OpenAI做的GPT，第二个是另外一个机构。

![](img/d091ad525a8ec9a0b08d6204924f6264_32.png)

Google DeepMind的DQN深度强化学习网络为核心的取得了一系列的进展。

![](img/d091ad525a8ec9a0b08d6204924f6264_34.png)

智源研究院作为一个在这个通用人工智能方向一直在努力的机构，有一个不同于他们两个的特点，就是从第一性原理出发，真正的构造一个这个从如果是从梦想的角度来说。

从原子到有机分子到神经系统到身体的一个一个完整的这么一个一个智能系统AGI，当然这是一个大概要二十年的目标才有可能实现的，那么在作为一个新型研发机构平台，那我们呢，其实在三个方向都在开展工作。

也是今天我要给大家汇报的这个重点，第一个呢，就是大模型方向，第二个呢，巨身方向，当然还有刚才说的这样的一个特色方向的进展。

![](img/d091ad525a8ec9a0b08d6204924f6264_36.png)

大模型这样的一个时代大概在2018年就开始了。

![](img/d091ad525a8ec9a0b08d6204924f6264_38.png)

也就是智源研究院成立的那一年就成为了全世界的一个一个一个大家公认的这么一个一个一个方向，在这个方向上，我们率先汇聚了AI领域的顶尖学者，我们叫志愿学者开启了大模型的这个探索，率先组建了大模型的研究团队。

成为今天中国大模型研究的主力，率先预见了大模型时代的到来，包括大模型这个名词，就是2021年智源研究院发布悟道1。

0的时候正式提出来的。

![](img/d091ad525a8ec9a0b08d6204924f6264_40.png)

然后进入到大家的这个视野，我们率先发布了悟道大模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_42.png)

率先这个启动了大模型的测评，旗舰项目服务于大模型的行业的发展。

![](img/d091ad525a8ec9a0b08d6204924f6264_44.png)

我们率先的倡导大模型开源开放。

![](img/d091ad525a8ec9a0b08d6204924f6264_46.png)

发布了Flag Open大模型开源系统，率先构建大模型的生态。

![](img/d091ad525a8ec9a0b08d6204924f6264_48.png)

包括今天的志愿大会，还有这个十多万人的志愿社区。

![](img/d091ad525a8ec9a0b08d6204924f6264_50.png)

都是大模型技术研讨的一个高地。

![](img/d091ad525a8ec9a0b08d6204924f6264_52.png)

其中呢，2021年6月份发布的悟道2。0的大模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_54.png)

当时是我们国家第一个，也是当时全球最大的大模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_56.png)

1。75万亿参数的大模型，在国际范围得到了广泛的反响。

![](img/d091ad525a8ec9a0b08d6204924f6264_58.png)

当然现在大模型已经成为全社会关注的热点。

![](img/d091ad525a8ec9a0b08d6204924f6264_60.png)

那什么是大模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_62.png)

我们认为至少有三个特点，一个是规模要大。

![](img/d091ad525a8ec9a0b08d6204924f6264_64.png)

网络参数，神经网络的参数，要达到百亿规模以上。

![](img/d091ad525a8ec9a0b08d6204924f6264_66.png)

第二个要有涌现性，这是人工智能发展六七十年来。

![](img/d091ad525a8ec9a0b08d6204924f6264_68.png)

今年可以说是最里程碑的这样的一个新的特性。

![](img/d091ad525a8ec9a0b08d6204924f6264_70.png)

就是涌现性产生了预料之外的新能力。

![](img/d091ad525a8ec9a0b08d6204924f6264_72.png)

一个模型如果只能从原有的数据。

![](img/d091ad525a8ec9a0b08d6204924f6264_74.png)

原有的算法就能推导出来的结果，那不叫涌现。

![](img/d091ad525a8ec9a0b08d6204924f6264_76.png)

涌现一定是有全新的功能出现才可以，第三个就是通用性。

![](img/d091ad525a8ec9a0b08d6204924f6264_78.png)

它不限于专门问题或者专门的领域，具有通用性的能够解决各类问题。

![](img/d091ad525a8ec9a0b08d6204924f6264_80.png)

当然受限于模型目前的阶段。

![](img/d091ad525a8ec9a0b08d6204924f6264_82.png)

也不能说所有的问题都能解决，但是它有很强的推广性。

![](img/d091ad525a8ec9a0b08d6204924f6264_84.png)

那么今天我就特别高兴宣布。

![](img/d091ad525a8ec9a0b08d6204924f6264_86.png)

智原正式推出全面开源的悟道3。0模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_88.png)

第一个就是视觉大模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_90.png)

是系列大模型，视觉的系列大模型，今年以来，智原连续发了六个视觉大模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_92.png)

第一个是当时最强的，10亿参数的视觉基础模型EVA，通用性是它的最重要的特点，这个模型通过语义学习和几何结构学习相结合，解决了视觉模型的通用性问题，在ImageNet分类，Coco 检测分割。

Kinect 视频分类，等广泛的视觉任务中，取得了当时最强的性能，这些任务当初都要一个一个的专门的模型去做。

我们靠一个通用模型实现了所有的这些专用模型的功能。

![](img/d091ad525a8ec9a0b08d6204924f6264_94.png)

而且性能比它们还要强，在这个基础上又训练了EVA Clip的多模态的预训链模型，是零样本学习的一个基础模型，在今年年初发布了五个B-Lin的版本，创造了零样本学习性能的新高度。

超越了此前最强的OpenClip模型，在ImageNet的1K零样本，Top1达到了82%的准确率，去年发布的EVA Clip 1Bin版本。

今年才被Meta发布的Dyno第二版模型追评。

![](img/d091ad525a8ec9a0b08d6204924f6264_96.png)

我们都知道语言模型可以问答，视觉模型怎么提问，在这方面我们率先提出了，理解图像 解释图像 输出图像的理念，把自然元处理中的上下文学习的思想引入视觉模型，提出了通用视觉模型Paint。

以视觉为中心作为整个建模的核心思想，将图像作为输入输出的模态。

![](img/d091ad525a8ec9a0b08d6204924f6264_98.png)

从而获得上下文的视觉信息，完成各种视觉任务。

![](img/d091ad525a8ec9a0b08d6204924f6264_100.png)

今年4月，智原推出了首个利用视觉提示，完成任意分割任务的通用视觉模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_102.png)

SegGPT 一通百通，SegGPT应该说是通用视觉。

![](img/d091ad525a8ec9a0b08d6204924f6264_104.png)

我们的大模型进入通用视觉的一个里程碑。

![](img/d091ad525a8ec9a0b08d6204924f6264_106.png)

这个模型发布的时间和Meta发布的Sem，是同一天发布的。

![](img/d091ad525a8ec9a0b08d6204924f6264_108.png)

碰巧撞车，这两个模型都是通用视觉方面的里程碑，Sem模型最大的特点叫一出即通。

![](img/d091ad525a8ec9a0b08d6204924f6264_110.png)

点一个点 简单地点一个点，就能把这个物体精确地分割出来。

![](img/d091ad525a8ec9a0b08d6204924f6264_112.png)

这是可以说完美地解决了传统的图像分割问题。

![](img/d091ad525a8ec9a0b08d6204924f6264_114.png)

但是这是一个物体，SegGPT 是一通百通。

![](img/d091ad525a8ec9a0b08d6204924f6264_116.png)

可以分割任意的物体。

![](img/d091ad525a8ec9a0b08d6204924f6264_118.png)

包括物体的任意的零件，甚至于一个物体的不同的表面。

![](img/d091ad525a8ec9a0b08d6204924f6264_120.png)

只要你是一个相对具有物理意义的结构。

![](img/d091ad525a8ec9a0b08d6204924f6264_122.png)

它都可以分割出来，这是一个例子。

![](img/d091ad525a8ec9a0b08d6204924f6264_124.png)

它可以做视频。

![](img/d091ad525a8ec9a0b08d6204924f6264_126.png)

所以这是第一阵视频选中。

![](img/d091ad525a8ec9a0b08d6204924f6264_128.png)

如果你关注的是视频的运动物体的话，所有的这些运动物体都可以不用任何人的操作。

![](img/d091ad525a8ec9a0b08d6204924f6264_130.png)

就全部给自动地分割出来，所以强大的通用能力，灵活的推理能力。

![](img/d091ad525a8ec9a0b08d6204924f6264_132.png)

和自动视觉的分割能力，可以说我们已经达到了通用视觉的一个里程碑。

![](img/d091ad525a8ec9a0b08d6204924f6264_134.png)

这样的一个技术 这样的一个模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_136.png)

在自动驾驶领域，在机器人领域，在我们实体智能领域，一定会发挥基础性的作用，当时发布这个模型之后。

![](img/d091ad525a8ec9a0b08d6204924f6264_138.png)

就有很多用户关注，能不能做灵样本的视频编辑。

![](img/d091ad525a8ec9a0b08d6204924f6264_140.png)

因为这也是传统在图像视频领域。

![](img/d091ad525a8ec9a0b08d6204924f6264_142.png)

很重要的一个应用，我们就实现了灵样本的简单提示，提示还是需要的，你到底要做什么，提示还是需要的，但是不需要你提供样本去训练它。

这个模型就可以完成我们原来的各种视频的编辑任务了。

![](img/d091ad525a8ec9a0b08d6204924f6264_144.png)

在这个基础上，我们进一步扩展了一个新的模型，一个接受多模态的输入，产生多模态输出的多模态大模型，这个模型能够在多模态的序列中，补全一切产生。

而且能产生能生成多模态的预测。

![](img/d091ad525a8ec9a0b08d6204924f6264_146.png)

我就请大家看这么几个例子。

![](img/d091ad525a8ec9a0b08d6204924f6264_148.png)

左上角的第一张图，这个模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_150.png)

你给他这张图，他不是说给你解释这边有太阳有水有船。

![](img/d091ad525a8ec9a0b08d6204924f6264_152.png)

他上来就告诉你，这是莫奈的日出印象，然后给了很多认知异常的解释。

![](img/d091ad525a8ec9a0b08d6204924f6264_154.png)

左边的第二个例子，是能够完成少样本的图文的理解。

![](img/d091ad525a8ec9a0b08d6204924f6264_156.png)

给两个图文对作为例子。

![](img/d091ad525a8ec9a0b08d6204924f6264_158.png)

模型就自动的完成任务，他知道你要干这样的事。

![](img/d091ad525a8ec9a0b08d6204924f6264_160.png)

给两个例子，比如说大熊猫是一个中国的国宝。

![](img/d091ad525a8ec9a0b08d6204924f6264_162.png)

中国人都很喜欢，你再给个皮卡丘。

![](img/d091ad525a8ec9a0b08d6204924f6264_164.png)

他就会说皮卡丘是日本的一个明星的动画。

![](img/d091ad525a8ec9a0b08d6204924f6264_166.png)

日本人都很喜欢这个角色。

![](img/d091ad525a8ec9a0b08d6204924f6264_168.png)

还有这个模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_170.png)

能够根据图片和视频进行问答和多轮对话。

![](img/d091ad525a8ec9a0b08d6204924f6264_172.png)

在0样本的Coco图像的描述性能。

![](img/d091ad525a8ec9a0b08d6204924f6264_174.png)

达到了109，超过了Flamingo 80Billion的84。

![](img/d091ad525a8ec9a0b08d6204924f6264_176.png)

右边这张图展示的生成能力，比如根据任意长度的文本可以生成图像。

![](img/d091ad525a8ec9a0b08d6204924f6264_178.png)

这个大家现在都很多都有了，中间的是一个图图生成。

![](img/d091ad525a8ec9a0b08d6204924f6264_180.png)

图图生成是什么意思呢，就是你给他一对图像，他开始推理，比如说这个左边给一个小狗的，下面那张下面那个图。

![](img/d091ad525a8ec9a0b08d6204924f6264_182.png)

给一个小狗的图像，加上还有另外一幅老虎的图像。

![](img/d091ad525a8ec9a0b08d6204924f6264_184.png)

他就猜你可能要一个狗形状的老虎。

![](img/d091ad525a8ec9a0b08d6204924f6264_186.png)

所以就产生了一个狗头老虎的这样的图像。

![](img/d091ad525a8ec9a0b08d6204924f6264_188.png)

叫虎头狮，这样的一个图像，右下角是在多模式上下文中的生成。

![](img/d091ad525a8ec9a0b08d6204924f6264_190.png)

根据文本和图片的对作为提示，生成融合上下文信息的一个新的图片。

![](img/d091ad525a8ec9a0b08d6204924f6264_192.png)

这个图片是理解了这两种模式之后。

![](img/d091ad525a8ec9a0b08d6204924f6264_194.png)

产生的一个新的图片，以及相应的描述，还有更多的能力，我们还在挖掘，我们也希望尽快有更多的合作。

![](img/d091ad525a8ec9a0b08d6204924f6264_196.png)

来挖掘这种可以说多模式模型，蕴含的无穷无尽的潜力。

![](img/d091ad525a8ec9a0b08d6204924f6264_198.png)

所以总的来说，把上下文类似于语言这样的上下文的。

![](img/d091ad525a8ec9a0b08d6204924f6264_200.png)

一种学习能力引进图像之后，其实有更丰富，更让大家兴奋的新的这种通用智能。

![](img/d091ad525a8ec9a0b08d6204924f6264_202.png)

能够激发出来，语言模型可以说是大模型中。

![](img/d091ad525a8ec9a0b08d6204924f6264_204.png)

现在竞争的热点。

![](img/d091ad525a8ec9a0b08d6204924f6264_206.png)

那悟道3。0，我们今天正式发布语言大模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_208.png)

悟道天鹰和对大模型进行评测的一个体系，叫天秤。

![](img/d091ad525a8ec9a0b08d6204924f6264_210.png)

悟道天鹰Aquila语言大模型，是第一个中英文双语。

![](img/d091ad525a8ec9a0b08d6204924f6264_212.png)

支持商用符合数据合规要求的数据大模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_214.png)

所以大家可以放心的去用。

![](img/d091ad525a8ec9a0b08d6204924f6264_216.png)

还可以放心的商业化，因为智原是一个非营利机构。

![](img/d091ad525a8ec9a0b08d6204924f6264_218.png)

我们就是为这个行业发展提供公共的这个技术的。

![](img/d091ad525a8ec9a0b08d6204924f6264_220.png)

天鹰的这语言大模型呢，是在一个中英文的高质量的合规的语调数据库。

![](img/d091ad525a8ec9a0b08d6204924f6264_222.png)

基础上从零开始训练的一个模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_224.png)

通过数据质量的控制和多种训练的优化。

![](img/d091ad525a8ec9a0b08d6204924f6264_226.png)

实现了在更小的数据集，更短的训练时间，获得比其他的开源模型更优的性能。

![](img/d091ad525a8ec9a0b08d6204924f6264_228.png)

这是一个系列模型，我们会这个。

![](img/d091ad525a8ec9a0b08d6204924f6264_230.png)

这一次呢，我们这个发布的是7B和33B。

![](img/d091ad525a8ec9a0b08d6204924f6264_232.png)

就是70亿参数和333亿参数的基础模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_234.png)

和AquilaChat，就是对话模型，也是这两个参数规模。

![](img/d091ad525a8ec9a0b08d6204924f6264_236.png)

以及AquilaCode代码模型，文本代码生成模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_238.png)

后续的这些代码模型，以及这个升级的都会都会开源。

![](img/d091ad525a8ec9a0b08d6204924f6264_240.png)

Aquila基础模型的技术上继承了GPT-3。

![](img/d091ad525a8ec9a0b08d6204924f6264_242.png)

LAMA等架构的这个优点。

![](img/d091ad525a8ec9a0b08d6204924f6264_244.png)

那么替换了一批更高效的底层算子。

![](img/d091ad525a8ec9a0b08d6204924f6264_246.png)

重新设计了中英文双语的Tokenizer。

![](img/d091ad525a8ec9a0b08d6204924f6264_248.png)

升级了BMTrain的并行训练的方法，在Aquila的训练过程中。

![](img/d091ad525a8ec9a0b08d6204924f6264_250.png)

实现了比Mektran+DeepSpeed Zero 2。

![](img/d091ad525a8ec9a0b08d6204924f6264_252.png)

近8倍的训练效率的提升，所以我们有信心。

![](img/d091ad525a8ec9a0b08d6204924f6264_254.png)

后续给大家提供更大规模的，更适合产品化的模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_256.png)

这个模型呢，已经具备了很强的对话能力。

![](img/d091ad525a8ec9a0b08d6204924f6264_258.png)

比如这几个例子里边。

![](img/d091ad525a8ec9a0b08d6204924f6264_260.png)

最左边的例子，问他能不能带着炸药上飞机。

![](img/d091ad525a8ec9a0b08d6204924f6264_262.png)

他马上提醒你这是违法的行为。

![](img/d091ad525a8ec9a0b08d6204924f6264_264.png)

违反了什么规定，中间这个例子呢，中间这个例子呢。

![](img/d091ad525a8ec9a0b08d6204924f6264_266.png)

是用对话的方式。

![](img/d091ad525a8ec9a0b08d6204924f6264_268.png)

这是个语言模型，他理解了用户的意图。

![](img/d091ad525a8ec9a0b08d6204924f6264_270.png)

然后调用图像生成模型，刚才说的那个生成模型，来生成一幅图片。

![](img/d091ad525a8ec9a0b08d6204924f6264_272.png)

比如说帮我生成一个糖状的图片，帮我生成一个机器人的图片。

![](img/d091ad525a8ec9a0b08d6204924f6264_274.png)

如果在生成的图片过程中，你觉得不满意。

![](img/d091ad525a8ec9a0b08d6204924f6264_276.png)

没关系你直接告诉他就行了，比如这个例子里边。

![](img/d091ad525a8ec9a0b08d6204924f6264_278.png)

先生成了一张人脸的图片，说他的眼睛不好看，换成蓝色的。

![](img/d091ad525a8ec9a0b08d6204924f6264_280.png)

他给你换成蓝色的，说这个肤色不够白，他就给你变白。

![](img/d091ad525a8ec9a0b08d6204924f6264_282.png)

所以你有什么需求，你直接告诉他，这个模型就帮你完成这些设计任务了。

![](img/d091ad525a8ec9a0b08d6204924f6264_284.png)

在技术上呢，我们训练过程中实现了。

![](img/d091ad525a8ec9a0b08d6204924f6264_286.png)

模型能力和指令微调的循环的迭代，包括对数据集的高效的筛选和优化。

![](img/d091ad525a8ec9a0b08d6204924f6264_288.png)

充分挖掘基础模型的潜力，Aquila Chat支持可扩展的特殊指令规范。

![](img/d091ad525a8ec9a0b08d6204924f6264_290.png)

可以根据你的需要。

![](img/d091ad525a8ec9a0b08d6204924f6264_292.png)

再增加比如说你的设计任务，一些比较体系化的指令。

![](img/d091ad525a8ec9a0b08d6204924f6264_294.png)

你可以把它定义出来，然后这个模型就按照你的工作的要求。

![](img/d091ad525a8ec9a0b08d6204924f6264_296.png)

来自动帮你完成任务。

![](img/d091ad525a8ec9a0b08d6204924f6264_298.png)

那么刚才我演示的背后的图像生成，和图像的调整修改功能。

![](img/d091ad525a8ec9a0b08d6204924f6264_300.png)

用的是我们去年发布的。

![](img/d091ad525a8ec9a0b08d6204924f6264_302.png)

Auto Diffusion，8种语言，今年升级为18种语言的。

![](img/d091ad525a8ec9a0b08d6204924f6264_304.png)

全球知识语言种类最多的，一个图像生成模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_306.png)

也已经进入了国际上，最热门的这样的一个图文生成模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_308.png)

因为知识的语言多。

![](img/d091ad525a8ec9a0b08d6204924f6264_310.png)

很多国家的用户都可以用这个模型，来生成他们喜欢的图像。

![](img/d091ad525a8ec9a0b08d6204924f6264_312.png)

代码模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_314.png)

基于Aquila，这个7Billion的这样的一个基础模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_316.png)

Aquila Code，也是7Billion，70亿参数，用小数据及小参数量。

![](img/d091ad525a8ec9a0b08d6204924f6264_318.png)

实现了高性能的，目前是支持中英双语的。

![](img/d091ad525a8ec9a0b08d6204924f6264_320.png)

也是应该说是性能最好的一个，开源的代码的模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_322.png)

这里面的所用的数据代码。

![](img/d091ad525a8ec9a0b08d6204924f6264_324.png)

经过了高质量的合规处理，使用合规的。

![](img/d091ad525a8ec9a0b08d6204924f6264_326.png)

开源的许可代码进行训练，所以大家可以放心的，用于我们的软件开发。

![](img/d091ad525a8ec9a0b08d6204924f6264_328.png)

这样的一些任务，Aquila Code 7B。

![](img/d091ad525a8ec9a0b08d6204924f6264_330.png)

分别在英伟达的和国产的芯片上。

![](img/d091ad525a8ec9a0b08d6204924f6264_332.png)

完成了模型的训练，而且通过对多种架构的代码，和模型的开源。

![](img/d091ad525a8ec9a0b08d6204924f6264_334.png)

在很多，无论你是什么样的一个软件的组合。

![](img/d091ad525a8ec9a0b08d6204924f6264_336.png)

这样的一个代码模型，都可以部署，这个就是刚才演示过了的，去年发布的9种语言，今年升级为18种语言的一个，在文图生成领域，国际上影响力很大的一个。

Auto-Diffusion模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_338.png)

下面给大家报告一下，大模型评测的工作，这项工作大家都知道，今天全世界发布了这么多模型，到底哪些模型好，哪些模型在哪些方面好，哪些方面还存在不足，我们在科技部大模型的，这样的一个旗舰项目的支持下。

今年1月1号正式启动，可以说第一件重要的任务，就是推出了大语言模型的评测体系，天秤，这样的一个大模型体系，目标就是建立科学公正开放的，评测基准方法工具级，协助研究人员全方位的，来评估技术模型。

以及训练上面的性能，同时探索，我们也在探索利用AI方法，实现主观评测，我们现在客观评测，主观评测同时在进行，同时也希望用AI，我们做AI用AI来减少，主观评测的工作量。

大幅提升评测的效率和客观性。

![](img/d091ad525a8ec9a0b08d6204924f6264_340.png)

目前天秤大语言模型评测体系。

![](img/d091ad525a8ec9a0b08d6204924f6264_342.png)

在能力任务指标，这样的一个三个维度上建立了。

![](img/d091ad525a8ec9a0b08d6204924f6264_344.png)

可以说是一个全方位的评测体系，包括30多种能力。

![](img/d091ad525a8ec9a0b08d6204924f6264_346.png)

就是语言大模型，可能具备的30多种能力。

![](img/d091ad525a8ec9a0b08d6204924f6264_348.png)

加上五种任务，再乘以四大类的指标，总共差不多600维的。

![](img/d091ad525a8ec9a0b08d6204924f6264_350.png)

这样的一个评测体系，应该说比较全面的能够衡量。

![](img/d091ad525a8ec9a0b08d6204924f6264_352.png)

一个大模型的能力，这个评测体系是一种自动化方式进行的。

![](img/d091ad525a8ec9a0b08d6204924f6264_354.png)

在线，当然如果一个模型开源，然后把模型拿来，直接在实验室评测，没问题，如果有模型能开放API，我们就直接调用，也能评测，速度很快，第二天就出全面的评测报告了，如果咱们刚才说的研发团队。

希望对自己的模型进行评估，也可以采用这个体系来自行评估，不去公开指标，有的时候大家在研发，有的指标好，有的指标坏。

不那么好。

![](img/d091ad525a8ec9a0b08d6204924f6264_356.png)

这没有关系，通过测评来不断的提升和发展。

![](img/d091ad525a8ec9a0b08d6204924f6264_358.png)

目前天秤的开源大模型评测体系，已经面向公众开放注册申请，目前支持，在硬件方面，支持英伟达，华为的生腾，韩5G，昆仑星，等多种芯片架构，以及PyTouch，MineSport，等多种深度学习框架。

此外天秤在我们GitHub上的项目中，也分享了，目前主要是语言模型的评测，我们目前也增加了，多模态文图生成的评测工具。

![](img/d091ad525a8ec9a0b08d6204924f6264_360.png)

当然文图生成的这一块还在开发中，欢迎大家使用。

![](img/d091ad525a8ec9a0b08d6204924f6264_362.png)

今年年初。

![](img/d091ad525a8ec9a0b08d6204924f6264_364.png)

同样是在科技部的大模型的旗舰项目支持下。

![](img/d091ad525a8ec9a0b08d6204924f6264_366.png)

正式发布了，Flag Open大模型技术开源体系。

![](img/d091ad525a8ec9a0b08d6204924f6264_368.png)

我刚才尽管在介绍智原的大模型的最新进展，但是我一直在说，我们是在做开源的模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_370.png)

这个模型没有任何保留的，可以全社会开放，那么大模型的旗舰项目。

![](img/d091ad525a8ec9a0b08d6204924f6264_372.png)

实际上正在，目前也有八个团队，在国家项目的支持下。

![](img/d091ad525a8ec9a0b08d6204924f6264_374.png)

在开展研究，那么他们的一些优秀的算法，后续也会通过评测集成的方式。

![](img/d091ad525a8ec9a0b08d6204924f6264_376.png)

变成一个体系，大模型不是任何一家机构。

![](img/d091ad525a8ec9a0b08d6204924f6264_378.png)

或者一家公司垄断的技术，大模型技术体系是大家共建共享。

![](img/d091ad525a8ec9a0b08d6204924f6264_380.png)

我们要共建一个智利社会，所需要的一套基础的算法体系。

![](img/d091ad525a8ec9a0b08d6204924f6264_382.png)

那么这样的一个Flag Open的，大模型的技术开源体系，希望在推动。

![](img/d091ad525a8ec9a0b08d6204924f6264_384.png)

在加强合作方面，来能够做出基础性的贡献。

![](img/d091ad525a8ec9a0b08d6204924f6264_386.png)

目前的Flag Open中的。

![](img/d091ad525a8ec9a0b08d6204924f6264_388.png)

AI算法方面，已经把我刚才讲到的，所有的开源模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_390.png)

以及国内外的一些模型，和背后的算法，集成进来了。

![](img/d091ad525a8ec9a0b08d6204924f6264_392.png)

支持并行加速技术FSDP，集成了高效推力技术。

![](img/d091ad525a8ec9a0b08d6204924f6264_394.png)

Laura和BM Infra，所以在这样的一个，开源的体系下面。

![](img/d091ad525a8ec9a0b08d6204924f6264_396.png)

如果一个机构，即便你是从零开始要做大模型，你也可以用这样的一套体系，很快地开展自己的，技术研发活动，那么其中Flag Proof，是关于硬件评测的，我们过去一年，在这方面做了很多工作。

也有可以说是很精确的，对硬件的性能的评测的结果，目的还是为了促进，咱们芯片硬件的发展，我们掌握的情况。

我们的芯片发展很快。

![](img/d091ad525a8ec9a0b08d6204924f6264_398.png)

所以我们也对，基础软件体系，更好的支撑AI的发展。

![](img/d091ad525a8ec9a0b08d6204924f6264_400.png)

抱有充分的信心，天秤那样的一个，大模型的评测平台，开源了，刚才说已经开源了，多模态的评测工具，但是这个还需要，进一步的发展，在Flag Data，就是数据的处理方面，也发布了一系列的。

数据分析的 清洗的，和未调的这样的工具。

![](img/d091ad525a8ec9a0b08d6204924f6264_402.png)

这些工具，本身我们自己都在用，但是我们也把它拿出来，供大家如果你做，数据加工清洗的话，你也可以去使用这样的工具。

来开发自己的。

![](img/d091ad525a8ec9a0b08d6204924f6264_404.png)

数据清洗系统，那么还有一个，就是大家关心的，大模型的生态，生态中最重要的，可以说物理基础，其实仍然是要回到软硬件，那么在AI的时代，软硬件应该是什么样的，一种形态呢，我们都知道，我们经过了两个时代。

一个就是PC互联网时代，在那个时代，最初是Wintel，这样的一个体系，在主导着整个的生态，那么后来出现了Linux，现在Linux操作系统，也已经成为操作系统的，主要的一个平台，在移动互联网时代。

出现了两个生态，一个是iOS的封闭生态，苹果在优化，另外一个是Android+ARM的生态，这个是通常大家知道，准封闭半开放生态，Android是开源的，但是也是受到一定的管控的。

不像Linux那样那么开放，那么在CPU方面，刚才讲Risk 5，在这样的一个时代就出现了，而且现在在CPU的这样的一个领域，已经应该说正在发挥主导作用，所以在智能时代，这样的一个基础软件体系。

应该是什么样的，我们认为，当然也不仅仅是我们认为，应该全世界应该主要的观点，都是它一定是一个开源开放的时代，那么今天尽管大模型，在很多系统方面表现已经很好，但是如果让全人类用，让千家万户用。

让千千万万的企业去用的话，一个封闭的生态，是不会这么长远发展下去的，一个开源的生态，在软件上要开源，在硬件上要开放，大家既要竞争又要合作，这是一个千千万万的企业，共同竞争 共同合作。

营造出来的开源开放的生态体系。

![](img/d091ad525a8ec9a0b08d6204924f6264_406.png)

在这方面，我们国家应该说，已经做了很多的努力，很多企业 很多机构，做的这个技术和模型都是开放的，但是我们还需要加强，我们初步统计了一下，今年以来的语言模型的，大模型开源的项目，全世界范围之内。

开源的总共有42项，我们国家放出来的，所谓放出来的就是我有，但是有38项，其中9项是开源的，那相比之下，我认为我们的开源开放力度，还是远远不够的，我们应该进一步加强开源开放，开源开放也是竞争。

你真有水平，真有好算法，拿出来 大家去评测去比去继承，才证明技术水平，而不是我就仅仅靠这样的一个结果，来说是不是优秀，在语言的数据方面，我们也做了一个工作，也是目前应该说大家急需的。

一个大规模的可商用的，中文开源的指令数据机，我相信很多做大模型的机构，或者是企业都在做同样的事情，这是对其挑优必须的一个能力，CYG应该说目前是，全世界范围之内。

规模最大的一个中文的开源的指令机。

![](img/d091ad525a8ec9a0b08d6204924f6264_408.png)

第一期有171K的，开源可商用的中文指令数据，已经开放了，已经有很多下载，大家已经在用了，我们还在开发第二期，争取成为规模最大，而且是持续更新的中文的，多任务的指令的数据机。

那么讲了大模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_410.png)

我刚才讲还有两条技术路线。

![](img/d091ad525a8ec9a0b08d6204924f6264_412.png)

尽管我们花了80%的人力物力资源，在做大模型，但是另外两条路线也不能不做。

![](img/d091ad525a8ec9a0b08d6204924f6264_414.png)

也必须做，虽然它更漫长一点，但是那是通往AGI的另外两条路径。

![](img/d091ad525a8ec9a0b08d6204924f6264_416.png)

第一个就是在巨深的多模态交互模型方面。

![](img/d091ad525a8ec9a0b08d6204924f6264_418.png)

![](img/d091ad525a8ec9a0b08d6204924f6264_419.png)

我们探索在Minecraft虚拟世界中，让智能体学习完成各种。

![](img/d091ad525a8ec9a0b08d6204924f6264_421.png)

由语言描述的任务，比如告诉智能体制作一个石锤子。

![](img/d091ad525a8ec9a0b08d6204924f6264_423.png)

建造一个木制的避难所，你告诉他这样的一个任务。

![](img/d091ad525a8ec9a0b08d6204924f6264_425.png)

他就可以自己在游戏世界，自己完成了。

![](img/d091ad525a8ec9a0b08d6204924f6264_427.png)

不要再用鼠标控制，一步步的走这些东西都不要了，你要想干啥，你告诉他他就可以。

![](img/d091ad525a8ec9a0b08d6204924f6264_429.png)

这个应该说是通用人工智能的，一个新的赛道。

![](img/d091ad525a8ec9a0b08d6204924f6264_431.png)

那么全世界范围之内，也有不少机构在进行，我们从去年基于模仿学习的。

![](img/d091ad525a8ec9a0b08d6204924f6264_433.png)

策略大模型VPT。

![](img/d091ad525a8ec9a0b08d6204924f6264_435.png)

奖励函数Mineclip，到今年利用大规模语言模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_437.png)

进行任务分解和规划的，Plan for MC。

![](img/d091ad525a8ec9a0b08d6204924f6264_439.png)

这样的一个模型方面，完成了大量的任务。

![](img/d091ad525a8ec9a0b08d6204924f6264_441.png)

我记得两个月之前，发布这个模型的时候，24项任务，应该是全球范围之内。

![](img/d091ad525a8ec9a0b08d6204924f6264_443.png)

完成任务最多的，这样的一个智能模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_445.png)

原来的那个，就是现有的这些方法，是依赖人类的知识和提示的，下一个目标。

![](img/d091ad525a8ec9a0b08d6204924f6264_447.png)

我们是让智能体，在这个基础上，在开放世界继续学习。

![](img/d091ad525a8ec9a0b08d6204924f6264_449.png)

所以包括策略级，和专门的针对，这种多模特交互的。

![](img/d091ad525a8ec9a0b08d6204924f6264_451.png)

大模型方面的进一步的研究，从而让它自适应的，在开放世界中。

![](img/d091ad525a8ec9a0b08d6204924f6264_453.png)

能够完成更多的任务，并且具备自己的创造力，创造性的完成任务。

![](img/d091ad525a8ec9a0b08d6204924f6264_455.png)

在类脑智能。

![](img/d091ad525a8ec9a0b08d6204924f6264_457.png)

和生命模拟这个方向，我们的工作也在继续，去年志愿大会发布了，最高精度的仿真线虫，到现在为止，这仍然是精度最高的，论文还正在评审过程中，有了这个工作基础，我们把仿真这个线虫，所用的生命模拟平台。

叫Evaluation天眼全面开源，并提供了在线服务，所以大家如果想做，同样的任务，你可以拿这个代码，自己去运行去做，你也可以，你说我没有那么多计算机算力，我只有这些一些生物数据，那没关系。

你通过在线的方式，可以在我们的平台上完成，天眼平台呢，有四项最显著的特点，第一个是当今效率最高的，精细神经系统仿真的平台，第二呢，是超大规模的神经网络仿真，目前呢，已经高效的复现了领域内。

多个大规模的神经模型，第三个呢，我们是提供在线工具，刚才讲的，一站式的，你只要有生物数据，那就可以一站式的建模，仿真 可视化，在一个平台上可以完成，而且其中这个可视化的交互，是天眼独有的。

整个你可以观察神经系统，在这样的一个运行过程中，它的信号发生了什么样的变化，是怎么样，因为我们最终想知道，生命 智能背后的每一步，不像今天是黑箱，我们想知道，这个到底发生了什么，所有的细节呢。

在这个平台上呢，都可以看到。

![](img/d091ad525a8ec9a0b08d6204924f6264_459.png)

我们针对呢，目前就是神经科学领域，结构和功能最完整的一个模型呢，是Allen研究所。

![](img/d091ad525a8ec9a0b08d6204924f6264_461.png)

美国Allen研究所的V1，也就是初级视觉皮图的一个模型，我们呢在这个天眼平台上，从仿真速度和模型细节，两方面入手。

提供了一个。

![](img/d091ad525a8ec9a0b08d6204924f6264_463.png)

在它的基础上提升了，一个运行更快，更加符合生物，生理约束的一个新版本，那么特别的呢，我们可以对千万规模，千万规模的精细神经元子，这样的神经网络，进行高效的可视化。

以及呢十万苍石的规模的交互。

![](img/d091ad525a8ec9a0b08d6204924f6264_465.png)

所以就像刚才说的，你可以像神经系统是一个复杂的森林，今天还是一个黑暗森林。

![](img/d091ad525a8ec9a0b08d6204924f6264_467.png)

你可以在这个森林中，对你周边一定范围之内的这个树木。

![](img/d091ad525a8ec9a0b08d6204924f6264_469.png)

树枝 树叶，所有的细节看清楚，到底在点亮之后。

![](img/d091ad525a8ec9a0b08d6204924f6264_471.png)

就可以看清楚到底在发生什么，我们相信呢，这个一定会，无论是对于这个神经科学。

![](img/d091ad525a8ec9a0b08d6204924f6264_473.png)

还是对于人工智能研究呢，都能起到基础性的支撑作用。

![](img/d091ad525a8ec9a0b08d6204924f6264_475.png)

为了加快这个计算速度。

![](img/d091ad525a8ec9a0b08d6204924f6264_477.png)

我们和天津超算合作，把这个天眼呢，已经在天河超级计算机上。

![](img/d091ad525a8ec9a0b08d6204924f6264_479.png)

成功地部署，在节省能耗的情况下。

![](img/d091ad525a8ec9a0b08d6204924f6264_481.png)

提升了20倍的这个计算速度，可以说实现了全球范围内最极致的，这个神经系统仿真的性能。

![](img/d091ad525a8ec9a0b08d6204924f6264_483.png)

第一次，把大规模精细神经系统的仿真速度。

![](img/d091ad525a8ec9a0b08d6204924f6264_485.png)

逼近生物真实，现在这个工作还在做，未来呢，我们还跟天河，就是天津的超算的进一步合作，进一步挖掘我们超算的这个，硬件和软件的潜力，早日实现，全球第一个精细的人类大脑，当然这个时间，我说早日啊，应该是早年。

可能还得15到20年的时间，才能做到，但是这是通向刚才讲的。

![](img/d091ad525a8ec9a0b08d6204924f6264_487.png)

AGI的一个必须的这么一个里程碑，那下面就请大家看一下。

![](img/d091ad525a8ec9a0b08d6204924f6264_489.png)

现在这个神经系统的一个模型，这就是智能在发生的一个物理的生理的基础。

![](img/d091ad525a8ec9a0b08d6204924f6264_491.png)

![](img/d091ad525a8ec9a0b08d6204924f6264_492.png)

![](img/d091ad525a8ec9a0b08d6204924f6264_493.png)

![](img/d091ad525a8ec9a0b08d6204924f6264_494.png)

![](img/d091ad525a8ec9a0b08d6204924f6264_495.png)

我刚才讲的这个神经系统。

![](img/d091ad525a8ec9a0b08d6204924f6264_497.png)

这其实是智能的一个最直接的一层，再往下就是我们的。

![](img/d091ad525a8ec9a0b08d6204924f6264_499.png)

这个细胞 蛋白质，这样的有机分子，这一块呢。

![](img/d091ad525a8ec9a0b08d6204924f6264_501.png)

我们的健康计算中心，专门专注于运用通用人工智能和大模型的这些前沿技术。

![](img/d091ad525a8ec9a0b08d6204924f6264_503.png)

不断地开拓生命科学，包括服务于健康这样的研究的边界。

![](img/d091ad525a8ec9a0b08d6204924f6264_505.png)

主要的是蛋白质的设计和量子化学。

![](img/d091ad525a8ec9a0b08d6204924f6264_507.png)

这两个方向，在2023年，研究中心研发的Open Complex大分子预测模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_509.png)

在CAMO蛋白质结构预测竞赛中赢得了年度冠军，不是一次冠军，是连续的每次比赛都是冠军，其中有一次我们忘记了提交数据，剩下的只要提交数据的全部是这个冠军，目前呢。

这个中心正致力于开发基于结构的大分子。

![](img/d091ad525a8ec9a0b08d6204924f6264_511.png)

大分子包括蛋白质，包括核酸适配体的生成模型。

![](img/d091ad525a8ec9a0b08d6204924f6264_513.png)

并且把它应用于药物设计等领域。

![](img/d091ad525a8ec9a0b08d6204924f6264_515.png)

此外呢，还正在构建一个生物分子的统一的大模型，希望能够推动包括人工智能，包括生命科学。

![](img/d091ad525a8ec9a0b08d6204924f6264_517.png)

包括医药设计这样的各类任务的发展，那最后呢，我就简单的这个报告一下，今年这个志愿大会的安排，志愿大会呢，今年是第五届，我们一直在努力，我们追求的是国际视野，技术前沿，思想碰撞，洞见未来。

办成最受人工智能，精英人群喜欢的专业的大会。

![](img/d091ad525a8ec9a0b08d6204924f6264_519.png)

应该说一年一度的志愿大会，已经成为北京全国乃至全球范围之内的一个，独具特色的一个专业的盛会，成为北京科技创新中心建设的一张闪亮的名片，像往年一样，今年的志愿大会同样是群星灿烂。

汇聚了人工智能领域最关键的人物，最重要的机构，最核心的话题和最内行的观众，我们这个大会呢，如果大家要去比的话，全球范围之内能够有这么多，顶尖专业人士出席的。

至少是极其罕见。

![](img/d091ad525a8ec9a0b08d6204924f6264_521.png)

那么马上呢，我这个报告还有一分半钟结束之后，我们就会进入今年的Keynote，那么今年的我们有两位嘉宾，一位是图令奖的获得者，深度学习的三巨头之一杨乐坤，乐坤呢现在在法国，凌晨四点。

原来他是在美国答应的这件事，但是呢，法国政府有活动，他必须去法国，然后我说那你太辛苦了，四点钟要再要要要要接入，你拍个视频吧也行，他说不，我就要实时的跟大家这个讲，所以大概一分钟之后啊，我们就接入。

那么我们上午的第二位嘉宾的Max Tegmark。

![](img/d091ad525a8ec9a0b08d6204924f6264_523.png)

他已经在前台就坐了，等会呢。

![](img/d091ad525a8ec9a0b08d6204924f6264_525.png)

他会分享他的观点，这两位嘉宾的，他观点是有一定的对立的，乐坤认为我们应该乐观的发展通用人物智能，现在远远没有到这个这个应该紧张的时候，他跟Max说。

现在就要这个加强这个这个管理和控制。

![](img/d091ad525a8ec9a0b08d6204924f6264_527.png)

等会我们听他们的精彩的观点，当然安全伦理风险，这肯定是这个我们应该关注的，这个高度关注的话题，明天呢，明天一天全天的一个关于AI安全的论坛，有很多著名的专家，这里边呢。

包括这个UC Berkeley的著名的人物智能教授，也是可以说几千万人都都是读着他的书学的AI，Russell教授，他也已经在现场，这会儿不在现场，他明天会现场跟大家进行这个交流，还有呢。

我们的深度学习的教父，Jeffrey Hinton，老先生身体不好，本来前年答应来讲，在最后大会要开的前两天，突然给我们发个邮件说，不行，我发现我的方法里面有个bug，这个会不能讲了，我说那不行啊。

那我们都已经宣传出去了，那个Hinton说，没关系，我马上在那个推特上发一步消息，就就说我是有bug，所以不能讲，后面的相关的报告都不讲了，这个这一周安排的报告都不讲了，但是今年呢。

大家也都新闻上都看到很多报道啊，他呢也是实时介入，明天呢会在伦敦给大家讲，他对人工智能最新的担心和他的这个，我觉得这是很难得，当然还有一位难得的人物，就是大家关注度很高的OpenAI的CEO。

Sam Altman，也是明天实时呢在线，跟大家进行这个，在这个论坛上跟大家进行交流。

![](img/d091ad525a8ec9a0b08d6204924f6264_529.png)

那这次会呢，我们差不多跟往年是这个类似的规模，有20个论坛，100场报告，顶尖的专家，顶尖的观众，让我们呢，共同来享受这两天的，纯粹的专业的，AI的最新的思想。

最新的进展。

![](img/d091ad525a8ec9a0b08d6204924f6264_531.png)

谢谢大家，(掌声)。

![](img/d091ad525a8ec9a0b08d6204924f6264_533.png)